
@inproceedings{brady_inductive_2004,
  series = {{{LNCS}}},
  title = {Inductive {{Families Need Not Store Their Indices}}},
  volume = {3085},
  booktitle = {Types for {{Proofs}} and {{Programs}}, {{Torino}}, 2003},
  publisher = {{Springer-Verlag}},
  author = {Brady, Edwin and McBride, Conor and McKinna, James},
  editor = {Berardi, Stefano and Coppo, Mario and Damiani, Ferrucio},
  year = {2004},
  keywords = {Alternative Implementation,Dependent Type,Elimination Rule,Functional Language,Type Theory},
  pages = {115-129},
  file = {/Users/doisinkidney/Zotero/storage/9Y2NHXFZ/Brady et al. - 2004 - Inductive Families Need Not Store Their Indices.pdf}
}

@inproceedings{wadler_how_1985,
  title = {How to {{Replace Failure}} by a {{List}} of {{Successes}}: {{A}} Method for Exception Handling, Backtracking, and Pattern Matching in Lazy Functional Languages},
  booktitle = {Functional {{Programming Languages}} and {{Computer Architecture}}, {{FPCA}} 1985, {{Nancy}}, {{France}}, {{September}} 16-19, 1985, {{Proceedings}}},
  doi = {10.1007/3-540-15975-4_33},
  url = {http://dx.doi.org/10.1007/3-540-15975-4_33},
  author = {Wadler, Philip},
  year = {1985},
  keywords = {Pattern Match,Functional Language,Empty List,Exception Handling,Theorem Prove},
  pages = {113--128}
}

@inproceedings{meijer_functional_1991,
  title = {Functional {{Programming}} with {{Bananas}}, {{Lenses}}, {{Envelopes}} and {{Barbed Wire}}},
  urldate = {2016-09-30},
  booktitle = {Functional {{Programming Languages}} and {{Computer Architecture}}},
  publisher = {{Springer}},
  url = {http://www.cs.tufts.edu/~nr/cs257/archive/erik-meijer/bananas.ps.gz},
  author = {Meijer, Erik and Fokkinga, Maarten and Paterson, Ross},
  year = {1991},
  pages = {124--144},
  file = {/Users/doisinkidney/Zotero/storage/TIGEDEZ2/Meijer et al. - Functional Programming with Bananas, Lenses, Envel.pdf}
}

@misc{piponi_monad_2009,
  title = {A {{Monad}} for {{Combinatorial Search}} with {{Heuristics}}},
  abstract = {Haskell provides a great way to perform combinatorial searching with backtracking: the list monad. Do-notation provides a nice DSL that make...},
  urldate = {2016-11-06},
  journal = {A Neighborhood of Infinity},
  url = {http://blog.sigfpe.com/2009/07/monad-for-combinatorial-search-with.html},
  author = {Piponi, Dan},
  month = jul,
  year = {2009},
  keywords = {Backtracking,Combinatorial Search,Haskell},
  file = {/Users/doisinkidney/Zotero/storage/9CJJK9SG/monad-for-combinatorial-search-with.html}
}

@inproceedings{kiselyov_embedded_2009,
  title = {Embedded Probabilistic Programming},
  booktitle = {Domain-{{Specific Languages}}},
  publisher = {{Springer}},
  url = {http://okmij.org/ftp/kakuritu/Hansei.html\#derivation},
  author = {Kiselyov, Oleg and Shan, Chung-Chieh},
  year = {2009},
  pages = {360--384},
  file = {/Users/doisinkidney/Zotero/storage/RAAKX9NM/dsl-paper.pdf}
}

@incollection{droste_semirings_2009,
  address = {Berlin, Heidelberg},
  series = {Monographs in {{Theoretical Computer Science}}. {{An EATCS Series}}},
  title = {Semirings and {{Formal Power Series}}},
  volume = {1},
  copyright = {\textcopyright{}2009 Springer-Verlag Berlin Heidelberg},
  isbn = {978-3-642-01491-8 978-3-642-01492-5},
  abstract = {This chapter presents basic foundations for the theory of weighted automata: semirings and formal power series. A fundamental question is how to extend the star operation (Kleene iteration) from languages to series. For this, we investigate ordered, complete and continuous semirings and the related concepts of star semirings and Conway semirings. We derive natural properties for the Kleene star of cycle-free series and also of matrices often used to analyze the behavior of weighted automata. Finally, we investigate cycle-free linear equations which provide a useful tool for proving identities for formal power series.},
  language = {en},
  urldate = {2016-10-31},
  booktitle = {Handbook of {{Weighted Automata}}},
  publisher = {{Springer Berlin Heidelberg}},
  url = {http://staff.mmcs.sfedu.ru/~ulysses/Edu/Marktoberdorf_2009/working_material/Esparsa/Kuich.\%20Semirings\%20and\%20FPS.pdf},
  author = {Droste, Manfred and Kuich, Werner},
  editor = {Droste, Manfred and Kuich, Werner and Vogler, Heiko},
  year = {2009},
  keywords = {Computation by Abstract Devices,Language Translation and Linguistics,Logics and Meanings of Programs,Mathematical Logic and Formal Languages,Mathematical Logic and Foundations,Theory of Computation},
  pages = {3-28},
  file = {/Users/doisinkidney/Zotero/storage/B2CHSEQ2/Droste and Kuich - Semirings and Formal Power Series.pdf},
  doi = {10.1007/978-3-642-01492-5_1}
}

@book{golan_semirings_1999,
  title = {Semirings and Their {{Applications}}},
  urldate = {2016-11-03},
  publisher = {{Springer Science \& Business Media}},
  url = {https://books.google.nl/books?hl=en\&lr=\&id=DNdTF_4PzpoC\&oi=fnd\&pg=PA1\&ots=NJkLYAMVwu\&sig=1yaUSRx1QpxfvKSEIXllAffGo3c},
  author = {Golan, Jonathan S.},
  year = {1999},
  file = {/Users/doisinkidney/Zotero/storage/7WDTV3YM/Golan - 1999 - Semirings and their Applications.pdf}
}

@inproceedings{fischer_reinventing_2009,
  title = {Reinventing {{Haskell Backtracking}}},
  abstract = {Almost ten years ago, Ralf Hinze has written a functional pearl on how to derive backtracking functionality for the purely functional programming language Haskell. In these notes, we show how to arrive at the efficient, two-continuation based backtracking monad derived by Hinze starting from an intuitive inefficient implementation that we subsequently refine using well known program transformations.
It turns out that the technique can be used to build monads for non-determinism from modular, independent parts which gives rise to various new implementations. Specifically, we show how the presented approach can be applied to obtain new implementations of breadth-first search and iterative deepening depth-first search.},
  language = {en},
  booktitle = {Informatik 2009, {{Im Fokus}} Das {{Leben}} ({{ATPS}}'09)},
  publisher = {{GI Edition}},
  url = {http://www-ps.informatik.uni-kiel.de/~sebf/data/pub/atps09.pdf},
  author = {Fischer, Sebastian},
  year = {2009},
  pages = {15},
  file = {/Users/doisinkidney/Zotero/storage/A8SSLP9E/Fischer - Reinventing Haskell Backtracking.pdf;/Users/doisinkidney/Zotero/storage/CDX7PKZ3/atps09.pdf}
}

@inproceedings{okasaki_fast_1999,
  title = {From {{Fast Exponentiation}} to {{Square Matrices}}: {{An Adventure}} in {{Types}}},
  volume = {34},
  shorttitle = {From {{Fast Exponentiation}} to {{Square Matrices}}},
  booktitle = {Proceedings of the {{ACM SIGPLAN International Conference}} on {{Functional Programming}} ({{ICFP}}'99), {{Paris}}, {{France}}, {{September}} 27-29, 1999},
  publisher = {{ACM}},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.456.357\&rep=rep1\&type=pdf},
  author = {Okasaki, Chris},
  year = {1999},
  keywords = {Data Structures,Haskell,Nested Types},
  pages = {28},
  file = {/Users/doisinkidney/Zotero/storage/3UGGUBQ5/Okasaki - From Fast Exponentiation to Square Matrices An Ad.pdf;/Users/doisinkidney/Zotero/storage/CJ887PD9/Okasaki - From Fast Exponentiation to Square Matrices An Ad.pdf;/Users/doisinkidney/Zotero/storage/CWBHZ7ZJ/Okasaki - From Fast Exponentiation to Square Matrices An Ad.pdf;/Users/doisinkidney/Zotero/storage/FUDZMXJC/Okasaki - From Fast Exponentiation to Square Matrices An Ad.pdf;/Users/doisinkidney/Zotero/storage/KUNSVH7E/Okasaki - From Fast Exponentiation to Square Matrices An Ad.pdf;/Users/doisinkidney/Zotero/storage/7PAEM9RB/citation.html;/Users/doisinkidney/Zotero/storage/BE6HVENT/summary.html;/Users/doisinkidney/Zotero/storage/EK75C6D7/cat.inist.fr.html;/Users/doisinkidney/Zotero/storage/PQFC4TKW/cat.inist.fr.html;/Users/doisinkidney/Zotero/storage/TPVFFHR9/cat.inist.fr.html}
}

@article{hutton_tutorial_1999,
  title = {A {{Tutorial}} on the {{Universality}} and {{Expressiveness}} of {{Fold}}},
  volume = {9},
  issn = {09567968},
  abstract = {In functional programming, fold is a standard operator that encapsulates a simple pattern of recursion for processing lists. This article is a tutorial on two key aspects of the fold operator for lists. First of all, we emphasize the use of the universal property of fold both as a proof principle that avoids the need for inductive proofs, and as a definition principle that guides the transformation of recursive functions into definitions using fold. Secondly, we show that even though the pattern of recursion encapsulated by fold is simple, in a language with tuples and functions as first-class values the fold operator has greater expressive power than might first be expected.},
  language = {en},
  number = {4},
  urldate = {2016-09-29},
  journal = {Journal of Functional Programming},
  doi = {10.1017/S0956796899003500},
  url = {http://www.cs.nott.ac.uk/~pszgmh/fold.pdf},
  author = {Hutton, Graham},
  year = {1999},
  pages = {355--372},
  file = {/Users/doisinkidney/Zotero/storage/AUIYTJFD/Hutton - 1999 - A tutorial on the universality and expressiveness .pdf;/Users/doisinkidney/Zotero/storage/XM59CHKC/HUTTON - 1999 - A tutorial on the universality and expressiveness .pdf}
}

@article{mcbride_applicative_2008,
  title = {Applicative Programming with Effects},
  volume = {18},
  number = {01},
  urldate = {2016-10-04},
  journal = {Journal of functional programming},
  url = {http://strictlypositive.org/Idiom.pdf},
  author = {McBride, Conor and Paterson, Ross},
  year = {2008},
  keywords = {Applicative Functors,Haskell},
  pages = {1--13},
  file = {/Users/doisinkidney/Zotero/storage/QXKBISRB/Applicative.pdf}
}

@article{borgstrom_lambda-calculus_2015,
  title = {A {{Lambda}}-{{Calculus Foundation}} for {{Universal Probabilistic Programming}}},
  journal = {arXiv preprint arXiv:1512.08990},
  url = {http://arxiv.org/pdf/1512.08990},
  author = {Borgstr\"om, Johannes and Lago, Ugo Dal and Gordon, Andrew D and Szymczak, Marcin},
  year = {2015},
  keywords = {Lambda Calculus,Probability},
  file = {/Users/doisinkidney/Zotero/storage/SC49EKF2/1512.08990.pdf}
}

@inproceedings{rivas_monoids_2015,
  title = {From Monoids to Near-Semirings: The Essence of {{MonadPlus}} and {{Alternative}}},
  isbn = {978-1-4503-3516-4},
  shorttitle = {From Monoids to Near-Semirings},
  abstract = {It is well-known that monads are monoids in the category of endo-functors, and in fact so are applicative functors. Unfortunately, the benefits of this unified view are lost when the additional non-determinism structure of |MonadPlus| or |Alternative| is required.

This article recovers the essence of these two type classes by extending monoids to near-semirings with both additive and multiplicative structure. This unified algebraic view enables us to generically define the free construction as well as a novel double Cayley representation that optimises both left-nested sums and left-nested products.},
  language = {en},
  urldate = {2016-11-23},
  booktitle = {Proceedings of the 17th {{International Symposium}} on {{Principles}} and {{Practice}} of {{Declarative Programming}}},
  publisher = {{ACM}},
  doi = {10.1145/2790449.2790514},
  url = {http://www.fceia.unr.edu.ar/~mauro/pubs/FromMonoidstoNearsemirings.pdf},
  author = {Rivas, Exequiel and Jaskelioff, Mauro and Schrijvers, Tom},
  year = {2015},
  pages = {196-207},
  file = {/Users/doisinkidney/Zotero/storage/TQ2SUXE7/Rivas et al. - From monoids to near-semirings the essence of Mon.pdf}
}

@article{brady_idris_2013,
  title = {Idris, a General-Purpose Dependently Typed Programming Language: {{Design}} and Implementation},
  volume = {23},
  issn = {1469-7653},
  number = {05},
  journal = {Journal of Functional Programming},
  doi = {10.1017/S095679681300018X},
  url = {http://journals.cambridge.org/article_S095679681300018X},
  author = {Brady, Edwin},
  month = sep,
  year = {2013},
  pages = {552--593},
  file = {/Users/doisinkidney/Zotero/storage/AJNPHXQQ/impldtp.pdf}
}

@book{kohlas_information_2003,
  address = {London ; New York},
  series = {Discrete Mathematics and Theoretical Computer Science},
  title = {Information Algebras: Generic Structures for Inference},
  isbn = {978-1-85233-689-9 978-1-4471-0009-6},
  lccn = {QA76.9.M35 K62 2003},
  shorttitle = {Information Algebras},
  language = {en},
  publisher = {{Springer}},
  url = {http://link.springer.com/10.1007/978-1-4471-0009-6},
  author = {Kohlas, J\"urg},
  year = {2003},
  keywords = {Algebra,Computer science,Mathematics,Information theory},
  doi = {10.1007/978-1-4471-0009-6}
}

@inproceedings{marlow_desugaring_2016,
  title = {Desugaring {{Haskell}}'s Do-Notation {{Into Applicative Operations}}},
  abstract = {Monads have taken the world by storm, and are supported by do-notation (at least in Haskell). Programmers are increasingly waking up to the usefulness and ubiquity of Applicatives, but they have so far been hampered by the absence of supporting notation. In this paper we show how to re-use the very same do-notation to work for Applicatives as well, providing efficiency benefits for some types that are both Monad and Applicative, and syntactic convenience for those that are merely Applicative. The result is fully implemented in GHC, and is in use at Facebook to make it easy to write highly-parallel queries in a distributed system.},
  url = {https://www.microsoft.com/en-us/research/publication/desugaring-haskells-do-notation-into-applicative-operations/},
  author = {Marlow, Simon and Peyton Jones, Simon and Kmett, Edward and Mokhov, Andrey},
  month = sep,
  year = {2016},
  file = {/Users/doisinkidney/Zotero/storage/9GBMQHNZ/desugaring-haskell-haskell16.pdf}
}

@article{belle_semiring_2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1609.06954},
  primaryClass = {cs},
  title = {Semiring {{Programming}}: {{A Framework}} for {{Search}}, {{Inference}} and {{Learning}}},
  shorttitle = {Semiring {{Programming}}},
  abstract = {To solve hard problems, AI relies on a variety of disciplines such as logic, probabilistic reasoning, machine learning and mathematical programming. Although it is widely accepted that solving real-world problems requires an integration amongst these, contemporary representation methodologies offer little support for this. In an attempt to alleviate this situation, we introduce a new declarative programming framework that provides abstractions of well-known problems such as SAT, Bayesian inference, generative models, and convex optimization. The semantics of programs is defined in terms of first-order structures with semiring labels, which allows us to freely combine and integrate problems from different AI disciplines.},
  urldate = {2017-03-04},
  journal = {arXiv:1609.06954 [cs]},
  url = {http://arxiv.org/abs/1609.06954},
  author = {Belle, Vaishak and De Raedt, Luc},
  month = sep,
  year = {2016},
  keywords = {Computer Science - Learning,Computer Science - Logic in Computer Science,Computer Science - Artificial Intelligence},
  file = {/Users/doisinkidney/Zotero/storage/RRWEF746/Belle and De Raedt - 2016 - Semiring Programming A Framework for Search, Infe.pdf;/Users/doisinkidney/Zotero/storage/TMCZHGRA/1609.html}
}

@phdthesis{eisenberg_dependent_2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1610.07978},
  title = {Dependent {{Types}} in {{Haskell}}: {{Theory}} and {{Practice}}},
  shorttitle = {Dependent {{Types}} in {{Haskell}}},
  abstract = {Haskell, as implemented in the Glasgow Haskell Compiler (GHC), has been adding new type-level programming features for some time. Many of these features---chiefly: generalized algebraic datatypes (GADTs), type families, kind polymorphism, and promoted datatypes---have brought Haskell to the doorstep of dependent types. Many dependently typed programs can even currently be encoded, but often the constructions are painful. In this dissertation, I describe Dependent Haskell, which supports full dependent types via a backward-compatible extension to today's Haskell. An important contribution of this work is an implementation, in GHC, of a portion of Dependent Haskell, with the rest to follow. The features I have implemented are already released, in GHC 8.0. This dissertation contains several practical examples of Dependent Haskell code, a full description of the differences between Dependent Haskell and today's Haskell, a novel type-safe dependently typed lambda-calculus (called Pico) suitable for use as an intermediate language for compiling Dependent Haskell, and a type inference and elaboration algorithm, Bake, that translates Dependent Haskell to type-correct Pico.},
  language = {en},
  urldate = {2017-03-04},
  school = {University of Pennsylvania},
  url = {https://github.com/goldfirere/thesis/raw/master/built/thesis.pdf},
  author = {Eisenberg, Richard A.},
  month = oct,
  year = {2016},
  keywords = {Computer Science - Programming Languages},
  file = {/Users/doisinkidney/Zotero/storage/NNSJJDCD/Eisenberg - Dependent Types in Haskell Theory and Practice.pdf;/Users/doisinkidney/Zotero/storage/SMC3TBG8/Eisenberg - 2016 - Dependent Types in Haskell Theory and Practice.pdf;/Users/doisinkidney/Zotero/storage/M9UDD9JG/1610.html;/Users/doisinkidney/Zotero/storage/XTQICH4T/summary.html}
}

@article{gibbons_metamorphisms_2007,
  title = {Metamorphisms: {{Streaming Representation}}-{{Changers}}},
  volume = {65},
  abstract = {Unfolds generate data structures, and folds consume them. A hylomorphism is a fold after an unfold, generating then consuming a virtual data structure. A metamorphism is the opposite composition, an unfold after a fold; typically, it will convert from one data representation to another. In general, metamorphisms are less interesting than hylomorphisms: there is no automatic fusion to deforest the intermediate virtual data structure. However, under certain conditions fusion is possible: some of the work of the unfold can be done before all of the work of the fold is complete. This permits streaming metamorphisms, and among other things allows conversion of infinite data representations. We present a theory of metamorphisms and outline some examples.},
  language = {en},
  number = {2},
  journal = {Science of Computer Programming},
  doi = {10.1016/j.scico.2006.01.006},
  url = {http://www.comlab.ox.ac.uk/oucl/work/jeremy.gibbons/publications/metamorphisms-scp.pdf},
  author = {Gibbons, Jeremy},
  year = {2007},
  pages = {108-139},
  file = {/Users/doisinkidney/Zotero/storage/DXL5Y9FC/Gibbons - Metamorphisms Streaming Representation-Changers.pdf}
}

@article{haenni_ordered_2004,
  title = {Ordered Valuation Algebras: A Generic Framework for Approximating Inference},
  volume = {37},
  issn = {0888-613X},
  shorttitle = {Ordered Valuation Algebras},
  abstract = {The paper presents a generic approach of approximating inference. The method is based on the concept of valuation algebras with its wide range of possible applications in many different domains. We present convenient resource-bounded anytime algorithms, where the maximal time of computation is determined by the user.},
  number = {1},
  urldate = {2017-03-28},
  journal = {International Journal of Approximate Reasoning},
  doi = {10.1016/j.ijar.2003.10.009},
  url = {http://www.sciencedirect.com/science/article/pii/S0888613X03001476},
  author = {Haenni, Rolf},
  month = aug,
  year = {2004},
  keywords = {Approximation,Anytime algorithms,Resource-bounded computation,Valuation algebras,Local computation,Binary join trees,Bucket elimination,Mini-buckets},
  pages = {1-41},
  file = {/Users/doisinkidney/Zotero/storage/AH2XENZQ/Haenni - 2004 - Ordered valuation algebras a generic framework fo.pdf;/Users/doisinkidney/Zotero/storage/U4NAUTDT/S0888613X03001476.html}
}

@incollection{kohlas_computation_2000,
  series = {Handbook of {{Defeasible Reasoning}} and {{Uncertainty Management Systems}}},
  title = {Computation in {{Valuation Algebras}}},
  copyright = {\textcopyright{}2000 Springer Science+Business Media Dordrecht},
  isbn = {978-90-481-5603-0 978-94-017-1737-3},
  abstract = {The main goal of this chapter is to describe an abstract framework called valuation algebra for computing marginals using local computation. The valuation algebra framework is useful in many domains, and especially for managing uncertainty in expert systems using probability, Dempster-Shafer belief functions, Spohnian epistemic belief theory, and possibility theory.},
  language = {en},
  number = {5},
  urldate = {2017-03-28},
  booktitle = {Handbook of {{Defeasible Reasoning}} and {{Uncertainty Management Systems}}},
  publisher = {{Springer Netherlands}},
  url = {https://www.researchgate.net/profile/Prakash_Shenoy/publication/2846681_Computation_in_Valuation_Algebras/links/09e41510982ec35920000000.pdf},
  author = {Kohlas, J\"urg and Shenoy, Prakash P.},
  editor = {Kohlas, J\"urg and Moral, Seraf\'in},
  year = {2000},
  keywords = {Artificial Intelligence (incl. Robotics),Logic,Mathematical Logic and Foundations,Programming Languages; Compilers; Interpreters,Theory of Computation},
  pages = {5-39},
  file = {/Users/doisinkidney/Zotero/storage/A8IAQV8Z/download.pdf},
  doi = {10.1007/978-94-017-1737-3_2}
}

@article{kohlas_semiring_2008,
  title = {Semiring {{Induced Valuation Algebras}}: {{Exact}} and {{Approximate Local Computation Algorithms}}},
  volume = {172},
  issn = {0004-3702},
  shorttitle = {Semiring {{Induced Valuation Algebras}}},
  abstract = {Local computation in join trees or acyclic hypertrees has been shown to be linked to a particular algebraic structure, called valuation algebra. There are many models of this algebraic structure ranging from probability theory to numerical analysis, relational databases and various classical and non-classical logics. It turns out that many interesting models of valuation algebras may be derived from semiring valued mappings. In this paper we study how valuation algebras are induced by semirings and how the structure of the valuation algebra is related to the algebraic structure of the semiring. In particular, c-semirings with idempotent multiplication induce idempotent valuation algebras and therefore permit particularly efficient architectures for local computation. Also important are semirings whose multiplicative semigroup is embedded in a union of groups. They induce valuation algebras with a partially defined division. For these valuation algebras, the well-known architectures for Bayesian networks apply. We also extend the general computational framework to allow derivation of bounds and approximations, for when exact computation is not feasible.},
  number = {11},
  urldate = {2017-03-28},
  journal = {Artificial Intelligence},
  doi = {10.1016/j.artint.2008.03.003},
  url = {http://4c.ucc.ie/web/upload/publications/jourart/Kohlas_Wilson_aij.pdf},
  author = {Kohlas, Juerg and Wilson, Nic},
  month = jul,
  year = {2008},
  keywords = {Join tree decompositions,Local computation,Semirings,Soft constraints,Uncertainty,Valuation algebras,Valuation networks},
  pages = {1360--1399},
  file = {/Users/doisinkidney/Zotero/storage/RXZXM9GX/Kohlasa and Wilsonb - 2008 - Semiring induced valuation algebras Exact and app.pdf}
}

@article{pouly_nenok_2010,
  title = {Nenok \textemdash{} a Software Architecture for Generic Inference},
  volume = {19},
  issn = {0218-2130},
  abstract = {Computing inference from a given knowledgebase is one of the key competences of computer science. Therefore, numerous formalisms and specialized inference routines have been introduced and implemented for this task. Typical examples are Bayesian networks, constraint systems or different kinds of logic. It is known today that these formalisms can be unified under a common algebraic roof called valuation algebra. Based on this system, generic inference algorithms for the processing of arbitrary valuation algebras can be defined. Researchers benefit from this high level of abstraction to address open problems independently of the underlying formalism. It is therefore all the more astonishing that this theory did not find its way into concrete software projects. Indeed, all modern programming languages for example provide generic sorting procedures, but generic inference algorithms are still mythical creatures. NENOK breaks a new ground and offers an extensive library of generic inference tools based on the valuation algebra framework. All methods are implemented as distributed algorithms that process local and remote knowledgebases in a transparent manner. Besides its main purpose as software library, NENOK also provides a sophisticated graphical user interface to inspect the inference process and the involved graphical structures. This can be used for educational purposes but also as a fast prototyping architecture for inference formalisms.},
  language = {en},
  number = {01},
  urldate = {2017-03-28},
  journal = {International Journal on Artificial Intelligence Tools},
  doi = {10.1142/S0218213010000042},
  url = {https://pdfs.semanticscholar.org/5293/6aa092bda3286877ee7e5ae214974987f749.pdf},
  author = {Pouly, Marc},
  month = feb,
  year = {2010},
  pages = {65-99},
  file = {/Users/doisinkidney/Zotero/storage/KGBVM4WI/6aa092bda3286877ee7e5ae214974987f749.pdf;/Users/doisinkidney/Zotero/storage/QNG7WXAK/S0218213010000042.html}
}

@article{hughes_novel_1986,
  title = {A {{Novel Representation}} of {{Lists}} and {{Its Application}} to the {{Function}} "{{Reverse}}"},
  volume = {22},
  issn = {0020-0190},
  abstract = {A representation of lists as first-class functions is proposed. Lists represented in this way can be appended together in constant time, and can be converted back into ordinary lists in time proportional to their length. Programs which construct lists using append can often be improved by using this representation. For example, naive reverse can be made to run in linear time, and the conventional `fast reverse' can then be derived easily. Examples are given in KRC (Turner, 1982), the notation being explained as it is introduced. The method can be compared to Sleep and Holmstr\"om's proposal (1982) to achieve a similar effect by a change to the interpreter.},
  number = {3},
  urldate = {2017-03-29},
  journal = {Information Processing Letters},
  doi = {10.1016/0020-0190(86)90059-1},
  url = {http://www.sciencedirect.com/science/article/pii/0020019086900591},
  author = {Hughes, R. John Muir},
  month = mar,
  year = {1986},
  keywords = {Functional programming,list processing,data representation,program transformation},
  pages = {141-144},
  file = {/Users/doisinkidney/Zotero/storage/IQA7SPXE/HUGHES - 1986 - A NOVEL REPRESENTATION OF LISTS AND ITS APPLICATIO.pdf;/Users/doisinkidney/Zotero/storage/8P27M66X/cat.inist.fr.html;/Users/doisinkidney/Zotero/storage/AK25BD8T/12ab75d7ff381f78527f8856b21c8e08.html;/Users/doisinkidney/Zotero/storage/BWARFEHM/80002852960.html;/Users/doisinkidney/Zotero/storage/CU3K6JUB/0020019086900591.html;/Users/doisinkidney/Zotero/storage/EIUWC5DK/0020019086900591.html;/Users/doisinkidney/Zotero/storage/FTXR2SAT/citation.html;/Users/doisinkidney/Zotero/storage/KHCHNSQT/12ab75d7ff381f78527f8856b21c8e08.html}
}

@techreport{hinze_numerical_1998,
  title = {Numerical {{Representations}} as {{Higher}}-{{Order Nested Datatypes}}},
  abstract = {Number systems serve admirably as templates for container types: a container object of size n is modelled after the representation of the number n and operations on container objects are modelled after their number-theoretic counterparts. Binomial queues are probably the first data structure that was designed with this analogy in mind. In this paper we show how to express these so-called numerical representations as higher-order nested datatypes. A nested datatype allows to capture the structural invariants of a numerical representation, so that the violation of an invariant can be detected at compile-time. We develop a programming method which allows to adapt algorithms to the new representation in a mostly straightforward manner. The framework is employed to implement three different container types: binary random-access lists, binomial queues, and 2-3 finger search trees. The latter data structure, which is treated in some depth, can be seen as the main innovation from a data-struct...},
  number = {IAI-TR-98-12},
  institution = {{Institut f\"ur Informatik III, Universit\"at Bonn}},
  url = {http://www.cs.ox.ac.uk/ralf.hinze/publications/\#R5},
  author = {Hinze, Ralf},
  month = dec,
  year = {1998},
  file = {/Users/doisinkidney/Zotero/storage/PHIN9HWW/Hinze - 1998 - Numerical Representations as Higher-Order Nested D.pdf;/Users/doisinkidney/Zotero/storage/EDDJFGES/summary.html}
}

@article{claessen_quickcheck_2011,
  title = {{{QuickCheck}}: {{A Lightweight Tool}} for {{Random Testing}} of {{Haskell Programs}}},
  volume = {46},
  issn = {0362-1340},
  shorttitle = {{{QuickCheck}}},
  abstract = {QuickCheck is a tool which aids the Haskell programmer in formulating and testing properties of programs. Properties are discribed as Haskell functions, and can be automatically tested on random input, but it is also possible to define custom test data generators. We present a number of case studies, in which the tool was successfully used, and also point out some pitfalls to avoid. Random testing is especially suitable for functional programs because properties can be stated at a fine grain. When a function is built from separately tested components, then random testing suffuces to obtain good coverage of the definition under test.},
  number = {4},
  urldate = {2017-06-28},
  journal = {SIGPLAN Not.},
  doi = {10.1145/1988042.1988046},
  url = {https://pdfs.semanticscholar.org/f8a3/f613080f69d4d3e005f0133c64d44a5bb902.pdf},
  author = {Claessen, Koen and Hughes, John},
  month = may,
  year = {2011},
  pages = {53--64},
  file = {/Users/doisinkidney/Zotero/storage/2CXEEKFA/f613080f69d4d3e005f0133c64d44a5bb902.pdf}
}

@article{hedges_monad_2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1406.2058},
  title = {Monad {{Transformers}} for {{Backtracking Search}}},
  volume = {153},
  issn = {2075-2180},
  abstract = {This paper extends Escardo and Oliva's selection monad to the selection monad transformer, a general monadic framework for expressing backtracking search algorithms in Haskell. The use of the closely related continuation monad transformer for similar purposes is also discussed, including an implementation of a DPLL-like SAT solver with no explicit recursion. Continuing a line of work exploring connections between selection functions and game theory, we use the selection monad transformer with the nondeterminism monad to obtain an intuitive notion of backward induction for a certain class of nondeterministic games.},
  urldate = {2017-10-10},
  journal = {Electronic Proceedings in Theoretical Computer Science},
  doi = {10.4204/EPTCS.153.3},
  url = {http://arxiv.org/abs/1406.2058},
  author = {Hedges, Jules},
  month = jun,
  year = {2014},
  keywords = {Computer Science - Programming Languages},
  pages = {31-50},
  file = {/Users/doisinkidney/Zotero/storage/4QCWHYME/Hedges - 2014 - Monad Transformers for Backtracking Search.pdf;/Users/doisinkidney/Zotero/storage/9RNYYLQD/Hedges - Monad Transformers for Backtracking Search.pdf;/Users/doisinkidney/Zotero/storage/EZ6S5B6Q/Hedges - 2014 - Monad Transformers for Backtracking Search.pdf;/Users/doisinkidney/Zotero/storage/Y6IIWXHS/Hedges - 2014 - Monad Transformers for Backtracking Search.pdf;/Users/doisinkidney/Zotero/storage/5Q4QG32M/1406.html;/Users/doisinkidney/Zotero/storage/A8QMHMTR/1406.html;/Users/doisinkidney/Zotero/storage/GYEKLDBX/paper.html}
}

@inproceedings{kiselyov_backtracking_2005,
  address = {New York, NY, USA},
  series = {{{ICFP}} '05},
  title = {Backtracking, {{Interleaving}}, and {{Terminating Monad Transformers}}: ({{Functional Pearl}})},
  isbn = {978-1-59593-064-4},
  shorttitle = {Backtracking, {{Interleaving}}, and {{Terminating Monad Transformers}}},
  abstract = {We design and implement a library for adding backtracking computations to any Haskell monad. Inspired by logic programming, our library provides, in addition to the operations required by the MonadPlus interface, constructs for fair disjunctions, fair conjunctions, conditionals, pruning, and an expressive top-level interface. Implementing these additional constructs is easy in models of backtracking based on streams, but not known to be possible in continuation-based models. We show that all these additional constructs can be generically and monadically realized using a single primitive msplit. We present two implementations of the library: one using success and failure continuations; and the other using control operators for manipulating delimited continuations.},
  urldate = {2017-10-10},
  booktitle = {Proceedings of the {{Tenth ACM SIGPLAN International Conference}} on {{Functional Programming}}},
  publisher = {{ACM}},
  doi = {10.1145/1086365.1086390},
  url = {http://okmij.org/ftp/Computation/monads.html\#LogicT},
  author = {Kiselyov, Oleg and Shan, Chung-chieh and Friedman, Daniel P. and Sabry, Amr},
  year = {2005},
  keywords = {Backtracking,continuations,control delimiters,Haskell,HASKELL,Logic Monad,logic programming,Prolog,streams},
  pages = {192--203},
  file = {/Users/doisinkidney/Zotero/storage/5MZ2N74Z/LogicT.pdf;/Users/doisinkidney/Zotero/storage/AEDCPH4V/1dceb887ebbe0a16fa650a07d008ed62d96c.pdf}
}

@incollection{spivey_combinators_2003,
  series = {Cornerstones in {{Computing}}},
  title = {Combinators for Logic Programming},
  booktitle = {The {{Fun}} of {{Programming}}},
  publisher = {{Palgrave}},
  url = {https://www.cs.ox.ac.uk/publications/books/fop/dist/fop/chapters/9/Logic.hs},
  author = {Spivey, J. Michael and Seres, Silvija},
  month = mar,
  year = {2003},
  file = {/Users/doisinkidney/Zotero/storage/QVIRPZJZ/Logic.hs}
}

@article{spivey_algebras_2009,
  title = {Algebras for Combinatorial Search},
  volume = {19},
  issn = {1469-7653, 0956-7968},
  abstract = {AbstractCombinatorial search strategies including depth-first, breadth-first and depth-bounded search are shown to be different implementations of a common algebraic specification that emphasizes the compositionality of the strategies. This specification is placed in a categorical setting that combines algebraic specifications and monads.},
  number = {3-4},
  urldate = {2017-10-13},
  journal = {Journal of Functional Programming},
  doi = {10.1017/S0956796809007321},
  url = {https://pdfs.semanticscholar.org/db3e/373bb6e7e7837ebc524da0a25903958554ed.pdf},
  author = {Spivey, J. Michael},
  month = jul,
  year = {2009},
  pages = {469-487},
  file = {/Users/doisinkidney/Zotero/storage/RJBV6ADB/373bb6e7e7837ebc524da0a25903958554ed.pdf;/Users/doisinkidney/Zotero/storage/HVBMPBM2/AB57FF99CEA76C1C31A336B560D6FD3C.html}
}

@inproceedings{barthe_differentially_2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1605.00283},
  address = {New York, NY, USA},
  series = {{{CCS}} '16},
  title = {Differentially {{Private Bayesian Programming}}},
  isbn = {978-1-4503-4139-4},
  abstract = {We present PrivInfer, an expressive framework for writing and verifying differentially private Bayesian machine learning algorithms. Programs in PrivInfer are written in a rich functional probabilistic programming language with constructs for performing Bayesian inference. Then, differential privacy of programs is established using a relational refinement type system, in which refinements on probability types are indexed by a metric on distributions. Our framework leverages recent developments in Bayesian inference, probabilistic programming languages, and in relational refinement types. We demonstrate the expressiveness of PrivInfer by verifying privacy for several examples of private Bayesian inference.},
  urldate = {2018-01-06},
  booktitle = {Proceedings of the 2016 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  publisher = {{ACM}},
  doi = {10.1145/2976749.2978371},
  url = {http://doi.acm.org/10.1145/2976749.2978371},
  author = {Barthe, Gilles and Farina, Gian Pietro and Gaboardi, Marco and Arias, Emilio Jesus Gallego and Gordon, Andy and Hsu, Justin and Strub, Pierre-Yves},
  year = {2016},
  keywords = {Computer Science - Programming Languages,probabilistic programming,differential privacy,type systems,Bayesian learning},
  pages = {68--79},
  file = {/Users/doisinkidney/Zotero/storage/6IFIVMWR/Barthe et al. - 2016 - Differentially Private Bayesian Programming.pdf;/Users/doisinkidney/Zotero/storage/S2KUUPVY/Barthe et al. - 2016 - Differentially Private Bayesian Programming.pdf;/Users/doisinkidney/Zotero/storage/2XRQSVE6/1605.html}
}

@inproceedings{audebaud_zippy_2008,
  address = {Berlin, Heidelberg},
  series = {{{MPC}} '08},
  title = {Zippy {{Tabulations}} of {{Recursive Functions}}},
  volume = {5133},
  isbn = {978-3-540-70593-2 978-3-540-70594-9},
  abstract = {This paper is devoted to the statement and proof of a theorem showing how recursive definitions whose associated call graphs satisfy certain shape conditions can be converted systematically into efficient bottom-up tabulation schemes. The increase in efficiency can be dramatic, typically transforming an exponential time algorithm into one that takes only quadratic time. The proof of the theorem relies heavily on the theory of zips developed by Roland Backhouse and Paul Hoogendijk.},
  language = {en},
  urldate = {2018-02-16},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  doi = {10.1007/978-3-540-70594-9_7},
  url = {http://link.springer.com/10.1007/978-3-540-70594-9_7},
  author = {Bird, Richard S.},
  editor = {Audebaud, Philippe and {Paulin-Mohring}, Christine},
  year = {2008},
  keywords = {Binomial Tree,Boolean Lattice,Call Graph,Decomposition Function,Recursive Function},
  pages = {92-109},
  file = {/Users/doisinkidney/Zotero/storage/GFGND65P/Bird - 2008 - Zippy Tabulations of Recursive Functions.pdf}
}

@article{mu_theory_2004,
  series = {Mathematics of {{Program Construction}} ({{MPC}} 2002)},
  title = {Theory and Applications of Inverting Functions as Folds},
  volume = {51},
  issn = {0167-6423},
  abstract = {This paper is devoted to the proof, applications, and generalisation of a theorem, due to Bird and de Moor, that gave conditions under which a total function can be expressed as a relational fold. The theorem is illustrated with three problems, all dealing with constructing trees with various properties. It is then generalised to give conditions under which the inverse of a partial function can be expressed as a relational hylomorphism. Its proof makes use of Doornbos and Backhouse's theory on well-foundedness and reductivity. Possible applications of the generalised theorem is discussed.},
  language = {en},
  number = {1},
  urldate = {2018-02-17},
  journal = {Science of Computer Programming},
  doi = {10.1016/j.scico.2003.09.003},
  url = {http://www.sciencedirect.com/science/article/pii/S0167642304000140},
  author = {Mu, Shin-Cheng and Bird, Richard},
  month = may,
  year = {2004},
  keywords = {Fold,Program derivation,Program inversion},
  pages = {87-116},
  file = {/Users/doisinkidney/Zotero/storage/3BIIK589/Mu and Bird - 2004 - Theory and applications of inverting functions as .pdf;/Users/doisinkidney/Zotero/storage/847R7SZS/Mu and Bird - 2004 - Theory and applications of inverting functions as .pdf;/Users/doisinkidney/Zotero/storage/2YTKFEZQ/S0167642304000140.html}
}

@article{rivas_notions_2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1406.4823},
  primaryClass = {cs, math},
  title = {Notions of {{Computation}} as {{Monoids}}},
  abstract = {There are different notions of computation, the most popular being monads, applicative functors, and arrows. In this article we show that these three notions can be seen as monoids in a monoidal category. We demonstrate that at this level of abstraction one can obtain useful results which can be instantiated to the different notions of computation. In particular, we show how free constructions and Cayley representations for monoids translate into useful constructions for monads, applicative functors, and arrows. Moreover, the uniform presentation of all three notions helps in the analysis of the relation between them.},
  urldate = {2018-02-17},
  journal = {arXiv:1406.4823 [cs, math]},
  url = {http://arxiv.org/abs/1406.4823},
  author = {Rivas, Exequiel and Jaskelioff, Mauro},
  month = may,
  year = {2014},
  keywords = {Computer Science - Logic in Computer Science,Computer Science - Programming Languages,Mathematics - Category Theory},
  file = {/Users/doisinkidney/Zotero/storage/J5IDJB2E/Rivas and Jaskelioff - 2014 - Notions of Computation as Monoids.pdf;/Users/doisinkidney/Zotero/storage/JU7AH2B5/RIVAS and JASKELIOFF - Notions of Computation as Monoids.pdf;/Users/doisinkidney/Zotero/storage/CY5HTMIJ/1406.html}
}

@inproceedings{hinze_kan_2012,
  address = {Berlin, Heidelberg},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Kan {{Extensions}} for {{Program Optimisation}} or: {{Art}} and {{Dan Explain}} an {{Old Trick}}},
  isbn = {978-3-642-31112-3 978-3-642-31113-0},
  shorttitle = {Kan {{Extensions}} for {{Program Optimisation}}},
  abstract = {Many program optimisations involve transforming a program in direct style to an equivalent program in continuation-passing style. This paper investigates the theoretical underpinnings of this transformation in the categorical setting of monads. We argue that so-called absolute Kan Extensions underlie this program optimisation. It is known that every Kan extension gives rise to a monad, the codensity monad, and furthermore that every monad is isomorphic to a codensity monad. The end formula for Kan extensions then induces an implementation of the monad, which can be seen as the categorical counterpart of continuation-passing style. We show that several optimisations are instances of this scheme: Church representations and implementation of backtracking using success and failure continuations, among others. Furthermore, we develop the calculational properties of Kan extensions, powers and ends. In particular, we propose a two-dimensional notation based on string diagrams that aims to support effective reasoning with Kan extensions.},
  language = {en},
  urldate = {2018-02-17},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer, Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-31113-0_16},
  url = {https://www.cs.ox.ac.uk/ralf.hinze/Kan.pdf},
  author = {Hinze, Ralf},
  month = jun,
  year = {2012},
  keywords = {Haskell,adjunction,backtracking,Church representation,codensity monad,CPS,end,Kan extension,power,string diagram},
  pages = {324-362},
  file = {/Users/doisinkidney/Zotero/storage/MSYEY5CW/Hinze - 2012 - Kan Extensions for Program Optimisation or Art an.pdf;/Users/doisinkidney/Zotero/storage/WMDNAZEF/Hinze - 2012 - Kan Extensions for Program Optimisation Or Art an.pdf;/Users/doisinkidney/Zotero/storage/SZHP4974/978-3-642-31113-0_16.html}
}

@inproceedings{voigtlander_asymptotic_2008,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Asymptotic {{Improvement}} of {{Computations}} over {{Free Monads}}},
  volume = {5133},
  isbn = {978-3-540-70593-2 978-3-540-70594-9},
  abstract = {We present a low-effort program transformation to improve the efficiency of computations over free monads in Haskell. The development is calculational and carried out in a generic setting, thus applying to a variety of datatypes. An important aspect of our approach is the utilisation of type class mechanisms to make the transformation as transparent as possible, requiring no restructuring of code at all. There is also no extra support necessary from the compiler (apart from an up-to-date type checker). Despite this simplicity of use, our technique is able to achieve true asymptotic runtime improvements. We demonstrate this by examples for which the complexity is reduced from quadratic to linear.},
  language = {en},
  urldate = {2018-02-17},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer, Berlin, Heidelberg}},
  doi = {10.1007/978-3-540-70594-9_20},
  url = {http://www.janis-voigtlaender.eu/papers/AsymptoticImprovementOfComputationsOverFreeMonads.pdf},
  author = {Voigtl\"ander, Janis},
  month = jul,
  year = {2008},
  keywords = {Functional Programming,Type Constructor,Fusion Rule,Program Transformation,Type Checker},
  pages = {388-403},
  file = {/Users/doisinkidney/Zotero/storage/4W9G5XDN/AsymptoticImprovementOfComputationsOverFreeMonads.pdf;/Users/doisinkidney/Zotero/storage/92LILNR6/Voigtländer - 2008 - Asymptotic Improvement of Computations over Free M.pdf;/Users/doisinkidney/Zotero/storage/SX4SA6WU/AsymptoticImprovementOfComputationsOverFreeMonads.pdf;/Users/doisinkidney/Zotero/storage/ZCC7QJSM/978-3-540-70594-9_20.html}
}

@misc{bakst_liquidhaskell_2018,
  title = {{{LiquidHaskell}}: {{Liquid Types For Haskell}}},
  shorttitle = {{{LiquidHaskell}}},
  urldate = {2018-02-19},
  howpublished = {ucsd-progsys},
  url = {https://github.com/ucsd-progsys/liquidhaskell},
  author = {Bakst, Alexander and Jhala, Ranjit and Kawaguchi, Ming and Rondon, Patrick and Seidel, Eric and Smith, Michael and Tondwalkar, Anish and Tetreault, Chris and Vazou, Niki},
  month = feb,
  year = {2018}
}

@inproceedings{goos_rebuilding_2003,
  address = {Berlin, Heidelberg},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Rebuilding a {{Tree}} from {{Its Traversals}}},
  volume = {2895},
  isbn = {978-3-540-20536-4 978-3-540-40018-9},
  shorttitle = {Rebuilding a {{Tree}} from {{Its Traversals}}},
  abstract = {Given the inorder and preorder traversal of a binary tree whose labels are all distinct, one can reconstruct the tree. This article examines two existing algorithms for rebuilding the tree in a functional framework, using existing theory on function inversion. We also present a new, although complicated, algorithm by trying another possibility not explored before.},
  language = {en},
  urldate = {2018-03-14},
  booktitle = {Programming {{Languages}} and {{Systems}}},
  publisher = {{Springer Berlin Heidelberg}},
  url = {http://link.springer.com/10.1007/978-3-540-40018-9_18},
  author = {Mu, Shin-Cheng and Bird, Richard},
  editor = {Goos, Gerhard and Hartmanis, Juris and {van Leeuwen}, Jan and Ohori, Atsushi},
  year = {2003},
  keywords = {Binary Tree,Function Inversion,Functional Inverse,Program Inversion,Spine Representation},
  pages = {265-282},
  file = {/Users/doisinkidney/Zotero/storage/KIH6JYTC/Mu and Bird - 2003 - Rebuilding a Tree from Its Traversals.pdf;/Users/doisinkidney/Zotero/storage/NBSEZER7/Mu and Bird - 2003 - Rebuilding a Tree from Its Traversals.pdf},
  doi = {10.1007/978-3-540-40018-9_18}
}

@inproceedings{jones_call-pattern_2007,
  title = {Call-Pattern Specialisation for Haskell Programs},
  isbn = {978-1-59593-815-2},
  abstract = {User-defined data types, pattern-matching, and recursion are ubiquitous features of Haskell programs. Sometimes a function is called with arguments that are statically known to be in constructor form, so that the work of pattern-matching is wasted. Even worse, the argument is sometimes freshly-allocated, only to be immediately decomposed by the function.},
  language = {en},
  urldate = {2018-03-21},
  publisher = {{ACM Press}},
  doi = {10.1145/1291151.1291200},
  url = {https://www.microsoft.com/en-us/research/publication/system-f-with-type-equality-coercions-2/},
  author = {Jones, Simon Peyton},
  year = {2007},
  pages = {327},
  file = {/Users/doisinkidney/Zotero/storage/JMQ9HUQK/Jones - 2007 - Call-pattern specialisation for haskell programs.pdf;/Users/doisinkidney/Zotero/storage/MBT8QXM2/Jones - 2007 - Call-pattern specialisation for Haskell programs.pdf;/Users/doisinkidney/Zotero/storage/U38CF3T4/system-f-with-type-equality-coercions-2.html}
}

@article{Hinze-Paterson:FingerTree,
  title = {Finger {{Trees}}: {{A Simple General}}-Purpose {{Data Structure}}},
  volume = {16},
  abstract = {We introduce 2-3 finger trees, a functional representation of persistent sequences supporting access to the ends in amortized constant time, and concatenation and splitting in time logarithmic in the size of the smaller piece. Representations achieving these bounds have appeared previously, but 2-3 finger trees are much simpler, as are the operations on them. Further, by defining the split operation in a general form, we obtain a general purpose data structure that can serve as a sequence, priority queue, search tree, priority search queue and more.},
  language = {en},
  number = {2},
  journal = {Journal of Functional Programming},
  url = {http://www.staff.city.ac.uk/~ross/papers/FingerTree.html},
  author = {Hinze, Ralf and Paterson, Ross},
  year = {2006},
  pages = {197--217},
  file = {/Users/doisinkidney/Zotero/storage/A5GHFDGK/HINZE - Finger trees a simple general-purpose data struct.pdf;/Users/doisinkidney/Zotero/storage/ZY9YJPT9/HINZE - Finger trees a simple general-purpose data struct.pdf}
}

@article{mcbride_ornamental_2010,
  title = {Ornamental {{Algebras}}, {{Algebraic Ornaments}}},
  abstract = {This paper re-examines the presentation of datatypes in dependently typed languages, addressing in particular the issue of what it means for one datatype to be in various ways more informative than another. Informal human observations like `lists are natural numbers with extra labels' and `vectors are lists indexed by length' are expressed in a first class language of ornaments\textemdash{}presentations of fancy new types based on plain old ones.},
  language = {en},
  author = {McBride, Conor},
  year = {2010},
  pages = {8},
  file = {/Users/doisinkidney/Zotero/storage/34NGW93J/McBRIDE - 2010 - Ornamental Algebras, Algebraic Ornaments.pdf;/Users/doisinkidney/Zotero/storage/ZGWGNNDW/McBRIDE - 2011 - Ornamental Algebras, Algebraic Ornaments.pdf}
}

@inproceedings{hinze_polynomial_2015,
  address = {Cham},
  title = {Polynomial {{Functors Constrained}} by {{Regular Expressions}}},
  volume = {9129},
  isbn = {978-3-319-19796-8 978-3-319-19797-5},
  abstract = {We show that every regular language, via some DFA which accepts it, gives rise to a homomorphism from the semiring of polynomial functors to the semiring of n\texttimes{}n matrices over polynomial functors. Given some polynomial functor and a regular language, this homomorphism can be used to automatically derive a functor whose values have the same shape as those of the original functor, but whose sequences of leaf types correspond to strings in the language.},
  language = {en},
  urldate = {2018-06-11},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer International Publishing}},
  url = {http://link.springer.com/10.1007/978-3-319-19797-5_6},
  author = {Piponi, Dan and Yorgey, Brent A.},
  editor = {Hinze, Ralf and Voigtl\"ander, Janis},
  year = {2015},
  keywords = {Differentiation,Dissection,Functors,Polynomial,Regular expressions},
  pages = {113-136},
  file = {/Users/doisinkidney/Zotero/storage/4VCB4Y6R/Piponi and Yorgey - 2015 - Polynomial Functors Constrained by Regular Express.pdf;/Users/doisinkidney/Zotero/storage/53JY7SI2/Piponi and Yorgey - 2015 - Polynomial Functors Constrained by Regular Express.pdf;/Users/doisinkidney/Zotero/storage/HQHG5UAY/Piponi and Yorgey - 2015 - Polynomial Functors Constrained by Regular Express.pdf},
  doi = {10.1007/978-3-319-19797-5_6}
}

@inproceedings{goncharov_kleene_2009,
  address = {Berlin, Heidelberg},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Kleene {{Monads}}: {{Handling Iteration}} in a {{Framework}} of {{Generic Effects}}},
  volume = {5728},
  isbn = {978-3-642-03740-5 978-3-642-03741-2},
  shorttitle = {Kleene {{Monads}}},
  abstract = {Monads are a well-established tool for modelling various computational effects. They form the semantic basis of Moggi's computational metalanguage, the metalanguage of effects for short, which made its way into modern functional programming in the shape of Haskell's do-notation. Standard computational idioms call for specific classes of monads that support additional control operations. Here, we introduce Kleene monads, which additionally feature nondeterministic choice and Kleene star, i.e. nondeterministic iteration, and we provide a metalanguage and a sound calculus for Kleene monads, the metalanguage of control and effects, which is the natural joint extension of Kleene algebra and the metalanguage of effects. This provides a framework for studying abstract program equality focussing on iteration and effects. These aspects are known to have decidable equational theories when studied in isolation. However, it is well known that decidability breaks easily; e.g. the Horn theory of continuous Kleene algebras fails to be recursively enumerable. Here, we prove several negative results for the metalanguage of control and effects; in particular, already the equational theory of the unrestricted metalanguage of control and effects over continuous Kleene monads fails to be recursively enumerable. We proceed to identify a fragment of this language which still contains both Kleene algebra and the metalanguage of effects and for which the natural axiomatisation is complete, and indeed the equational theory is decidable.},
  language = {en},
  urldate = {2018-06-13},
  booktitle = {Algebra and {{Coalgebra}} in {{Computer Science}}},
  publisher = {{Springer, Berlin, Heidelberg}},
  url = {https://link.springer.com/chapter/10.1007/978-3-642-03741-2_3},
  author = {Goncharov, Sergey and Schr\"oder, Lutz and Mossakowski, Till},
  month = sep,
  year = {2009},
  keywords = {Dynamic Logic,Equational Theory,Horn Theory,Nondeterministic Choice,Regular Program},
  pages = {18-33},
  file = {/Users/doisinkidney/Zotero/storage/68U996LY/09e415130cd1669506000000.pdf;/Users/doisinkidney/Zotero/storage/GWKZ6L66/Goncharov et al. - 2009 - Kleene Monads Handling Iteration in a Framework o.pdf;/Users/doisinkidney/Zotero/storage/PPB2ZME9/Goncharov et al. - 2009 - Kleene Monads Handling Iteration in a Framework o.pdf;/Users/doisinkidney/Zotero/storage/VZV8IVIG/978-3-642-03741-2_3.html},
  doi = {10.1007/978-3-642-03741-2_3}
}

@inproceedings{altenkirch_partiality_2017,
  address = {Berlin, Heidelberg},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Partiality, {{Revisited}}},
  volume = {10203},
  isbn = {978-3-662-54457-0 978-3-662-54458-7},
  abstract = {Capretta's delay monad can be used to model partial computations, but it has the ``wrong'' notion of built-in equality, strong bisimilarity. An alternative is to quotient the delay monad by the ``right'' notion of equality, weak bisimilarity. However, recent work by Chapman et al. suggests that it is impossible to define a monad structure on the resulting construction in common forms of type theory without assuming (instances of) the axiom of countable choice.Using an idea from homotopy type theory\textemdash{}a higher inductive-inductive type\textemdash{}we construct a partiality monad without relying on countable choice. We prove that, in the presence of countable choice, our partiality monad is equivalent to the delay monad quotiented by weak bisimilarity. Furthermore we outline several applications.},
  language = {en},
  urldate = {2018-06-19},
  booktitle = {Foundations of {{Software Science}} and {{Computation Structures}}},
  publisher = {{Springer, Berlin, Heidelberg}},
  doi = {10.1007/978-3-662-54458-7_31},
  url = {http://link.springer.com/10.1007/978-3-662-54458-7_31},
  author = {Altenkirch, Thorsten and Danielsson, Nils Anders and Kraus, Nicolai},
  month = apr,
  year = {2017},
  pages = {534-549},
  file = {/Users/doisinkidney/Zotero/storage/CTLM5XDQ/Altenkirch et al. - 2017 - Partiality, Revisited.pdf;/Users/doisinkidney/Zotero/storage/L8F98IQM/Altenkirch et al. - 2017 - Partiality, Revisited.pdf;/Users/doisinkidney/Zotero/storage/XGDP694U/Altenkirch et al. - 2017 - Partiality, Revisited.pdf;/Users/doisinkidney/Zotero/storage/XIJ9ASUQ/Altenkirch et al. - 2017 - Partiality, Revisited.pdf;/Users/doisinkidney/Zotero/storage/5NKZK8MQ/978-3-662-54458-7_31.html}
}

@inproceedings{danielsson_bag_2012,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Bag {{Equivalence}} via a {{Proof}}-{{Relevant Membership Relation}}},
  isbn = {978-3-642-32346-1 978-3-642-32347-8},
  abstract = {Two lists are bag equivalent if they are permutations of each other, i.e. if they contain the same elements, with the same multiplicity, but perhaps not in the same order. This paper describes how one can define bag equivalence as the presence of bijections between sets of membership proofs. This definition has some desirable properties: Many bag equivalences can be proved using a flexible form of equational reasoning. The definition generalises easily to arbitrary unary containers, including types with infinite values, such as streams. By using a slight variation of the definition one gets set equivalence instead, i.e. equality up to order and multiplicity. Other variations give the subset and subbag preorders. The definition works well in mechanised proofs.},
  language = {en},
  urldate = {2018-06-20},
  booktitle = {Interactive {{Theorem Proving}}},
  publisher = {{Springer, Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-32347-8_11},
  url = {https://link.springer.com/chapter/10.1007/978-3-642-32347-8_11},
  author = {Danielsson, Nils Anders},
  month = aug,
  year = {2012},
  pages = {149-165},
  file = {/Users/doisinkidney/Zotero/storage/48TN8RVW/Danielsson - 2012 - Bag Equivalence via a Proof-Relevant Membership Re.pdf;/Users/doisinkidney/Zotero/storage/6FHBRC2J/Danielsson - 2012 - Bag Equivalence via a Proof-Relevant Membership Re.pdf;/Users/doisinkidney/Zotero/storage/Z3C57Z7B/10.html}
}

@inproceedings{danielsson_lightweight_2008,
  address = {New York, NY, USA},
  series = {{{POPL}} '08},
  title = {Lightweight {{Semiformal Time Complexity Analysis}} for {{Purely Functional Data Structures}}},
  isbn = {978-1-59593-689-9},
  abstract = {Okasaki and others have demonstrated how purely functional data structures that are efficient even in the presence of persistence can be constructed. To achieve good time bounds essential use is often made of laziness. The associated complexity analysis is frequently subtle, requiring careful attention to detail, and hence formalising it is valuable. This paper describes a simple library which can be used to make the analysis of a class of purely functional data structures and algorithms almost fully formal. The basic idea is to use the type system to annotate every function with the time required to compute its result. An annotated monad is used to combine time complexity annotations. The library has been used to analyse some existing data structures, for instance the deque operations of Hinze and Paterson's finger trees.},
  language = {en},
  urldate = {2018-06-20},
  booktitle = {Proceedings of the 35th {{Annual ACM SIGPLAN}}-{{SIGACT Symposium}} on {{Principles}} of {{Programming Languages}}},
  publisher = {{ACM}},
  doi = {10.1145/1328438.1328457},
  url = {http://www.cse.chalmers.se/~nad/publications/danielsson-popl2008.pdf},
  author = {Danielsson, Nils Anders},
  year = {2008},
  keywords = {dependent types,lazy evaluation,purely functional data structures,amortised time complexity},
  pages = {133--144},
  file = {/Users/doisinkidney/Zotero/storage/8NI9UUMH/Danielsson - Lightweight Semiformal Time Complexity Analysis fo.pdf;/Users/doisinkidney/Zotero/storage/A9CNNCIR/Danielsson - Lightweight Semiformal Time Complexity Analysis fo.pdf}
}

@inproceedings{atkey_productive_2013,
  title = {Productive Coprogramming with Guarded Recursion},
  isbn = {978-1-4503-2326-0},
  language = {en},
  urldate = {2018-06-21},
  publisher = {{ACM Press}},
  doi = {10.1145/2500365.2500597},
  url = {https://bentnib.org/productive.html},
  author = {Atkey, Robert and McBride, Conor},
  year = {2013},
  pages = {197},
  file = {/Users/doisinkidney/Zotero/storage/SXKIJ6DE/Atkey and McBride - 2013 - Productive coprogramming with guarded recursion.pdf}
}

@inproceedings{mcbride_how_2014,
  address = {New York, NY, USA},
  series = {{{ICFP}} '14},
  title = {How to {{Keep Your Neighbours}} in {{Order}}},
  isbn = {978-1-4503-2873-9},
  abstract = {I present a datatype-generic treatment of recursive container types whose elements are guaranteed to be stored in increasing order, with the ordering invariant rolled out systematically. Intervals, lists and binary search trees are instances of the generic treatment. On the journey to this treatment, I report a variety of failed experiments and the transferable learning experiences they triggered. I demonstrate that a total element ordering is enough to deliver insertion and flattening algorithms, and show that (with care about the formulation of the types) the implementations remain as usual. Agda's instance arguments and pattern synonyms maximize the proof search done by the typechecker and minimize the appearance of proofs in program text, often eradicating them entirely. Generalizing to indexed recursive container types, invariants such as size and balance can be expressed in addition to ordering. By way of example, I implement insertion and deletion for 2-3 trees, ensuring both order and balance by the discipline of type checking.},
  urldate = {2018-06-21},
  booktitle = {Proceedings of the 19th {{ACM SIGPLAN International Conference}} on {{Functional Programming}}},
  publisher = {{ACM}},
  doi = {10.1145/2628136.2628163},
  url = {https://personal.cis.strath.ac.uk/conor.mcbride/pub/Pivotal.pdf},
  author = {McBride, Conor Thomas},
  year = {2014},
  keywords = {dependent types,sorting,agda,balancing,ordering},
  pages = {297--309},
  file = {/Users/doisinkidney/Zotero/storage/T8BXF2WX/McBride - How to Keep Your Neighbours in Order.pdf}
}

@article{fritz_bimonoidal_2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1804.03527},
  primaryClass = {cs, math},
  title = {Bimonoidal {{Structure}} of {{Probability Monads}}},
  abstract = {We give a conceptual treatment of the notion of joints, marginals, and independence in the setting of categorical probability. This is achieved by endowing the usual probability monads (like the Giry monad) with a monoidal and an opmonoidal structure, mutually compatible (i.e. a bimonoidal structure). If the underlying monoidal category is cartesian monoidal, a bimonoidal structure is given uniquely by a commutative strength. However, if the underlying monoidal category is not cartesian monoidal, a strength is not enough to guarantee all the desired properties of joints and marginals. A bimonoidal structure is then the correct requirement for the more general case. We explain the theory and the operational interpretation, with the help of the graphical calculus for monoidal categories. We give a definition of stochastic independence based on the bimonoidal structure, compatible with the intuition and with other approaches in the literature for cartesian monoidal categories. We then show as an example that the Kantorovich monad on the category of complete metric spaces is a bimonoidal monad for a non-cartesian monoidal structure.},
  urldate = {2018-06-27},
  journal = {arXiv:1804.03527 [cs, math]},
  url = {http://arxiv.org/abs/1804.03527},
  author = {Fritz, Tobias and Perrone, Paolo},
  month = apr,
  year = {2018},
  keywords = {Computer Science - Logic in Computer Science,Mathematics - Category Theory,Mathematics - Probability,60A05; 18C15; 16W30,Mathematics - Quantum Algebra},
  file = {/Users/doisinkidney/Zotero/storage/VSKXRVE4/Fritz and Perrone - 2018 - Bimonoidal Structure of Probability Monads.pdf;/Users/doisinkidney/Zotero/storage/CSMLIG25/1804.html}
}

@inproceedings{ahman_when_2012,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {When {{Is}} a {{Container}} a {{Comonad}}?},
  isbn = {978-3-642-28728-2 978-3-642-28729-9},
  abstract = {Abbott, Altenkirch, Ghani and others have taught us that many parameterized datatypes (set functors) can be usefully analyzed via container representations in terms of a set of shapes and a set of positions in each shape. This paper builds on the observation that datatypes often carry additional structure that containers alone do not account for. We introduce directed containers to capture the common situation where every position in a datastructure determines another datastructure, informally, the sub-datastructure rooted by that position. Some natural examples are non-empty lists and node-labelled trees, and datastructures with a designated position (zippers). While containers denote set functors via a fully-faithful functor, directed containers interpret fully-faithfully into comonads. But more is true: every comonad whose underlying functor is a container is represented by a directed container. In fact, directed containers are the same as containers that are comonads. We also describe some constructions of directed containers. We have formalized our development in the dependently typed programming language Agda.},
  language = {en},
  urldate = {2018-06-27},
  booktitle = {Foundations of {{Software Science}} and {{Computational Structures}}},
  publisher = {{Springer, Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-28729-9_5},
  url = {https://link.springer.com/chapter/10.1007/978-3-642-28729-9_5},
  author = {Ahman, Danel and Chapman, James and Uustalu, Tarmo},
  month = mar,
  year = {2012},
  pages = {74-88},
  file = {/Users/doisinkidney/Zotero/storage/D7FRX67R/Ahman et al. - 2012 - When Is a Container a Comonad.pdf;/Users/doisinkidney/Zotero/storage/RM2YW4IV/Ahman et al. - 2012 - When Is a Container a Comonad.pdf;/Users/doisinkidney/Zotero/storage/2N83EPYI/10.html;/Users/doisinkidney/Zotero/storage/3XC6FV22/978-3-642-28729-9_5.html}
}

@unpublished{mcbride_polynomial_2012,
  title = {A Polynomial Testing Principle},
  abstract = {Two polynomial functions of degree at most n agree on all inputs if they agree on n + 1 different inputs, e.g., on \{0, 1, 2, . . . , n\}. This fact gives us a simple procedure for testing equivalence in a language of polynomial expressions. Moreover, we may readily extend this language to include a summation operator and test standard results which are usually established inductively.},
  language = {en},
  urldate = {2019-05-03},
  url = {https://personal.cis.strath.ac.uk/conor.mcbride/PolyTest.pdf},
  author = {McBride, Conor},
  month = feb,
  year = {2012},
  file = {/Users/doisinkidney/Zotero/storage/TJY6RASV/McBride - A polynomial testing principle.pdf}
}

@techreport{norell_dependently_2008,
  title = {Dependently {{Typed Programming}} in {{Agda}}},
  copyright = {Springer-Verlag},
  language = {en},
  url = {http://www.cse.chalmers.se/~ulfn/papers/afp08/tutorial.pdf},
  author = {Norell, Ulf and Chapman, James},
  year = {2008},
  file = {/Users/doisinkidney/Zotero/storage/N2JXRX7J/Norell and Chapman - Dependently Typed Programming in Agda.pdf}
}

@article{dybjer_introduction_2017,
  title = {An {{Introduction}} to {{Programming}} and {{Proving}} in {{Agda}} (Incomplete Draft)},
  language = {en},
  author = {Dybjer, Peter},
  month = sep,
  year = {2017},
  pages = {24},
  file = {/Users/doisinkidney/Zotero/storage/TNAMXB5E/Dybjer - An Introduction to Programming and Proving in Agda.pdf}
}

@misc{danielsson_agda_2018,
  title = {The {{Agda}} Standard Library},
  urldate = {2018-07-28},
  url = {https://agda.github.io/agda-stdlib/README.html},
  author = {Danielsson, Nils Anders},
  collaborator = {Abel, Andreas and Andjelkovic, Stevan and Bernardy, Jean-Philippe and Berry, Peter and Hardy, Bradley and Breitner, Joachim and Bronson, Samuel and Brown, Daniel and Chapman, James and Chen, Liang-Ting and Daggitt, Matthew and Devriese, Dominique and Doel, Dan and Gerg{\H o}, \'Erdi and Grohne, Helmut and Foster, Simon and Hu, Liyang and Hu, Jason and Jansson, Patrik and Jeffrey, Alan and Kokke, Wen and Kotelnikov, Evgeny and Meshveliani, Sergei and Mertens, Eric and Morrison, Darin and Moulin, Guilhem and Mu, Shin-Cheng and Norell, Ulf and Ohkawa, Noriyuki and Pouillard, Nicolas and {Sicard-Ram\'irez}, Andr\'es and Zeilberger, Noam},
  month = jun,
  year = {2018}
}

@inproceedings{weirich_depending_2014,
  address = {New York, NY, USA},
  series = {{{ICFP}} '14},
  title = {Depending on {{Types}}},
  isbn = {978-1-4503-2873-9},
  abstract = {Is Haskell a dependently typed programming language? Should it be? GHC's many type-system features, such as Generalized Algebraic Datatypes (GADTs), datatype promotion, multiparameter type classes, and type families, give programmers the ability to encode domain-specific invariants in their types. Clever Haskell programmers have used these features to enhance the reasoning capabilities of static type checking. But really, how far have we come? Could we do more? In this talk, I will discuss dependently typed programming in Haskell, through examples, analysis and comparisons with modern full-spectrum dependently typed languages, such as Coq, Agda and Idris. What sorts of dependently typed programming can be done in Haskell now? What could GHC learn from these languages? Conversely, what lessons can GHC offer in return?},
  urldate = {2018-07-29},
  booktitle = {Proceedings of the 19th {{ACM SIGPLAN International Conference}} on {{Functional Programming}}},
  publisher = {{ACM}},
  doi = {10.1145/2628136.2631168},
  url = {https://www.cis.upenn.edu/~sweirich/talks/icfp14.pdf},
  author = {Weirich, Stephanie},
  year = {2014},
  keywords = {dependent types,haskell},
  pages = {241--241},
  file = {/Users/doisinkidney/Zotero/storage/D7QDGRXG/Weirich - 2014 - Depending on Types.pdf;/Users/doisinkidney/Zotero/storage/HNU7MRHG/icfp14.pdf}
}

@inproceedings{pfaff_performance_2004,
  address = {New York, NY, USA},
  series = {{{SIGMETRICS}} '04/{{Performance}} '04},
  title = {Performance {{Analysis}} of {{BSTs}} in {{System Software}}},
  isbn = {978-1-58113-873-3},
  abstract = {Binary search tree (BST) based data structures, such as AVL trees, red-black trees, and splay trees, are often used in system software, such as operating system kernels. Choosing the right kind of tree can impact performance significantly, but the literature offers few empirical studies for guidance. We compare 20 BST variants using three experiments in real-world scenarios with real and artificial workloads. The results indicate that when input is expected to be randomly ordered with occasional runs of sorted order, red-black trees are preferred; when insertions often occur in sorted order, AVL trees excel for later random access, whereas splay trees perform best for later sequential or clustered access. For node representations, use of parent pointers is shown to be the fastest choice, with threaded nodes a close second choice that saves memory; nodes without parent pointers or threads suffer when traversal and modification are combined; maintaining a in-order doubly linked list is advantageous when traversal is very common; and right-threaded nodes perform poorly.},
  language = {en},
  urldate = {2018-07-29},
  booktitle = {Proceedings of the {{Joint International Conference}} on {{Measurement}} and {{Modeling}} of {{Computer Systems}}},
  publisher = {{ACM}},
  doi = {10.1145/1005686.1005742},
  url = {https://benpfaff.org/papers/libavl.pdf},
  author = {Pfaff, Ben},
  year = {2004},
  keywords = {binary search tree,AVL tree,BST,red-black tree,splay tree,threaded tree},
  pages = {410--411},
  file = {/Users/doisinkidney/Zotero/storage/75V4WPKQ/Pfaﬀ - Performance Analysis of BSTs in System Software∗.pdf;/Users/doisinkidney/Zotero/storage/ERMAGWUW/Pfaff - 2004 - Performance Analysis of BSTs in System Software.pdf}
}

@article{cohen_cubical_2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1611.02108},
  primaryClass = {cs, math},
  title = {Cubical {{Type Theory}}: A Constructive Interpretation of the Univalence Axiom},
  shorttitle = {Cubical {{Type Theory}}},
  abstract = {This paper presents a type theory in which it is possible to directly manipulate \$n\$-dimensional cubes (points, lines, squares, cubes, etc.) based on an interpretation of dependent type theory in a cubical set model. This enables new ways to reason about identity types, for instance, function extensionality is directly provable in the system. Further, Voevodsky's univalence axiom is provable in this system. We also explain an extension with some higher inductive types like the circle and propositional truncation. Finally we provide semantics for this cubical type theory in a constructive meta-theory.},
  language = {en},
  urldate = {2018-07-30},
  journal = {arXiv:1611.02108 [cs, math]},
  url = {http://arxiv.org/abs/1611.02108},
  author = {Cohen, Cyril and Coquand, Thierry and Huber, Simon and M\"ortberg, Anders},
  month = nov,
  year = {2016},
  keywords = {F.3.2,Computer Science - Logic in Computer Science,F.4.1,Mathematics - Logic},
  pages = {34},
  file = {/Users/doisinkidney/Zotero/storage/JPB35LT3/Cohen et al. - 2016 - Cubical Type Theory a constructive interpretation.pdf;/Users/doisinkidney/Zotero/storage/SAVUJFRF/Cohen et al. - 2016 - Cubical Type Theory a constructive interpretation.pdf;/Users/doisinkidney/Zotero/storage/WNZZ885E/Cohen et al. - 2016 - Cubical Type Theory a constructive interpretation.pdf;/Users/doisinkidney/Zotero/storage/YYV2LT9Q/Cohen et al. - Cubical Type Theory a constructive interpretation.pdf;/Users/doisinkidney/Zotero/storage/JRUQW2TM/1611.html;/Users/doisinkidney/Zotero/storage/V8XZUFR6/1611.html}
}

@inproceedings{cheng_functional_2018,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Functional {{Pearl}}: {{Folding Polynomials}} of {{Polynomials}}},
  isbn = {978-3-319-90685-0 978-3-319-90686-7},
  shorttitle = {Functional {{Pearl}}},
  abstract = {Polynomials are a central concept to many branches in mathematics and computer science. In particular, manipulation of polynomial expressions can be used to model a wide variety of computation. In this paper, we consider a simple recursive construction of multivariate polynomials over a base ring such as the integers or a (finite) field. We show that this construction allows inductive implementation of polynomial operations such as arithmetic, evaluation, substitution, etc. Furthermore, we can transform a polynomial expression into in a sequence of arithmetic expressions in the base ring and prove the correctness of this transformation in Agda. Combined with our recursive construction, this allows for compiling polynomial expressions over a tower of extension fields into scalar expressions over the ground field, for example. Such a technique is not only interesting in its own right but also finds plentiful application in research areas such as cryptography.},
  language = {en},
  urldate = {2018-08-02},
  booktitle = {Functional and {{Logic Programming}}},
  publisher = {{Springer, Cham}},
  doi = {10.1007/978-3-319-90686-7_5},
  url = {https://link.springer.com/chapter/10.1007/978-3-319-90686-7_5},
  author = {Cheng, Chen-Mou and Hsu, Ruey-Lin and Mu, Shin-Cheng},
  month = may,
  year = {2018},
  pages = {68-83},
  file = {/Users/doisinkidney/Zotero/storage/D8GT5G46/Cheng et al. - 2018 - Functional Pearl Folding Polynomials of Polynomia.pdf;/Users/doisinkidney/Zotero/storage/CYZ5CHC3/978-3-319-90686-7_5.html}
}

@inproceedings{jeffrey_causality_2013,
  title = {Causality for Free!: Parametricity Implies Causality for Functional Reactive Programs},
  isbn = {978-1-4503-1860-0},
  shorttitle = {Causality for Free!},
  abstract = {Functional Reactive Programming (FRP) is a model of reactive systems in which signals are time-dependent values, and signal functions are functions between signals. Signal functions are required to be causal, in that output behaviour at time t is only allowed to depend on input behaviour up to time t. In order to enforce causality, many FRP libraries are arrowized, in that they provide combinators for building signal functions, rather than allowing users to write functions directly. In this paper, we provide a definition of deep causality (which coincides with the usual definition on signals of base type, but differs on nested signals). We show that FRP types can be interpreted in System F{$\omega$} extended with a kind of time, and show that in this interpretation, a ``theorems for free'' argument shows that parametric functions are deep causal. Since all System F{$\omega$} functions are parametric, this implies that all implementable functions are deep causal. This model is the formal basis of the agda-frp-js FRP library for the dependently typed programming language Agda, which compiles to JavaScript and executes in the browser. Assuming parametricity of Agda, this allows reactive programs to be written as regular functions over signals, without sacrificing causality. All results in this paper have been mechanically verified in Agda.},
  language = {en},
  urldate = {2018-08-02},
  publisher = {{ACM Press}},
  doi = {10.1145/2428116.2428127},
  url = {http://dl.acm.org/citation.cfm?doid=2428116.2428127},
  author = {Jeffrey, Alan},
  year = {2013},
  pages = {57},
  file = {/Users/doisinkidney/Zotero/storage/HH8UXHSG/Jeffrey - 2013 - Causality for free! parametricity implies causali.pdf}
}

@inproceedings{danielsson_total_2010,
  address = {New York, NY, USA},
  series = {{{ICFP}} '10},
  title = {Total {{Parser Combinators}}},
  isbn = {978-1-60558-794-3},
  abstract = {A monadic parser combinator library which guarantees termination of parsing, while still allowing many forms of left recursion, is described. The library's interface is similar to those of many other parser combinator libraries, with two important differences: one is that the interface clearly specifies which parts of the constructed parsers may be infinite, and which parts have to be finite, using dependent types and a combination of induction and coinduction; and the other is that the parser type is unusually informative. The library comes with a formal semantics, using which it is proved that the parser combinators are as expressive as possible. The implementation is supported by a machine-checked correctness proof.},
  urldate = {2018-08-03},
  booktitle = {Proceedings of the 15th {{ACM SIGPLAN International Conference}} on {{Functional Programming}}},
  publisher = {{ACM}},
  doi = {10.1145/1863543.1863585},
  url = {http://www.cse.chalmers.se/~nad/publications/danielsson-parser-combinators.html},
  author = {Danielsson, Nils Anders},
  year = {2010},
  keywords = {dependent types,mixed induction and coinduction,parser combinators,productivity,termination},
  pages = {285--296},
  file = {/Users/doisinkidney/Zotero/storage/HAZDEJPP/danielsson-parser-combinators.pdf;/Users/doisinkidney/Zotero/storage/TETBD5MS/Danielsson - 2010 - Total Parser Combinators.pdf}
}

@inproceedings{gregoire_proving_2005,
  address = {Berlin, Heidelberg},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Proving {{Equalities}} in a {{Commutative Ring Done Right}} in {{Coq}}},
  volume = {3603},
  isbn = {978-3-540-28372-0 978-3-540-31820-0},
  abstract = {We present a new implementation of a reflexive tactic which solves equalities in a ring structure inside the Coq system. The efficiency is improved to a point that we can now prove equalities that were previously beyond reach. A special care has been taken to implement efficient algorithms while keeping the complexity of the correctness proofs low. This leads to a single tool, with a single implementation, which can be addressed for a ring or for a semi-ring, abstract or not, using the Leibniz equality or a setoid equality. This example shows that such reflective methods can be effectively used in symbolic computation.},
  language = {en},
  urldate = {2018-08-03},
  booktitle = {Theorem {{Proving}} in {{Higher Order Logics}}},
  publisher = {{Springer Berlin Heidelberg}},
  doi = {10.1007/11541868_7},
  url = {http://link.springer.com/10.1007/11541868_7},
  author = {Gr\'egoire, Benjamin and Mahboubi, Assia},
  year = {2005},
  pages = {98-113},
  file = {/Users/doisinkidney/Zotero/storage/GTPFHWSU/Grégoire and Mahboubi - 2005 - Proving Equalities in a Commutative Ring Done Righ.pdf;/Users/doisinkidney/Zotero/storage/KK2HQB4Z/11541868_7.html}
}

@article{main_free_1985,
  title = {Free Semiring-Representations and Nondeterminism},
  volume = {30},
  issn = {0022-0000},
  abstract = {Semirings provide a simple abstract model of the syntax for a nondeterministic programming language. Each element of a semiring is a nondeterministic program segment, and the semiring operations (+ and {$\uplus$}) correspond to nondeterministic or and program composition. This is analogous to using an algebraic theory for the abstract syntax of a deterministic language. In the case of algebraic theories, an algebra provides the semantics, and free algebras (which always exist) are particularly important. For a semiring, semantics is provided by a representation as a system of relations. This paper examines the question of when free representations exist. Unlike free algebras, free representations do not always exist. It is shown that a semiring has free representations generated by arbitrary sets of variables iff it has a free representation generated by a single variable. Examples of semirings are given that do not have free representations. However, for an important class of semirings, free representations are always available. This class consists of semirings which arise when nondeterminism is freely added to a deterministic programming language.},
  number = {3},
  urldate = {2018-08-03},
  journal = {Journal of Computer and System Sciences},
  doi = {10.1016/0022-0000(85)90049-2},
  url = {http://www.sciencedirect.com/science/article/pii/0022000085900492},
  author = {Main, Michael G. and Benson, David B.},
  month = jun,
  year = {1985},
  pages = {318-328},
  file = {/Users/doisinkidney/Zotero/storage/B2SDYE45/Main and Benson - 1985 - Free semiring-representations and nondeterminism.pdf;/Users/doisinkidney/Zotero/storage/4RXL7GYM/0022000085900492.html}
}

@inproceedings{oconnor_applications_2016,
  address = {New York, NY, USA},
  series = {{{TyDe}} 2016},
  title = {Applications of {{Applicative Proof Search}}},
  isbn = {978-1-4503-4435-7},
  abstract = {In this paper, we develop a library of typed proof search procedures, and demonstrate their remarkable utility as a mechanism for proof-search and automation. We describe a framework for describing proof-search procedures in Agda, with a library of tactical combinators based on applicative functors. This framework is very general, so we demonstrate the approach with two common applications from the field of software verification: a library for property-based testing in the style of SmallCheck, and the embedding of a basic model checker inside our framework, which we use to verify the correctness of common concurrency algorithms.},
  urldate = {2018-08-03},
  booktitle = {Proceedings of the 1st {{International Workshop}} on {{Type}}-{{Driven Development}}},
  publisher = {{ACM}},
  doi = {10.1145/2976022.2976030},
  url = {http://doi.acm.org/10.1145/2976022.2976030},
  author = {O'Connor, Liam},
  year = {2016},
  keywords = {Agda,automation,concurrency,critical section,model checking,proof,properties,testing},
  pages = {43--55},
  file = {/Users/doisinkidney/Zotero/storage/L9AIHCP8/O'Connor - 2016 - Applications of Applicative Proof Search.pdf}
}

@article{gumundsson_formalizing_2017,
  title = {Formalizing the Translation Method in {{Agda}}},
  abstract = {If \dbend\dbend\dbend\dbend\dbend\dbend{} and \dbend\dbend\dbend\dbend\dbend\dbend{} are sets of combinatorial objects, the translation method, introduced by Wood and Zeilberger (2009), allows one to turn an algebraic proof of the identity |\dbend\dbend\dbend\dbend\dbend\dbend{} | = |\dbend\dbend\dbend\dbend\dbend\dbend{}| into a bijection between \dbend\dbend\dbend\dbend\dbend\dbend{} and \dbend\dbend\dbend\dbend\dbend\dbend. We give a formalized implementation of the translation method in the programming language Agda. In contrast to the implementation previously given by Wood and Zeilberger, the bijections produced by our implementation are formally verified, making our implementation more robust. We also take advantage of the fact that Agda is a proof assistant, allowing users of our implementation to use the existing facilities provided by Agda for developing proofs. In particular, converting an existing algebraic proof for use in our implementation is often straightforward.},
  language = {en},
  author = {Gu\dh{}mundsson, Bjarki \'Ag\'ust},
  month = jun,
  year = {2017},
  pages = {112},
  file = {/Users/doisinkidney/Zotero/storage/IHJEUPEG/Guðmundsson - Formalizing the translation method in Agda.pdf}
}

@article{johnson_sparse_1974,
  title = {Sparse Polynomial Arithmetic},
  volume = {8},
  issn = {01635824},
  abstract = {Sparse polynomial representations are used in a number of algebraic manipulation systems, including Aitran. This paper discusses the arithmetic operations with sparsely represented polynomials; we give particular attention to multiplication and division\textbullet{} We give new algorithms for multiplying two polynomials, with n and m terms, in time mnlogm; these algorithms have the property that, in the usual univariate dense case, the algorithm is bounded by ran. Division algorithms are discussed which run in comparable time.},
  language = {en},
  number = {3},
  urldate = {2018-08-07},
  journal = {ACM SIGSAM Bulletin},
  doi = {10.1145/1086837.1086847},
  url = {http://portal.acm.org/citation.cfm?doid=1086837.1086847},
  author = {Johnson, Stephen C.},
  month = aug,
  year = {1974},
  pages = {63-71},
  file = {/Users/doisinkidney/Zotero/storage/N574968I/Johnson - 1974 - Sparse polynomial arithmetic.pdf}
}

@book{danielsson_functional_2007,
  address = {G\"oteborg},
  series = {Doktorsavhandlingar Vid {{Chalmers Tekniska H\"ogskola}}},
  title = {Functional Program Correctness through Types},
  isbn = {978-91-7385-034-6},
  abstract = {This thesis addresses the problem of avoiding errors in functional programs. The thesis has three parts, discussing different aspects of program correctness, with the unifying theme that types are an integral part of the methods used to establish correctness.},
  language = {en},
  number = {N.S., 2715},
  publisher = {{Chalmers Univ. of Technology}},
  author = {Danielsson, Nils Anders},
  year = {2007},
  file = {/Users/doisinkidney/Zotero/storage/9LF78LD6/Danielsson - 2007 - Functional program correctness through types.pdf},
  note = {OCLC: 551639193}
}

@article{meshveliani_dependent_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1709.01810},
  primaryClass = {cs},
  title = {On Dependent Types and Intuitionism in Programming Mathematics},
  abstract = {It is discussed a practical possibility of a provable programming of mathematics basing on intuitionism and the dependent types feature of a programming language.The principles of constructive mathematics and provable programming are illustrated with examples taken from algebra. The discourse follows the experience in designing in Agda a computer algebra library DoCon-A, which deals with generic algebraic structures and also provides the needed machine-checked proofs. This paper is a revised translation of a certain paper published in Russian in 2014.},
  urldate = {2018-08-07},
  journal = {arXiv:1709.01810 [cs]},
  url = {http://arxiv.org/abs/1709.01810},
  author = {Meshveliani, Sergei D.},
  month = sep,
  year = {2017},
  keywords = {Computer Science - Logic in Computer Science},
  file = {/Users/doisinkidney/Zotero/storage/B6BMMMVS/Meshveliani - 2017 - On dependent types and intuitionism in programming.pdf;/Users/doisinkidney/Zotero/storage/H6SGLFYG/Meshveliani - 2017 - On dependent types and intuitionism in programming.pdf;/Users/doisinkidney/Zotero/storage/CMU37WUY/1709.html;/Users/doisinkidney/Zotero/storage/HFMYLAK9/1709.html}
}

@techreport{meshveliani_dependent_2013,
  address = {Pereslavl-Zalessky, Russia},
  title = {Dependent {{Types}} for an {{Adequate Programming}} of {{Algebra}}},
  abstract = {This research compares the author's experience in programming algebra in Haskell and in Agda (currently the former experience is large, and the latter is small). There are discussed certain hopes and doubts related to the dependently typed and verified programming of symbolic computation. This concerns the 1) author's experience history, 2) algebraic class hierarchy design, 3) proof cost overhead in evaluation and in coding, 4) other subjects. Various examples are considered.},
  language = {en},
  institution = {{Program Systems Institute of Russian Academy of sciences}},
  url = {http://ceur-ws.org/Vol-1010/paper-05.pdf},
  author = {Meshveliani, Sergei D},
  year = {2013},
  pages = {15},
  file = {/Users/doisinkidney/Zotero/storage/SESGEH6A/Meshveliani - Dependent Types for an Adequate Programming of Alg.pdf}
}

@phdthesis{zalakain_evidence-providing_2017,
  address = {Strathclyde},
  type = {Submitted for the {{Degree}} of {{B}}.{{Sc}}. in {{Computer Science}}},
  title = {Evidence-Providing Problem Solvers in {{Agda}}},
  abstract = {The Curry-Howard correspondence draws a direct link between logic and computation: propositions are modelled as types and proofs as programs; to prove a proposition is to con- struct a program inhabiting its corresponding type. Several computer-assisted theorem provers have been developed under this idea. They are not just used to verify human reasoning: they are also often capable of generating proofs automatically.
This project considers the development of such automated theorem provers in Agda, a de- pendently typed programming language. As a warm-up, I present a verified solver for equations on monoids. Then, I comment on the solver for commutative rings included in Agda's stan- dard library. Finally, I develop a verified decision procedure for Presburger arithmetic \textemdash{} a decidable first-order predicate logic.},
  language = {en},
  urldate = {2018-03-08},
  school = {University of Strathclyde},
  url = {https://umazalakain.info/static/report.pdf},
  author = {Zalakain, Uma},
  year = {2017},
  file = {/Users/doisinkidney/Zotero/storage/HK3IVT32/report.pdf}
}

@article{fu_dependently_2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1806.05230},
  primaryClass = {cs},
  title = {Dependently {{Typed Folds}} for {{Nested Data Types}}},
  abstract = {We present an approach to develop folds for nested data types using dependent types. We call such folds \$\textbackslash{}textit\{dependently typed folds\}\$, they have the following properties. (1) Dependently typed folds are defined by well-founded recursion and they can be defined in a total dependently typed language. (2) Dependently typed folds do not depend on maps, map functions and many terminating functions can be defined using dependently typed folds. (3) The induction principles for nested data types follow from the definitions of dependently typed folds and the programs defined by dependently typed folds can be formally verified. (4) Dependently typed folds exist for any nested data types and they can be specialized to the traditional \$\textbackslash{}textit\{higher-order folds\}\$. Using various of examples, we show how to program and reason about dependently typed folds. We also show how to obtain dependently typed folds in general and how to specialize them to the corresponding higher-order folds.},
  urldate = {2018-08-15},
  journal = {arXiv:1806.05230 [cs]},
  url = {http://arxiv.org/abs/1806.05230},
  author = {Fu, Peng and Selinger, Peter},
  month = jun,
  year = {2018},
  keywords = {Computer Science - Programming Languages,Computer Science - Logic in Computer Science},
  file = {/Users/doisinkidney/Zotero/storage/3VTZEW3W/Fu and Selinger - 2018 - Dependently Typed Folds for Nested Data Types.pdf;/Users/doisinkidney/Zotero/storage/9I9EVTSR/Fu and Selinger - 2018 - Dependently Typed Folds for Nested Data Types.pdf;/Users/doisinkidney/Zotero/storage/5PE5R4LH/1806.html;/Users/doisinkidney/Zotero/storage/WEBYY88G/1806.html}
}

@article{dowek_theorem_2003,
  title = {Theorem {{Proving Modulo}}},
  volume = {31},
  issn = {0168-7433, 1573-0670},
  abstract = {Deduction modulo is a way to remove computational arguments from proofs by reasoning modulo a congruence on propositions. Such a technique, issued from automated theorem proving, is of general interest because it permits one to separate computations and deductions in a clean way. The first contribution of this paper is to define a sequent calculus modulo that gives a proof-theoretic account of the combination of computations and deductions. The congruence on propositions is handled through rewrite rules and equational axioms. Rewrite rules apply to terms but also directly to atomic propositions.The second contribution is to give a complete proof search method, called extended narrowing and resolution (ENAR), for theorem proving modulo such congruences. The completeness of this method is proved with respect to provability in sequent calculus modulo.An important application is that higher-order logic can be presented as a theory in deduction modulo. Applying the ENAR method to this presentation of higher-order logic subsumes full higher-order resolution.},
  language = {en},
  number = {1},
  urldate = {2018-08-16},
  journal = {Journal of Automated Reasoning},
  doi = {10.1023/A:1027357912519},
  url = {https://link.springer.com/article/10.1023/A:1027357912519},
  author = {Dowek, Gilles and Hardin, Th\'er\`ese and Kirchner, Claude},
  month = sep,
  year = {2003},
  pages = {33-72},
  file = {/Users/doisinkidney/Zotero/storage/3FJ82L3C/10.html}
}

@incollection{geuvers_automatically_2017,
  address = {Cham},
  title = {Automatically {{Proving Equivalence}} by {{Type}}-{{Safe Reflection}}},
  volume = {10383},
  isbn = {978-3-319-62074-9 978-3-319-62075-6},
  abstract = {One difficulty with reasoning and programming with dependent types is that proof obligations arise naturally once programs become even moderately sized. For example, implementing an adder for binary numbers indexed over their natural number equivalents naturally leads to proof obligations for equalities of expressions over natural numbers. The need for these equality proofs comes, in intensional type theories, from the fact that the propositional equality enables us to prove as equal terms that are not judgementally equal, which means that the typechecker can't always obtain equalities by reduction. As far as possible, we would like to solve such proof obligations automatically. In this paper, we show one way to automate these proofs by reflection in the dependently typed programming language Idris. We show how defining reflected terms indexed by the original Idris expression allows us to construct and manipulate proofs. We build a hierarchy of tactics for proving equivalences in semigroups, monoids, commutative monoids, groups, commutative groups, semi-rings and rings. We also show how each tactic reuses those from simpler structures, thus avoiding duplication of code and proofs.},
  language = {en},
  urldate = {2018-08-16},
  booktitle = {Intelligent {{Computer Mathematics}}},
  publisher = {{Springer International Publishing}},
  url = {http://link.springer.com/10.1007/978-3-319-62075-6_4},
  author = {Slama, Franck and Brady, Edwin},
  editor = {Geuvers, Herman and England, Matthew and Hasan, Osman and Rabe, Florian and Teschke, Olaf},
  year = {2017},
  pages = {40-55},
  file = {/Users/doisinkidney/Zotero/storage/PDB7LZPW/Slama and Brady - 2017 - Automatically Proving Equivalence by Type-Safe Ref.pdf},
  doi = {10.1007/978-3-319-62075-6_4}
}

@article{mu_algebra_2009,
  title = {Algebra of Programming in {{Agda}}: {{Dependent}} Types for Relational Program Derivation},
  volume = {19},
  issn = {1469-7653, 0956-7968},
  shorttitle = {Algebra of Programming in {{Agda}}},
  abstract = {Relational program derivation is the technique of stepwise refining a relational specification to a program by algebraic rules. The program thus obtained is correct by construction. Meanwhile, dependent type theory is rich enough to express various correctness properties to be verified by the type checker. We have developed a library, AoPA (Algebra of Programming in Agda), to encode relational derivations in the dependently typed programming language Agda. A program is coupled with an algebraic derivation whose correctness is guaranteed by the type system. Two non-trivial examples are presented: an optimisation problem and a derivation of quicksort in which well-founded recursion is used to model terminating hylomorphisms in a language with inductive types.},
  language = {en},
  number = {5},
  urldate = {2018-08-17},
  journal = {Journal of Functional Programming},
  doi = {10.1017/S0956796809007345},
  url = {https://github.com/scmu/aopa},
  author = {Mu, Shin-Cheng and Ko, Hsiang-Shang and Jansson, Patrik},
  month = sep,
  year = {2009},
  pages = {545-579},
  file = {/Users/doisinkidney/Zotero/storage/D7UWNTJ4/Mu et al. - 2009 - Algebra of programming in Agda Dependent types fo.pdf;/Users/doisinkidney/Zotero/storage/D8FNYT4X/Mu et al. - 2009 - Algebra of programming in Agda Dependent types fo.pdf;/Users/doisinkidney/Zotero/storage/5D6VGKJQ/ACA0C08F29621A892FB0C0B745254D15.html}
}

@misc{mu_aopa_2018,
  title = {Aopa: {{Algebra}} of {{Programming}} in {{Agda}}: {{Dependent Types}} for {{Relational Program Derivation}}},
  shorttitle = {Aopa},
  urldate = {2018-08-17},
  url = {https://github.com/scmu/aopa},
  author = {Mu, Shin-Cheng},
  month = aug,
  year = {2018}
}

@article{mu_programming_2012,
  series = {12th {{International Conference}} on {{Relational}} and {{Algebraic Methods}} in {{Computer Science}} ({{RAMiCS}} 2011)},
  title = {Programming from {{Galois}} Connections},
  volume = {81},
  issn = {1567-8326},
  abstract = {Problem statements often resort to superlatives such as in e.g. ``\ldots{} the smallest such number'', ``\ldots{} the best approximation'', ``\ldots{} the longest such list'' which lead to specifications made of two parts: one defining a broad class of solutions (the easy part) and the other requesting one particular such solution, optimal in some sense (the hard part). This article introduces a binary relational combinator which mirrors this linguistic structure and exploits its potential for calculating programs by optimization. This applies in particular to specifications written in the form of Galois connections, in which one of the adjoints delivers the optimal solution. The framework encompasses re-factoring of results previously developed by Bird and de Moor for greedy and dynamic programming, in a way which makes them less technically involved and therefore easier to understand and play with.},
  number = {6},
  urldate = {2018-08-18},
  journal = {The Journal of Logic and Algebraic Programming},
  doi = {10.1016/j.jlap.2012.05.003},
  url = {http://www.sciencedirect.com/science/article/pii/S1567832612000525},
  author = {Mu, Shin-Cheng and Oliveira, Jos\'e Nuno},
  month = aug,
  year = {2012},
  keywords = {Algebra of programming,Galois connection,Program derivation},
  pages = {680-704},
  file = {/Users/doisinkidney/Zotero/storage/9CVSDF8W/Mua and Oliveirab - Programming from Galois Connections.pdf;/Users/doisinkidney/Zotero/storage/BSN7ZWTQ/Mua and Oliveirab - Programming from Galois Connections.pdf;/Users/doisinkidney/Zotero/storage/C3VP3FGT/Mua and Oliveirab - Programming from Galois Connections.pdf;/Users/doisinkidney/Zotero/storage/DH8S72BQ/Mu and Oliveira - 2012 - Programming from Galois connections.pdf;/Users/doisinkidney/Zotero/storage/KP24NNPC/Mua and Oliveirab - Programming from Galois Connections.pdf;/Users/doisinkidney/Zotero/storage/TMNESM34/Mua and Oliveirab - Programming from Galois Connections.pdf;/Users/doisinkidney/Zotero/storage/VJG783ZD/Mu and Oliveira - 2012 - Programming from Galois connections.pdf;/Users/doisinkidney/Zotero/storage/3FES9GDK/S1567832612000525.html;/Users/doisinkidney/Zotero/storage/5PW4E5QS/24608.html;/Users/doisinkidney/Zotero/storage/DFIVUJSJ/bwmeta1.element.html;/Users/doisinkidney/Zotero/storage/F5RRMDCZ/S1567832612000525.html;/Users/doisinkidney/Zotero/storage/FMY882Y9/S1567832612000525.html}
}

@article{chiang_formal_2016,
  series = {Articles Dedicated to {{Prof}}. {{J}}. {{N}}. {{Oliveira}} on the Occasion of His 60th Birthday},
  title = {Formal Derivation of {{Greedy}} Algorithms from Relational Specifications: {{A}} Tutorial},
  volume = {85},
  issn = {2352-2208},
  shorttitle = {Formal Derivation of {{Greedy}} Algorithms from Relational Specifications},
  abstract = {Many programming tasks can be specified as optimisation problems in which a relation is used to generate all possible solutions, from which we wish to choose an optimal one. A relational operator ``shrink'', developed by Jos\'e N. Oliveira, is particularly suitable for constructing greedy algorithms from such specifications. Meanwhile, it has become standard in many sub-fields in programming language that proofs must be machine-verified. This tutorial leads the readers through the development of algebraic derivations of three greedy algorithms, one fold-based and two unfold-based, using AoPA, a library designed for machine-verified relational program calculation.},
  number = {5, Part 2},
  urldate = {2018-08-18},
  journal = {Journal of Logical and Algebraic Methods in Programming},
  doi = {10.1016/j.jlamp.2015.12.003},
  url = {http://www.sciencedirect.com/science/article/pii/S2352220815001492},
  author = {Chiang, Yu-Hsi and Mu, Shin-Cheng},
  month = aug,
  year = {2016},
  keywords = {Program derivation,Algebra of programming,Galois connection,Dependent type,Machine-aided theorem proving},
  pages = {879-905},
  file = {/Users/doisinkidney/Zotero/storage/ELC6ARTN/1-s2.0-S2352220815001492-main.pdf;/Users/doisinkidney/Zotero/storage/KWCCV77B/Chiang and Mu - 2016 - Formal derivation of Greedy algorithms from relati.pdf;/Users/doisinkidney/Zotero/storage/8JPBXYJD/S2352220815001492.html;/Users/doisinkidney/Zotero/storage/VD8GZPYV/S2352220815001492.html}
}

@inproceedings{audebaud_algebra_2008,
  address = {Berlin, Heidelberg},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Algebra of {{Programming Using Dependent Types}}},
  volume = {5133},
  isbn = {978-3-540-70593-2 978-3-540-70594-9},
  abstract = {Dependent type theory is rich enough to express that a program satisfies an input/output relational specification, but it could be hard to construct the proof term. On the other hand, squiggolists know very well how to show that one relation is included in another by algebraic reasoning. We demonstrate how to encode functional and relational derivations in a dependently typed programming language. A program is coupled with an algebraic derivation from a specification, whose correctness is guaranteed by the type system.},
  language = {en},
  urldate = {2018-08-18},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  doi = {10.1007/978-3-540-70594-9_15},
  url = {http://link.springer.com/10.1007/978-3-540-70594-9_15},
  author = {Mu, Shin-Cheng and Ko, Hsiang-Shang and Jansson, Patrik},
  editor = {Audebaud, Philippe and {Paulin-Mohring}, Christine},
  year = {2008},
  keywords = {Dependent Type,Proof Term,Algebraic Reasoning,Functional Fold,Implicit Parameter},
  pages = {268-283},
  file = {/Users/doisinkidney/Zotero/storage/57EQ9UCL/Mu et al. - 2008 - Algebra of Programming Using Dependent Types.pdf;/Users/doisinkidney/Zotero/storage/ASKFWFTU/Mu et al. - Algebra of Programming Using Dependent Types.pdf;/Users/doisinkidney/Zotero/storage/5VKT7DWK/10.html}
}

@article{gibbons_third_1996,
  title = {The {{Third Homomorphism Theorem}}},
  volume = {6},
  abstract = {The Third Homomorphism Theorem is a folk theorem of the constructive algorithmics community. It states that a function on lists that can be computed both from left to right and from right to left is necessarily a list homomorphism - it can be computed according to any parenthesization of the list. We formalize and prove the theorem, and describe two practical applications: to fast parallel algorithms for language recognition problems and for downwards accumulations on trees.},
  language = {en-gb},
  number = {4},
  urldate = {2018-08-18},
  journal = {Journal of Functional Programming},
  url = {http://www.cs.ox.ac.uk/publications/publication2365-abstract.html},
  author = {Gibbons, Jeremy},
  year = {1996},
  file = {/Users/doisinkidney/Zotero/storage/8FS437A6/Gibbons - 1995 - The Third Homomorphism Theorem.pdf;/Users/doisinkidney/Zotero/storage/JRISL6I9/publication2365-abstract.html;/Users/doisinkidney/Zotero/storage/VX8PP8EU/summary.html}
}

@techreport{bird_introduction_1986,
  title = {An {{Introduction}} to the {{Theory}} of {{Lists}}},
  abstract = {In these lectures we introduce a notation and a calculus for specifying and manipulating computable functions over lists. The calculus is used to derive efficient solutions for a number of problems, including problems in text processing. Although programming per se is not the main topic, we indicate briefly how these solutions can be implemented in a purely functional programming language.},
  language = {en},
  number = {PRG56},
  urldate = {2018-08-18},
  institution = {{OUCL}},
  url = {http://www.cs.ox.ac.uk/publications/publication3837-abstract.html},
  author = {Bird, Richard S.},
  year = {1986},
  pages = {40},
  file = {/Users/doisinkidney/Zotero/storage/8TH8DBIC/1986 - AN INTRODUCTION TO THE THEORY OF LISTS.pdf;/Users/doisinkidney/Zotero/storage/IT3YH6KV/1986 - AN INTRODUCTION TO THE THEORY OF LISTS.pdf;/Users/doisinkidney/Zotero/storage/ALAUKME7/publication3837-abstract.html;/Users/doisinkidney/Zotero/storage/YQYVWRWW/publication3837-abstract.html}
}

@book{bird_algebra_1997,
  address = {London ; New York},
  series = {Prentice-{{Hall}} International Series in Computer Science},
  title = {Algebra of Programming},
  isbn = {978-0-13-507245-5},
  lccn = {QA76.6 .B567 1997},
  publisher = {{Prentice Hall}},
  author = {Bird, Richard and de Moor, Oege},
  year = {1997},
  keywords = {Computer algorithms,Computer programming,Programming (Mathematics)},
  file = {/Users/doisinkidney/Zotero/storage/X3N7TDKM/The-Algebra-of-Programming.pdf}
}

@article{feo_fast_nodate,
  title = {Fast {{Algorithms}} for {{Towers}} of {{Finite Fields}} and {{Isogenies}}},
  language = {en},
  author = {Feo, Luca De},
  pages = {191},
  file = {/Users/doisinkidney/Zotero/storage/AHVPAL6S/Feo - Fast Algorithms for Towers of Finite Fields and Is.pdf}
}

@misc{gibbons_horners_2011,
  title = {Horner's {{Rule}}},
  abstract = {This post is about my all-time favourite calculation, of a linear-time algorithm for the maximum segment sum problem, based on Horner's Rule. The problem was popularized in Jon Bentley'\ldots{}},
  language = {en},
  urldate = {2018-08-19},
  journal = {Patterns in Functional Programming},
  url = {https://patternsinfp.wordpress.com/2011/05/05/horners-rule/},
  author = {Gibbons, Jeremy},
  month = may,
  year = {2011},
  file = {/Users/doisinkidney/Zotero/storage/WRD6S87U/horners-rule.html}
}

@misc{gibbons_distributivity_2011,
  title = {Distributivity in {{Horner}}'s {{Rule}}},
  abstract = {This is a continuation of my previous post on Horner's Rule, and in particular, of the discussion there about distributivity in the datatype-generic version of the Maximum Segment Sum problem\ldots{}},
  language = {en},
  urldate = {2018-08-19},
  journal = {Patterns in Functional Programming},
  url = {https://patternsinfp.wordpress.com/2011/05/17/distributivity-in-horners-rule/},
  author = {Gibbons, Jeremy},
  month = may,
  year = {2011},
  file = {/Users/doisinkidney/Zotero/storage/QSZZFG3P/distributivity-in-horners-rule.html}
}

@article{mcbride_view_2004,
  title = {The {{View}} from the {{Left}}},
  volume = {14},
  issn = {0956-7968},
  abstract = {Pattern matching has proved an extremely powerful and durable notion in functional programming. This paper contributes a new programming notation for type theory which elaborates the notion in various ways. First, as is by now quite well-known in the type theory community, definition by pattern matching becomes a more discriminating tool in the presence of dependent types, since it refines the explanation of types as well as values. This becomes all the more true in the presence of the rich class of datatypes known as inductive families (Dybjer, 1991). Secondly, as proposed by Peyton Jones (1997) for Haskell, and independently rediscovered by us, subsidiary case analyses on the results of intermediate computations, which commonly take place on the right-hand side of definitions by pattern matching, should rather be handled on the left. In simply-typed languages, this subsumes the trivial case of Boolean guards; in our setting it becomes yet more powerful. Thirdly, elementary pattern matching decompositions have a well-defined interface given by a dependent type; they correspond to the statement of an induction principle for the datatype. More general, user-definable decompositions may be defined which also have types of the same general form. Elementary pattern matching may therefore be recast in abstract form, with a semantics given by translation. Such abstract decompositions of data generalize Wadler's (1987) notion of `view'. The programmer wishing to introduce a new view of a type \$\textbackslash{}mathit\{T\}\$, and exploit it directly in pattern matching, may do so via a standard programming idiom. The type theorist, looking through the Curry\textendash{}Howard lens, may see this as proving a theorem, one which establishes the validity of a new induction principle for \$\textbackslash{}mathit\{T\}\$. We develop enough syntax and semantics to account for this high-level style of programming in dependent type theory. We close with the development of a typechecker for the simply-typed lambda calculus, which furnishes a view of raw terms as either being well-typed, or containing an error. The implementation of this view is ipso facto a proof that typechecking is decidable.},
  number = {1},
  urldate = {2018-08-21},
  journal = {J. Funct. Program.},
  doi = {10.1017/S0956796803004829},
  url = {http://strictlypositive.org/vfl.pdf},
  author = {McBride, Conor and McKinna, James},
  month = jan,
  year = {2004},
  pages = {69--111},
  file = {/Users/doisinkidney/Zotero/storage/JPF2T4CC/McBride and McKinna - 2004 - The View from the Left.pdf}
}

@article{cockx_pattern_nodate,
  title = {Pattern {{Matching Without K}}},
  abstract = {Dependent pattern matching is an intuitive way to write programs and proofs in dependently typed languages. It is reminiscent of both pattern matching in functional languages and case analysis in on-paper mathematics. However, in general it is incompatible with new type theories such as homotopy type theory (HoTT). As a consequence, proofs in such theories are typically harder to write and to understand. The source of this incompatibility is the reliance of dependent pattern matching on the so-called K axiom \textendash{} also known as the uniqueness of identity proofs \textendash{} which is inadmissible in HoTT. The Agda language supports an experimental criterion to detect definitions by pattern matching that make use of the K axiom, but so far it lacked a formal correctness proof. In this paper, we propose a new criterion for dependent pattern matching without K, and prove it correct by a translation to eliminators in the style of Goguen et al. (2006). Our criterion both allows more good definitions than existing proposals, and solves a previously undetected problem in the criterion offered by Agda. It has been implemented in Agda and is the first to be supported by a formal proof. Thus it brings the benefits of dependent pattern matching to contexts where we cannot assume K, such as HoTT. It also points the way to new forms of dependent pattern matching, for example on higher inductive types.},
  language = {en},
  author = {Cockx, Jesper and Devriese, Dominique and Piessens, Frank},
  pages = {12},
  file = {/Users/doisinkidney/Zotero/storage/DMX39U5W/Cockx et al. - Pattern Matching Without K.pdf}
}

@inproceedings{altenkirch_observational_2007,
  address = {Freiburg, Germany},
  title = {Observational Equality, Now!},
  isbn = {978-1-59593-677-6},
  language = {en},
  urldate = {2018-08-22},
  booktitle = {Proceedings of the 2007 Workshop on {{Programming}} Languages Meets Program Verification  - {{PLPV}} '07},
  publisher = {{ACM Press}},
  doi = {10.1145/1292597.1292608},
  url = {http://portal.acm.org/citation.cfm?doid=1292597.1292608},
  author = {Altenkirch, Thorsten and McBride, Conor and Swierstra, Wouter},
  year = {2007},
  pages = {57},
  file = {/Users/doisinkidney/Zotero/storage/Q7Z2XQGX/Altenkirch et al. - 2007 - Observational equality, now!.pdf}
}

@article{abel_programming_nodate,
  title = {Programming {{Infinite Structures}} by {{Observations}}},
  abstract = {Inductive datatypes provide mechanisms to define finite data such as finite lists and trees via constructors and allow programmers to analyze and manipulate finite data via pattern matching. In this paper, we develop a dual approach for working with infinite data structures such as streams. Infinite data inhabits coinductive datatypes which denote greatest fixpoints. Unlike finite data which is defined by constructors we define infinite data by observations. Dual to pattern matching, a tool for analyzing finite data, we develop the concept of copattern matching, which allows us to synthesize infinite data. This leads to a symmetric language design where pattern matching on finite and infinite data can be mixed.},
  language = {en},
  author = {Abel, Andreas and Pientka, Brigitte and Thibodeau, David and Setzer, Anton},
  pages = {13},
  file = {/Users/doisinkidney/Zotero/storage/ZCY9V457/Abel et al. - Programming Inﬁnite Structures by Observations.pdf}
}

@inproceedings{firsov_certified_2013,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Certified {{Parsing}} of {{Regular Languages}}},
  isbn = {978-3-319-03545-1},
  abstract = {We report on a certified parser generator for regular languages using the Agda programming language. Specifically, we programmed a transformation of regular expressions into a Boolean-matrix based representation of nondeterministic finite automata (NFAs). And we proved (in Agda) that a string matches a regular expression if and only if the NFA accepts it. The proof of the if-part is effectively a function turning acceptance of a string into a parse tree while the only-if part gives a function turning rejection into a proof of impossibility of a parse tree.},
  language = {en},
  booktitle = {Certified {{Programs}} and {{Proofs}}},
  publisher = {{Springer International Publishing}},
  author = {Firsov, Denis and Uustalu, Tarmo},
  editor = {Gonthier, Georges and Norrish, Michael},
  year = {2013},
  keywords = {Incidence Matrix,Parse Tree,Pattern Match,Regular Expression,Regular Language},
  pages = {98-113}
}

@techreport{russino_polynomial_2017,
  title = {Polynomial {{Terms}} and {{Sparse Horner Normal Form}}},
  language = {en},
  url = {http://www.russinoff.com/papers/shnf.pdf},
  author = {Russinoff, David M},
  month = jul,
  year = {2017},
  pages = {8},
  file = {/Users/doisinkidney/Zotero/storage/XGCQCLFR/Russinoﬀ - Polynomial Terms and Sparse Horner Normal Form.pdf}
}

@misc{mcbride_polynomial_2018,
  type = {Tweet},
  title = {A {{Polynomial Testing Principle}}},
  abstract = {A polynomial testing principle gives a machine-checked proof that, under suitably controlled circumstances, in a small but familiar domain, testing can reveal the absence of bugs.},
  language = {en},
  urldate = {2018-08-23},
  journal = {Conor McBride's Twitter Feed},
  url = {https://twitter.com/pigworker/status/1013535783234473984},
  author = {McBride, Conor},
  month = jul,
  year = {2018},
  file = {/Users/doisinkidney/Zotero/storage/DB4NV3DI/1013535783234473984.html}
}

@inproceedings{kiselyov_extensible_2013-2,
  address = {New York, NY, USA},
  series = {Haskell '13},
  title = {Extensible {{Effects}}: {{An Alternative}} to {{Monad Transformers}}},
  isbn = {978-1-4503-2383-3},
  shorttitle = {Extensible {{Effects}}},
  abstract = {We design and implement a library that solves the long-standing problem of combining effects without imposing restrictions on their interactions (such as static ordering). Effects arise from interactions between a client and an effect handler (interpreter); interactions may vary throughout the program and dynamically adapt to execution conditions. Existing code that relies on monad transformers may be used with our library with minor changes, gaining efficiency over long monad stacks. In addition, our library has greater expressiveness, allowing for practical idioms that are inefficient, cumbersome, or outright impossible with monad transformers. Our alternative to a monad transformer stack is a single monad, for the coroutine-like communication of a client with its handler. Its type reflects possible requests, i.e., possible effects of a computation. To support arbitrary effects and their combinations, requests are values of an extensible union type, which allows adding and, notably, subtracting summands. Extending and, upon handling, shrinking of the union of possible requests is reflected in its type, yielding a type-and-effect system for Haskell. The library is lightweight, generalizing the extensible exception handling to other effects and accurately tracking them in types.},
  language = {en},
  urldate = {2018-08-24},
  booktitle = {Proceedings of the 2013 {{ACM SIGPLAN Symposium}} on {{Haskell}}},
  publisher = {{ACM}},
  doi = {10.1145/2503778.2503791},
  url = {http://okmij.org/ftp/Haskell/extensible/},
  author = {Kiselyov, Oleg and Sabry, Amr and Swords, Cameron},
  year = {2013},
  keywords = {Effects,Haskell,coroutine,effect handler,effect interaction,monad,monad transformer,open union,type and effect system},
  pages = {59--70},
  file = {/Users/doisinkidney/Zotero/storage/PDUC9QH6/exteff.pdf;/Users/doisinkidney/Zotero/storage/XTZHSAEH/Kiselyov et al. - 2013 - Extensible Effects An Alternative to Monad Transf.pdf}
}

@misc{meshveliani_docon-provable_2018,
  address = {Pereslavl - Zalessky},
  title = {{{DoCon}}-{{A}} a {{Provable Algebraic Domain Constructor}}},
  urldate = {2018-08-24},
  url = {http://www.botik.ru/pub/local/Mechveliani/docon-A/2.02/},
  author = {Meshveliani, Sergei D.},
  month = apr,
  year = {2018},
  file = {/Users/doisinkidney/Zotero/storage/KJL3PGNM/manual.pdf}
}

@article{coquand_isomorphism_2013,
  title = {Isomorphism Is Equality},
  volume = {24},
  issn = {00193577},
  abstract = {The setting of this work is dependent type theory extended with the univalence axiom. We prove that, for a large class of algebraic structures, isomorphic instances of a structure are equal\textemdash{}in fact, isomorphism is in bijective correspondence with equality. The class of structures includes monoids whose underlying types are ``sets'', and also posets where the underlying types are sets and the ordering relations are pointwise ``propositional''. For monoids on sets equality coincides with the usual notion of isomorphism from universal algebra, and for posets of the kind mentioned above equality coincides with order isomorphism.},
  language = {en},
  number = {4},
  urldate = {2018-08-25},
  journal = {Indagationes Mathematicae},
  doi = {10.1016/j.indag.2013.09.002},
  url = {http://www.cse.chalmers.se/~nad/publications/coquand-danielsson-isomorphism-is-equality.html},
  author = {Coquand, Thierry and Danielsson, Nils Anders},
  month = nov,
  year = {2013},
  pages = {1105-1120},
  file = {/Users/doisinkidney/Zotero/storage/8X25PWGE/Coquand and Danielsson - 2013 - Isomorphism is equality.pdf}
}

@inproceedings{oury_power_2008-1,
  address = {New York, NY, USA},
  series = {{{ICFP}} '08},
  title = {The {{Power}} of {{Pi}}},
  isbn = {978-1-59593-919-7},
  abstract = {This paper exhibits the power of programming with dependent types by dint of embedding three domain-specific languages: Cryptol, a language for cryptographic protocols; a small data description language; and relational algebra. Each example demonstrates particular design patterns inherent to dependently-typed programming. Documenting these techniques paves the way for further research in domain-specific embedded type systems.},
  urldate = {2018-08-25},
  booktitle = {Proceedings of the 13th {{ACM SIGPLAN International Conference}} on {{Functional Programming}}},
  publisher = {{ACM}},
  doi = {10.1145/1411204.1411213},
  url = {http://doi.acm.org/10.1145/1411204.1411213},
  author = {Oury, Nicolas and Swierstra, Wouter},
  year = {2008},
  keywords = {dependent types,domain-specific embedded languages},
  pages = {39--50},
  file = {/Users/doisinkidney/Zotero/storage/44IEPBZG/Oury and Swierstra - 2008 - The Power of Pi.pdf}
}

@article{curtis_calculating_2015,
  title = {Calculating a Linear-Time Solution to the Densest-Segment Problem},
  volume = {25},
  issn = {0956-7968, 1469-7653},
  abstract = {The problem of finding a densest segment of a list is similar to the well-known maximum segment sum problem, but its solution is surprisingly challenging. We give a general specification of such problems, and formally develop a linear-time online solution, using a sliding-window style algorithm. The development highlights some elegant properties of densities, involving partitions that are decreasing and all right-skew.},
  language = {en},
  urldate = {2018-08-26},
  journal = {Journal of Functional Programming},
  doi = {10.1017/S095679681500026X},
  url = {https://www.cambridge.org/core/journals/journal-of-functional-programming/article/calculating-a-lineartime-solution-to-the-densestsegment-problem/B7A7F3DB6A6220FB95F819F91BA94DCE},
  author = {Curtis, Sharon and Mu, Shin-Cheng},
  year = {2015/ed},
  file = {/Users/doisinkidney/Zotero/storage/5K72WV57/Curtis and Mu - 2015 - Calculating a linear-time solution to the densest-.pdf;/Users/doisinkidney/Zotero/storage/8LJU85AM/B7A7F3DB6A6220FB95F819F91BA94DCE.html}
}

@phdthesis{lioubartsev_constructing_2016,
  address = {Stockholm, Sweden},
  title = {Constructing a {{Computer Algebra System Capable}} of {{Generating Pedagogical Step}}-by-{{Step Solutions}}},
  abstract = {For the problem of producing pedagogical step-by-step so- lutions to mathematical problems in education, standard methods and algorithms used in construction of computer algebra systems are often not suitable. A method of us- ing rules to manipulate mathematical expressions in small steps is suggested and implemented. The problem of creat- ing a step-by-step solution by choosing which rule to apply and when to do it is redefined as a graph search problem and variations of the A* algorithm are used to solve it. It is all put together into one prototype solver that was evalu- ated in a study. The study was a questionnaire distributed among high school students. The results showed that while the solutions were not as good as human-made ones, they were competent. Further improvements of the method are suggested that would probably lead to better solutions.},
  urldate = {2016-08-26},
  school = {KTH Royal Institue of Technology},
  url = {http://www.diva-portal.se/smash/get/diva2:945222/FULLTEXT01.pdf},
  author = {Lioubartsev, Dmitrij},
  year = {2016},
  file = {/Users/doisinkidney/Zotero/storage/2Z62FSZP/FULLTEXT01.pdf}
}

@article{wood_translation_2009,
  title = {A {{Translation Method}} for {{Finding Combinatorial Bijections}}},
  volume = {13},
  issn = {0219-3094},
  abstract = {Consider a combinatorial identity that can be proved by induction. In this paper, we describe a general method for translating the inductive proof into a recursive bijection. Furthermore, we will demonstrate that the resulting recursive bijection can often be defined in a direct, non-recursive way. Thus, the translation method often results in a bijective proof of the identity that helps illuminate the underlying combinatorial structures. This paper has two main parts: First, we describe the translation method and the accompanying Maple code; and second, we give a few examples of how the method has been used to discover new bijections.},
  language = {en},
  number = {3},
  urldate = {2018-08-29},
  journal = {Annals of Combinatorics},
  doi = {10.1007/s00026-009-0024-y},
  url = {https://doi.org/10.1007/s00026-009-0024-y},
  author = {Wood, Philip Matchett and Zeilberger, Doron},
  month = oct,
  year = {2009},
  keywords = {05A19,bijection,bijective proof,combinatorial identity},
  pages = {383},
  file = {/Users/doisinkidney/Zotero/storage/6UJ9BBPT/Wood and Zeilberger - 2009 - A Translation Method for Finding Combinatorial Bij.pdf}
}

@phdthesis{van_der_walt_reflection_2012,
  type = {Master's {{Thesis}}},
  title = {Reflection in {{Agda}}},
  abstract = {This project explores the recent addition to Agda enabling reflection, in the style of Lisp, MetaML, and Template Haskell. It illustrates several possible applications of reflection that arise in dependently typed programming, and details the limitations of the current implementation of reflection. Examples of type-safe metaprograms are given that illustrate the power of reflection coupled with a dependently typed language. Among other things the limitations inherent in having quote and unquote implemented as keywords are highlighted. The fact that lambda terms are returned without typing information is discussed, and a solution is presented. Also provided is a detailed users' guide to the reflection API and a library of working code examples to illustrate how various common tasks can be performed, along with suggestions for an updated reflection API in a future version of Agda.},
  language = {en},
  urldate = {2018-09-16},
  school = {Universiteit of Utrecht},
  url = {https://dspace.library.uu.nl/handle/1874/256628},
  author = {{van der Walt}, P. D.},
  month = oct,
  year = {2012},
  file = {/Users/doisinkidney/Zotero/storage/X358AMNW/van der Walt - 2012 - Reflection in Agda.pdf;/Users/doisinkidney/Zotero/storage/8ZQY4FCH/256628.html}
}

@inproceedings{lindley_hasochism_2013,
  address = {New York, NY, USA},
  series = {Haskell '13},
  title = {Hasochism: {{The Pleasure}} and {{Pain}} of {{Dependently Typed Haskell Programming}}},
  isbn = {978-1-4503-2383-3},
  shorttitle = {Hasochism},
  abstract = {Haskell's type system has outgrown its Hindley-Milner roots to the extent that it now stretches to the basics of dependently typed programming. In this paper, we collate and classify techniques for programming with dependent types in Haskell, and contribute some new ones. In particular, through extended examples---merge-sort and rectangular tilings---we show how to exploit Haskell's constraint solver as a theorem prover, delivering code which, as Agda programmers, we envy. We explore the compromises involved in simulating variations on the theme of the dependent function space in an attempt to help programmers put dependent types to work, and to inform the evolving language design both of Haskell and of dependently typed languages more broadly.},
  urldate = {2018-08-29},
  booktitle = {Proceedings of the 2013 {{ACM SIGPLAN Symposium}} on {{Haskell}}},
  publisher = {{ACM}},
  doi = {10.1145/2503778.2503786},
  url = {http://doi.acm.org/10.1145/2503778.2503786},
  author = {Lindley, Sam and McBride, Conor},
  year = {2013},
  keywords = {dependent types,singletons,data type promotion,invariants,proof search},
  pages = {81--92},
  file = {/Users/doisinkidney/Zotero/storage/U7CFKDH5/Lindley and McBride - 2013 - Hasochism The Pleasure and Pain of Dependently Ty.pdf}
}

@inproceedings{dolan_fun_2013,
  address = {New York, NY, USA},
  series = {{{ICFP}} '13},
  title = {Fun with {{Semirings}}: {{A Functional Pearl}} on the {{Abuse}} of {{Linear Algebra}}},
  volume = {48},
  isbn = {978-1-4503-2326-0},
  shorttitle = {Fun with {{Semirings}}},
  abstract = {Describing a problem using classical linear algebra is a very well-known problem-solving technique. If your question can be formulated as a question about real or complex matrices, then the answer can often be found by standard techniques. It's less well-known that very similar techniques still apply where instead of real or complex numbers we have a closed semiring, which is a structure with some analogue of addition and multiplication that need not support subtraction or division. We define a typeclass in Haskell for describing closed semirings, and implement a few functions for manipulating matrices and polynomials over them. We then show how these functions can be used to calculate transitive closures, find shortest or longest or widest paths in a graph, analyse the data flow of imperative programs, optimally pack knapsacks, and perform discrete event simulations, all by just providing an appropriate underlying closed semiring.},
  language = {en},
  urldate = {2018-09-04},
  booktitle = {Proceedings of the 18th {{ACM SIGPLAN International Conference}} on {{Functional Programming}}},
  publisher = {{ACM}},
  doi = {10.1145/2500365.2500613},
  url = {https://www.cl.cam.ac.uk/~sd601/papers/semirings.pdf},
  author = {Dolan, Stephen},
  year = {2013},
  keywords = {closed semirings,linear systems,shortest paths,transitive closure},
  pages = {101--110},
  file = {/Users/doisinkidney/Zotero/storage/EUN94HUM/Dolan - Fun with Semirings.pdf}
}

@book{martin-lof_intuitionistic_1980,
  address = {Padua},
  title = {Intuitionistic {{Type Theory}}},
  url = {http://www.cse.chalmers.se/~peterd/papers/MartinL\%00f6f1984.pdf},
  author = {{Martin-L\"of}, Per},
  month = jun,
  year = {1980},
  file = {/Users/doisinkidney/Zotero/storage/IQS3729C/MartinLöf1984.pdf}
}

@misc{the_coq_development_team_2018_1219885,
  title = {The {{Coq Proof Assistant}}, Version 8.8.0},
  url = {https://doi.org/10.5281/zenodo.1219885},
  author = {Team, The Coq Development},
  month = apr,
  year = {2018}
}

@misc{escardo_libraries_2018,
  title = {Libraries for {{Bin}}},
  language = {en},
  urldate = {2018-09-12},
  url = {https://lists.chalmers.se/pipermail/agda/2018/010379.html},
  author = {Escardo, Martin},
  month = jul,
  year = {2018}
}

@misc{meshveliani_binary-4_2018,
  title = {Binary-4 \textendash{} a {{Pure Binary Natural Number Arithmetic}} Library for {{Agda}}},
  shorttitle = {Binary-4},
  abstract = {Binary-4 is a pure, regular-performance, complete, and certified binary arithmetic for natural numbers written in Agda.},
  url = {http://www.botik.ru/pub/local/Mechveliani/binNat/},
  author = {Meshveliani, Sergei},
  year = {21-Aug-2018}
}

@article{loulergue_calculating_2017,
  title = {Calculating {{Parallel Programs}} in {{Coq Using List Homomorphisms}}},
  volume = {45},
  issn = {0885-7458, 1573-7640},
  abstract = {SyDPaCC is a set of libraries for the Coq proof assistant. It allows to write naive functional programs (i.e. with high complexity) that are considered as specifications, and to transform them into more efficient versions. These more efficient versions can then be automatically parallelised before being extracted from Coq into source code for the functional language OCaml together with calls to the Bulk Synchronous Parallel ML (BSML) library. In this paper we present a new core version of SyDPaCC for the development of parallel programs correct-by-construction using the theory of list homomorphisms and algorithmic skeletons implemented and verified in Coq. The framework is illustrated on the maximum prefix sum problem.},
  language = {en},
  number = {2},
  urldate = {2018-09-13},
  journal = {International Journal of Parallel Programming},
  doi = {10.1007/s10766-016-0415-8},
  url = {http://link.springer.com/10.1007/s10766-016-0415-8},
  author = {Loulergue, Fr\'ed\'eric and Bousdira, Wadoud and Tesson, Julien},
  month = apr,
  year = {2017},
  pages = {300-319},
  file = {/Users/doisinkidney/Zotero/storage/UK3HBZKP/Loulergue et al. - 2017 - Calculating Parallel Programs in Coq Using List Ho.pdf}
}

@article{chuang_extraction_nodate,
  title = {Extraction of {{Programs}} for {{Exact Real Number Computation Using Agda}}},
  language = {en},
  author = {Chuang, Chi Ming},
  pages = {213},
  file = {/Users/doisinkidney/Zotero/storage/VTEGICG8/Chuang - Extraction of Programs for Exact Real Number Compu.pdf}
}

@article{ferreira_principles_nodate,
  title = {Principles and {{Applications}} of {{Algorithmic Problem Solving}}},
  language = {en},
  author = {Ferreira, Jo\~ao Fernando Peixoto},
  pages = {345},
  file = {/Users/doisinkidney/Zotero/storage/RF69IQLC/Ferreira - Principles and Applications of Algorithmic Problem.pdf}
}

@article{kokke_programming_nodate,
  title = {Programming Proof Search Using Reflection},
  abstract = {As proofs in type theory become increasingly complex, there is a growing need to provide better proof automation. This paper shows how to implement a Prolog-style resolution procedure in the dependently typed programming language Agda. Connecting this resolution procedure to Agda's reflection mechanism provides a first-class proof search tactic for first-order Agda terms. As a result, writing proof automation tactics need not be different from writing any other program.},
  language = {en},
  author = {Kokke, Pepijn and Swierstra, Wouter},
  pages = {27},
  file = {/Users/doisinkidney/Zotero/storage/8H5U9HPU/Kokke and Swierstra - Programming proof search using reﬂection.pdf}
}

@inproceedings{hutchison_tool_2006,
  address = {Berlin, Heidelberg},
  title = {A {{Tool}} for {{Automated Theorem Proving}} in {{Agda}}},
  volume = {3839},
  isbn = {978-3-540-31428-8 978-3-540-31429-5},
  abstract = {We present a tool for automated theorem proving in Agda, an implementation of Martin-L\"of's intuitionistic type theory. The tool is intended to facilitate interactive proving by relieving the user from filling in simple but tedious parts of a proof. The proof search is conducted directly in type theory and produces proof terms. Any proof term is verified by the Agda type-checker, which ensures soundness of the tool. Some effort has been spent on trying to produce human readable results, which allows the user to examine the generated proofs. We have tested the tool on examples mainly in the area of (functional) program verification. Most examples we have considered contain induction, and some contain generalisation. The contribution of this work outside the Agda community is to extend the experience of automated proof for intuitionistic type theory.},
  language = {en},
  urldate = {2018-09-13},
  booktitle = {Types for {{Proofs}} and {{Programs}}},
  publisher = {{Springer Berlin Heidelberg}},
  url = {http://link.springer.com/10.1007/11617990_10},
  author = {Lindblad, Fredrik and Benke, Marcin},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Filli\^atre, Jean-Christophe and {Paulin-Mohring}, Christine and Werner, Benjamin},
  year = {2006},
  keywords = {Elimination Rule,Type Theory,Logical Framework,Meta Variable,Proof Assistant},
  pages = {154-169},
  file = {/Users/doisinkidney/Zotero/storage/2LIWNNNY/Lindblad and Benke - 2006 - A Tool for Automated Theorem Proving in Agda.pdf;/Users/doisinkidney/Zotero/storage/BNCI9EYW/Lindblad and Benke - 2006 - A Tool for Automated Theorem Proving in Agda.pdf},
  doi = {10.1007/11617990_10}
}

@inproceedings{kokke_auto_2015,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Auto in {{Agda}}},
  isbn = {978-3-319-19797-5},
  abstract = {As proofs in type theory become increasingly complex, there is a growing need to provide better proof automation. This paper shows how to implement a Prolog-style resolution procedure in the dependently typed programming language Agda. Connecting this resolution procedure to Agda's reflection mechanism provides a first-class proof search tactic for first-order Agda terms. As a result, writing proof automation tactics need not be different from writing any other program.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer International Publishing}},
  url = {http://www.staff.science.uu.nl/~swier004/publications/2015-mpc.pdf},
  author = {Kokke, Pepijn and Swierstra, Wouter},
  editor = {Hinze, Ralf and Voigtl\"ander, Janis},
  year = {2015},
  keywords = {Abstract Syntax Tree,Goal Type,Implicit Argument,Proof Search,Unification Algorithm},
  pages = {276-301},
  file = {/Users/doisinkidney/Zotero/storage/8E57HAPM/Kokke and Swierstra - 2015 - Auto in Agda.pdf;/Users/doisinkidney/Zotero/storage/HPTCKCL2/Kokke and Swierstra - Programming proof search using reﬂection.pdf;/Users/doisinkidney/Zotero/storage/XU258KUR/Kokke and Swierstra - 2015 - Auto in Agda.pdf}
}

@incollection{thiemann_extensible_2016,
  address = {Berlin, Heidelberg},
  title = {Extensible and {{Efficient Automation Through Reflective Tactics}}},
  volume = {9632},
  isbn = {978-3-662-49497-4 978-3-662-49498-1},
  abstract = {Foundational proof assistants simultaneously offer both expressive logics and strong guarantees. The price they pay for this flexibility is often the need to build and check explicit proof objects which can be expensive. In this work we develop a collection of techniques for building reflective automation, where proofs are witnessed by verified decision procedures rather than verbose proof objects. Our techniques center around a verified domain specific language for proving, Rtac, written in Gallina, Coq's logic. The design of tactics makes it easy to combine them into higher-level automation that can be proved sound in a mostly automated way. Furthermore, unlike traditional uses of reflection, Rtac tactics are independent of the underlying problem domain. This allows them to be re-tasked to automate new problems with very little effort. We demonstrate the usability of Rtac through several case studies demonstrating orders of magnitude speedups for relatively little engineering work.},
  language = {en},
  urldate = {2018-09-15},
  booktitle = {Programming {{Languages}} and {{Systems}}},
  publisher = {{Springer Berlin Heidelberg}},
  url = {http://link.springer.com/10.1007/978-3-662-49498-1_21},
  author = {Malecha, Gregory and Bengtson, Jesper},
  editor = {Thiemann, Peter},
  year = {2016},
  pages = {532-559},
  file = {/Users/doisinkidney/Zotero/storage/DG5QW9GB/Malecha and Bengtson - 2016 - Extensible and Efficient Automation Through Reflec.pdf},
  doi = {10.1007/978-3-662-49498-1_21}
}

@incollection{bobaru_integrating_2011,
  address = {Berlin, Heidelberg},
  title = {Integrating an {{Automated Theorem Prover}} into {{Agda}}},
  volume = {6617},
  isbn = {978-3-642-20397-8 978-3-642-20398-5},
  abstract = {Agda is a dependently typed functional programming language and a proof assistant in which developing programs and proving their correctness is one activity. We show how this process can be enhanced by integrating external automated theorem provers, provide a prototypical integration of the equational theorem prover Waldmeister, and give examples of how this proof automation works in practice.},
  language = {en},
  urldate = {2018-09-15},
  booktitle = {{{NASA Formal Methods}}},
  publisher = {{Springer Berlin Heidelberg}},
  url = {http://link.springer.com/10.1007/978-3-642-20398-5_10},
  author = {Foster, Simon and Struth, Georg},
  editor = {Bobaru, Mihaela and Havelund, Klaus and Holzmann, Gerard J. and Joshi, Rajeev},
  year = {2011},
  pages = {116-130},
  file = {/Users/doisinkidney/Zotero/storage/KURGY5CK/Foster and Struth - 2011 - Integrating an Automated Theorem Prover into Agda.pdf},
  doi = {10.1007/978-3-642-20398-5_10}
}

@incollection{scholz_parsing_2011,
  address = {Berlin, Heidelberg},
  title = {Parsing {{Mixfix Operators}}},
  volume = {5836},
  isbn = {978-3-642-24451-3 978-3-642-24452-0},
  abstract = {A simple grammar scheme for expressions containing mixfix operators is presented. The scheme is parameterised by a precedence relation which is only restricted to be a directed acyclic graph; this makes it possible to build up precedence relations in a modular way. Efficient and simple implementations of parsers for languages with user-defined mixfix operators, based on the grammar scheme, are also discussed. In the future we plan to replace the support for mixfix operators in the language Agda with a grammar scheme and an implementation based on this work.},
  language = {en},
  urldate = {2018-09-16},
  booktitle = {Implementation and {{Application}} of {{Functional Languages}}},
  publisher = {{Springer Berlin Heidelberg}},
  url = {http://link.springer.com/10.1007/978-3-642-24452-0_5},
  author = {Danielsson, Nils Anders and Norell, Ulf},
  editor = {Scholz, Sven-Bodo and Chitil, Olaf},
  year = {2011},
  pages = {80-99},
  file = {/Users/doisinkidney/Zotero/storage/JFL9L879/Danielsson and Norell - 2011 - Parsing Mixfix Operators.pdf},
  doi = {10.1007/978-3-642-24452-0_5}
}

@article{danielsson_dependent_nodate,
  title = {Dependent Lenses},
  abstract = {Very well-behaved lenses provide a convenient mechanism for defining setters and getters for nested records (among other things). However, they do not work very well for dependent records, in which one field's type can depend on the value of a previous field.},
  language = {en},
  author = {Danielsson, Nils Anders},
  pages = {11},
  file = {/Users/doisinkidney/Zotero/storage/2JWJKWWL/Danielsson - Dependent lenses.pdf}
}

@article{allais_certied_nodate,
  title = {Certified {{Proof Search}} for {{Intuitionistic Linear Logic}}},
  abstract = {In this article we show the difficulties a type-theorist may face when attempting to formalise a decidability result described informally. We then demonstrate how generalising the problem and switching to a more structured presentation can alleviate her suffering.},
  language = {en},
  author = {Allais, Guillaume and McBride, Conor},
  pages = {15},
  file = {/Users/doisinkidney/Zotero/storage/4K9GKNQM/Allais and McBride - Certiﬁed Proof Search for Intuitionistic Linear Lo.pdf}
}

@article{allais_using_2011,
  title = {Using Reflection to Solve Some Differential Equations},
  abstract = {On top of coqtail's libraries that provide a formalization of power series, we added a small development that aims at simplifying proofs that given power series are solutions of specific differential equations. The use of reflection allows to prove general facts about differential equations which can then be used to simplify the proofs thanks to an Ltac machinery that performs the tedious conversions.},
  language = {en},
  author = {Allais, Guillaume},
  month = jun,
  year = {2011},
  pages = {6},
  file = {/Users/doisinkidney/Zotero/storage/CHYR3YFF/Allais - Using reﬂection to solve some diﬀerential equation.pdf}
}

@inproceedings{allais_new_2013,
  address = {Boston, Massachusetts, USA},
  title = {New Equations for Neutral Terms: A Sound and Complete Decision Procedure, Formalized},
  isbn = {978-1-4503-2384-0},
  shorttitle = {New Equations for Neutral Terms},
  abstract = {The definitional equality of an intensional type theory is its test of type compatibility. Today's systems rely on ordinary evaluation semantics to compare expressions in types, frustrating users with type errors arising when evaluation fails to identify two `obviously' equal terms. If only the machine could decide a richer theory! We propose a way to decide theories which supplement evaluation with `{$\nu$}-rules', rearranging the neutral parts of normal forms, and report a successful initial experiment.},
  language = {en},
  urldate = {2018-09-16},
  booktitle = {Proceedings of the 2013 {{ACM SIGPLAN}} Workshop on {{Dependently}}-Typed Programming - {{DTP}} '13},
  publisher = {{ACM Press}},
  doi = {10.1145/2502409.2502411},
  url = {http://dl.acm.org/citation.cfm?doid=2502409.2502411},
  author = {Allais, Guillaume and McBride, Conor and Boutillier, Pierre},
  year = {2013},
  keywords = {Computer Science - Programming Languages},
  pages = {13},
  file = {/Users/doisinkidney/Zotero/storage/9RFBSGFR/Allais et al. - 2013 - New Equations for Neutral Terms A Sound and Compl.pdf;/Users/doisinkidney/Zotero/storage/Y6EL76MR/Allais et al. - 2013 - New equations for neutral terms a sound and compl.pdf;/Users/doisinkidney/Zotero/storage/ZJ8H8B2U/1304.html}
}

@incollection{hinze_engineering_2013,
  address = {Berlin, Heidelberg},
  title = {Engineering {{Proof}} by {{Reflection}} in {{Agda}}},
  volume = {8241},
  isbn = {978-3-642-41581-4 978-3-642-41582-1},
  abstract = {This paper explores the recent addition to Agda enabling reflection, in the style of Lisp and Template Haskell. It gives a brief introduction to using reflection, and details the complexities encountered when automating certain proofs with proof by reflection. It presents a library that can be used for automatically quoting a class of concrete Agda terms to a non-dependent, user-defined inductive data type, alleviating some of the burden a programmer faces when using reflection in a practical setting.},
  language = {en},
  urldate = {2018-09-16},
  booktitle = {Implementation and {{Application}} of {{Functional Languages}}},
  publisher = {{Springer Berlin Heidelberg}},
  url = {http://link.springer.com/10.1007/978-3-642-41582-1_10},
  author = {{van der Walt}, Paul and Swierstra, Wouter},
  editor = {Hinze, Ralf},
  year = {2013},
  pages = {157-173},
  file = {/Users/doisinkidney/Zotero/storage/66IQWHX3/van der Walt and Swierstra - 2013 - Engineering Proof by Reflection in Agda.pdf},
  doi = {10.1007/978-3-642-41582-1_10}
}

@article{korkut_intrinsic_nodate,
  title = {Intrinsic {{Verification}} of a {{Regular Expression Matcher}}},
  abstract = {Harper's 1999 Functional Pearl on regular expression matching is a strong example of the interplay between programming and proof, and has been used for many years in introductory functional programming classes. In this paper, we revisit this algorithm from the point of view of dependently typed programming. In the process of formalizing the algorithm and its correctness using the Agda proof assistant, we found three interesting variations. First, defunctionalizing the matcher allows Agda to see termination without an explicit metric, and provides a simple first-order matcher with a clear relationship to the original, giving an alternative to a later Educational Pearl by Yi. Second, intrinsically verifying the soundness of the algorithm has useful computational content, allowing the extraction of matching strings from the parse tree. Third, while Harper uses a negative definition of standard regular expressions (no starred subexpression accepts the empty string), using a syntactic definition of standardness simplifies the staging of the development. These variations provide a nice illustration of the benefits of thinking in a dependently typed language, and have some pedagogical value for streamlining and extending the presentation of this material. {${_\ast}$}This material is based on research sponsored in part by by The United States Air Force Research Laboratory under agreement number FA9550-15-1-0053. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of the United States Air Force Research Laboratory, the U.S. Government or Carnegie Mellon University.},
  language = {en},
  author = {Korkut, Joomy and Trifunovski, Maksim and Licata, Daniel R},
  pages = {25},
  file = {/Users/doisinkidney/Zotero/storage/HTMKSUNR/Korkut et al. - Intrinsic Veriﬁcation of a Regular Expression Matc.pdf;/Users/doisinkidney/Zotero/storage/P934KSVE/Korkut et al. - Intrinsic Veriﬁcation of a Regular Expression Matc.pdf;/Users/doisinkidney/Zotero/storage/UK7N74L9/Korkut et al. - Intrinsic Veriﬁcation of a Regular Expression Matc.pdf}
}

@inproceedings{ml10sectyp,
  title = {Security-{{Typed Programming}} within {{Dependently}}-{{Typed Programming}}},
  booktitle = {International {{Conference}} on {{Functional Programming}}},
  author = {Morgenstern, Jamie and Licata, Daniel R.},
  year = {2010},
  file = {/Users/doisinkidney/Zotero/storage/WL4LDTFI/Morgenstern and Licata - 2010 - Security-Typed Programming within Dependently-Type.pdf}
}

@misc{allais_three_2016,
  title = {Three {{Tricks}} to Make {{Termination Obvious}}},
  abstract = {Two weeks ago I spent some time implementing Wadler's "Prettier Printer". The implementation is fairly straightforward except for three functions that are not seen as terminating. Here are the three tricks that made them go through.},
  urldate = {2018-09-16},
  journal = {gallais' blog},
  url = {https://gallais.github.io/blog/termination-tricks.html},
  author = {Allais, Guillaume},
  month = nov,
  year = {2016},
  file = {/Users/doisinkidney/Zotero/storage/ITLVNI2H/termination-tricks.html}
}

@inproceedings{abel_miniagda_2010,
  title = {{{MiniAgda}}: {{Integrating}} Sized and Dependent Types},
  shorttitle = {Miniagda},
  abstract = {Sized types are a modular and theoretically well-understood tool for checking termination of recursive and productivity of corecursive definitions. The essential idea is to track structural descent and guardedness in the type system to make termination checking robust and suitable for strong abstractions like higher-order functions and polymorphism. To study the application of sized types to proof assistants and programming languages based on dependent type theory, we have implemented a core language, MiniAgda, with explicit handling of sizes. New considerations were necessary to soundly integrate sized types with dependencies and pattern matching, which was made possible by modern concepts such as inaccessible patterns and parametric function spaces. This paper provides an introduction to MiniAgda by example and informal explanations of the underlying principles. 1},
  language = {en},
  booktitle = {{{PAR}}, Volume 43 of {{EPTCS}}},
  author = {Abel, Andreas},
  year = {2010},
  pages = {14--28},
  file = {/Users/doisinkidney/Zotero/storage/C8SGX7MN/Abel - 2010 - Miniagda Integrating sized and dependent types.pdf;/Users/doisinkidney/Zotero/storage/KP266WFQ/Abel - MiniAgda Integrating Sized and Dependent Types.pdf;/Users/doisinkidney/Zotero/storage/LCKS32ZV/summary\;jsessionid=11EAC1E0ADB87A0CC4E950303BE9DB40.html}
}

@misc{jedynak_simple_2018,
  title = {A Simple Demonstration of the {{Agda Reflection API}}.},
  urldate = {2018-09-17},
  url = {https://github.com/wjzz/Agda-reflection-for-semiring-solver},
  author = {Jedynak, Wojciech},
  month = sep,
  year = {2018}
}

@misc{norell_agda-prelude_2018,
  title = {Agda-Prelude: {{Programming}} Library for {{Agda}}},
  copyright = {MIT},
  shorttitle = {Agda-Prelude},
  abstract = {This is an alternative to the Agda standard library that focuses more on programming and type checking time performance.

Notable features:

Makes heavy use of instance arguments.

Efficient decision procedures for natural number arithmetic (Tactic.Nat).

Evidence-producing and efficient gcd and primality testing (Data.Nat.GCD and Data.Nat.Prime).

This is very much work in progress, so expect major changes. In particular the proof-side of things is very much unstructured.},
  urldate = {2018-09-17},
  url = {https://github.com/UlfNorell/agda-prelude},
  author = {Norell, Ulf},
  month = aug,
  year = {2018}
}

@phdthesis{christiansen_practical_2015,
  title = {Practical {{Reflection}} and {{Metaprogramming}} for {{Dependent Types}}},
  abstract = {Embedded domain-specific languages are special-purpose programming languages that are implemented within existing generalpurpose programming languages. Dependent type systems allow strong invariants to be encoded in representations of domain-specific languages, but it can also make it difficult to program in these embedded languages. Interpreters and compilers must always take these invariants into account at each stage, and authors of embedded languages must work hard to relieve users of the burden of proving these properties.},
  language = {en},
  school = {IT University of Copenhagen},
  url = {http://davidchristiansen.dk/david-christiansen-phd.pdf},
  author = {Christiansen, David Raymond},
  month = nov,
  year = {2015},
  file = {/Users/doisinkidney/Zotero/storage/NRBJRYLX/Christiansen - Practical Reflection and Metaprogramming for Depen.pdf}
}

@article{weirich_arity-generic_nodate,
  title = {Arity-{{Generic Datatype}}-{{Generic Programming}}},
  abstract = {Some programs are doubly-generic. For example, map is datatypegeneric in that many different data structures support a mapping operation. A generic programming language like Generic Haskell can use a single definition to generate map for each type. However, map is also arity-generic because it belongs to a family of related operations that differ in the number of arguments. For lists, this family includes repeat, map, zipWith, zipWith3, zipWith4, etc. With dependent types or clever programming, one can unify all of these functions together in a single definition.},
  language = {en},
  author = {Weirich, Stephanie and Casinghino, Chris},
  pages = {12},
  file = {/Users/doisinkidney/Zotero/storage/UM4HL7ZW/Weirich and Casinghino - Arity-Generic Datatype-Generic Programming.pdf}
}

@phdthesis{mu_calculational_2003-1,
  type = {Ph.{{D}}.},
  title = {A Calculational Approach to Program Inversion},
  language = {eng},
  urldate = {2018-09-18},
  school = {University of Oxford},
  url = {https://ethos.bl.uk/OrderDetails.do;jsessionid=797639DAEAA5E69A0BE5E51DACA5044F?uin=uk.bl.ethos.275405},
  author = {Mu, Shin-Cheng},
  month = jan,
  year = {2003},
  file = {/Users/doisinkidney/Zotero/storage/28FA7TKN/Mu - 2003 - A calculational approach to program inversion.pdf;/Users/doisinkidney/Zotero/storage/36Q9CI7P/Mu - 2003 - A calculational approach to program inversion.pdf;/Users/doisinkidney/Zotero/storage/4ZU2NBJK/Mu - A CALCULATIONAL APPROACH TO PROGRAM INVERSION.pdf;/Users/doisinkidney/Zotero/storage/BKUWKM3E/Mu - 2003 - A Calculational Approach to Program Inversion.pdf;/Users/doisinkidney/Zotero/storage/BS5W6V3A/Mu - 2003 - A Calculational Approach to Program Inversion.pdf;/Users/doisinkidney/Zotero/storage/DSZ23VZC/Mu - 2003 - A Calculational Approach to Program Inversion.pdf;/Users/doisinkidney/Zotero/storage/E54CP6N7/Mu - A CALCULATIONAL APPROACH TO PROGRAM INVERSION.pdf;/Users/doisinkidney/Zotero/storage/LENLXK88/thesis.pdf;/Users/doisinkidney/Zotero/storage/NRH5HGEB/Mu - 2003 - A Calculational Approach to Program Inversion.pdf;/Users/doisinkidney/Zotero/storage/VY4BY2SP/Mu - 2003 - A Calculational Approach to Program Inversion.pdf;/Users/doisinkidney/Zotero/storage/XCX94TJ3/Mu - A CALCULATIONAL APPROACH TO PROGRAM INVERSION.pdf;/Users/doisinkidney/Zotero/storage/XNJEQ9HW/Mu - A CALCULATIONAL APPROACH TO PROGRAM INVERSION.pdf;/Users/doisinkidney/Zotero/storage/ZLHTA8KC/Mu - 2003 - A Calculational Approach to Program Inversion.pdf;/Users/doisinkidney/Zotero/storage/PGMNKEZ7/OrderDetails.html;/Users/doisinkidney/Zotero/storage/X8F873MY/OrderDetails.html}
}

@misc{yang_well-founded_2010,
  title = {Well-Founded Recursion in {{Agda}}},
  shorttitle = {Well-Founded Recursion in {{Agda}}},
  language = {en-US},
  urldate = {2018-09-19},
  journal = {Inside 245-5D},
  url = {http://blog.ezyang.com/2010/06/well-founded-recursion-in-agda/},
  author = {Yang, Edward Z.},
  month = jun,
  year = {2010},
  file = {/Users/doisinkidney/Zotero/storage/IPAIWHEA/well-founded-recursion-in-agda.html}
}

@misc{diatchki_introducing_2010,
  title = {Introducing {{Well}}-{{Founded Recursion}}},
  shorttitle = {Galois \guilsinglright{} {{Blog}} \guilsinglright{} {{Blog}} \guillemotright{} {{Tech Talk}}},
  urldate = {2018-09-19},
  journal = {Galois {$>$} Blog},
  url = {https://web.archive.org/web/20100822202828/http://www.galois.com/blog/2010/06/11/tech-talk-introducing-well-founded-recursion/},
  author = {Diatchki, Iavor S.},
  month = jun,
  year = {2010},
  file = {/Users/doisinkidney/Zotero/storage/29UCZ6R2/tech-talk-introducing-well-founded-recursion.html}
}

@article{bove_modelling_2005,
  title = {Modelling General Recursion in Type Theory},
  volume = {15},
  issn = {0960-1295, 1469-8072},
  language = {en},
  number = {4},
  urldate = {2018-09-19},
  journal = {Mathematical Structures in Computer Science},
  doi = {10.1017/S0960129505004822},
  url = {http://www.journals.cambridge.org/abstract_S0960129505004822},
  author = {Bove, Ana and Capretta, Venanzio},
  month = jul,
  year = {2005},
  pages = {671-708},
  file = {/Users/doisinkidney/Zotero/storage/XJH42CYY/Bove and Capretta - 2005 - Modelling general recursion in type theory.pdf}
}

@article{nordstrom_terminating_1987,
  title = {Terminating General Recursion},
  volume = {28},
  issn = {0006-3835, 1572-9125},
  abstract = {In Martin-Lof's type theory, general recursion is not available. The only iterating constructs are primitive recursion over natural numbers and other inductive sets. The paper describes a way to allow a general recursion operator in type theory (extended with propositions). A proof rule for the new operator is presented. The addition of the new operator will not distroy the property that all well-typed programs terminate. An advantage of the new program construct is that it is possible to separate the termination proof of the program from the proof of other properties.},
  language = {en},
  number = {3},
  urldate = {2018-09-19},
  journal = {BIT},
  doi = {10.1007/BF01941137},
  url = {http://link.springer.com/10.1007/BF01941137},
  author = {Nordstr\"om, Bengt},
  month = sep,
  year = {1987},
  pages = {605-619},
  file = {/Users/doisinkidney/Zotero/storage/UKPV6PBD/Nordström - 1988 - Terminating general recursion.pdf}
}

@article{abel_wellfounded_2013,
  title = {Wellfounded {{Recursion}} with {{Copatterns}}},
  abstract = {In this paper, we study strong normalization of a core language based on System F{$\omega$} which supports programming with finite and infinite structures. Building on our prior work, finite data such as finite lists and trees are defined via constructors and manipulated via pattern matching, while infinite data such as streams and infinite trees is defined by observations and synthesized via copattern matching. In this work, we take a type-based approach to strong normalization by tracking size information about finite and infinite data in the type. This guarantees compositionality. More importantly, the duality of pattern and copatterns provide a unifying semantic concept which allows us for the first time to elegantly and uniformly support both well-founded induction and coinduction by mere rewriting. The strong normalization proof is structured around Girard's reducibility candidates. As such our system allows for non-determinism and does not rely on coverage. Since System F{$\omega$} is general enough that it can be the target of compilation for the Calculus of Constructions, this work is a significant step towards representing observation-centric infinite data in proof assistants such as Coq and Agda.},
  language = {en},
  url = {http://www2.tcs.ifi.lmu.de/\%7Eabel/icfp13-long.pdf},
  author = {Abel, Andreas and Pientka, Brigitte},
  month = jun,
  year = {2013},
  pages = {25},
  file = {/Users/doisinkidney/Zotero/storage/27CYWC4L/Abel and Pientka - Wellfounded Recursion with Copatterns.pdf}
}

@misc{mertens_introducing_2010,
  address = {Galois Inc. 421 SW 6th Ave. Suite 300, Portland, OR, USA},
  title = {Introducing {{Well}}-Founded {{Recursion}}},
  abstract = {Implementing recursive functions can be tricky when you want to be certain that they eventually terminate. This talk introduces the concept of well-founded recursion as a tool for implementing recursive functions. It implements these concepts in the Agda programming language and demonstrates the technique by implementing a simple version of Quicksort.},
  language = {en},
  urldate = {2016-04-26},
  url = {https://web.archive.org/web/20160426192417/http://code.galois.com/talk/2010/10-06-mertens.pdf},
  author = {Mertens, Eric},
  month = jun,
  year = {2010},
  file = {/Users/doisinkidney/Zotero/storage/AYDUTTXY/Mertens - Introducing Well-founded Recursion.pdf}
}

@misc{paulson2016future,
  title = {The {{Future}} of {{Formalised Mathematics}}},
  abstract = {Recent years have witnessed tremendous achievements in formalised mathe- matics, including the completion of the Flyspeck project (a machine-checked proof of the Kepler Conjecture) and the formalisation of the odd order theorem, the central limit the- orem and G\"odel's second incompleteness theorem. Formalised mathematics has started to attract the attention of mainstream mathematicians such as Harvey Friedman, Tim Gow- ers and Tom Hales. Nevertheless, there is much disagreement on the details of formalisms (constructive or classical, typed or typeless), proof languages (linear or structured) and automation (minimal, heuristic or algorithmic). The recent translation of the HOL Light multivariate analysis library to Isabelle highlights some of these di􏰀erences. The speaker will address these issues, referencing recent developments in the formalisation of real alge- braic geometry.},
  language = {en},
  url = {https://www.cl.cam.ac.uk/~lp15/papers/Formath/Future\%20of\%20formalised\%20maths.pdf},
  author = {Paulson, Lawrence C},
  year = {2016},
  file = {/Users/doisinkidney/Zotero/storage/R9S6SV6Y/Paulson - The Future of Formalised Mathematics.pdf}
}

@book{abel_foetus_1998,
  title = {Foetus \textendash{} {{Termination Checker}} for {{Simple Functional Programs}}},
  abstract = {We introduce a simple functional language foetus (lambda calculus with tuples, constructors and pattern matching) supplied with a termination checker. This checker tries to find a well-founded structural order on the parameters on the given function to prove termination. The components of the check algorithm are: function call extraction out of the program text, call graph completion and finding a lexical order for the function parameters. The HTML version of this paper contains many ready-to-run Web-based examples.},
  author = {Abel, Andreas},
  year = {1998},
  file = {/Users/doisinkidney/Zotero/storage/6RRBVHKX/Abel - 1998 - foetus – Termination Checker for Simple Functional.pdf;/Users/doisinkidney/Zotero/storage/K7PV9HSB/summary.html}
}

@inproceedings{atkey_syntax_2018,
  address = {Oxford, United Kingdom},
  title = {Syntax and {{Semantics}} of {{Quantitative Type Theory}}},
  isbn = {978-1-4503-5583-4},
  abstract = {We present Quantitative Type Theory, a Type Theory that records usage information for each variable in a judgement, based on a previous system by McBride. The usage information is used to give a realizability semantics using a variant of Linear Combinatory Algebras, refining the usual realizability semantics of Type Theory by accurately tracking resource behaviour. We define the semantics in terms of Quantitative Categories with Families, a novel extension of Categories with Families for modelling resource sensitive type theories.},
  language = {en},
  urldate = {2018-09-20},
  booktitle = {Proceedings of the 33rd {{Annual ACM}}/{{IEEE Symposium}} on {{Logic}} in {{Computer Science}}  - {{LICS}} '18},
  publisher = {{ACM Press}},
  doi = {10.1145/3209108.3209189},
  url = {http://dl.acm.org/citation.cfm?doid=3209108.3209189},
  author = {Atkey, Robert},
  year = {2018},
  pages = {56-65},
  file = {/Users/doisinkidney/Zotero/storage/3XYITYUB/Atkey - 2018 - Syntax and Semantics of Quantitative Type Theory.pdf}
}

@article{abel_resourceful_nodate,
  title = {Resourceful {{Dependent Types}}},
  language = {en},
  author = {Abel, Andreas},
  pages = {2},
  file = {/Users/doisinkidney/Zotero/storage/VQE7K7YK/Abel - Resourceful Dependent Types.pdf}
}

@article{shulman_type_nodate,
  title = {Type Theory and Category Theory},
  language = {en},
  author = {Shulman, Michael},
  pages = {126},
  file = {/Users/doisinkidney/Zotero/storage/UYEH5SND/Shulman - Type theory and category theory.pdf}
}

@article{isaza_category_2014,
  title = {Category {{Theory Applied}} to {{Functional Programming}}},
  language = {en},
  author = {Isaza, Juan Pedro Villa},
  year = {2014},
  pages = {131},
  file = {/Users/doisinkidney/Zotero/storage/ZEA9EU2W/Isaza - 2014 - Category Theory Applied to Functional Programming.pdf}
}

@phdthesis{blaguszewski_implementing_2010,
  address = {G\"oteborg, Sweden},
  type = {Master of {{Science Thesis}} in the {{Program CSALL}}},
  title = {Implementing and {{Optimizing}} a {{Simple}}, {{Dependently}}-{{Typed Language}}},
  abstract = {This thesis presents a compiler for the simple functional programming language LambdaPi, which includes dependent types. The compiler is written in Haskell and uses LLVM, a framework for building optimizing compiler backends. It can compile the complete standard library provided by LambdaPi's authors into native machine code. It is not much of an optimizing compiler, but several obvious opportunities for improvement exist.
First I discuss the theoretical background of project: the principles of dependent types and the languages which include them. I also give a brief overview of the LLVM system and of related work. The second section describes the process of implementation, which was done in stages from a trivial calculator language up to full LambdaPi. And finally we consider opportunities for optimization. Some of these stem from Edwin Brady's [2005] analysis of Epigram, while others are lower-level and can be performed for us by LLVM.},
  language = {en},
  urldate = {2018-09-20},
  school = {Chalmers University of Technology},
  url = {http://publications.lib.chalmers.se/records/fulltext/124826.pdf},
  author = {Blaguszewski, Michael},
  month = apr,
  year = {2010},
  file = {/Users/doisinkidney/Zotero/storage/PBMHDGYH/124826.pdf},
  note = {https://archives.haskell.org/code.haskell.org/LambdaPiC/}
}

@article{harper_foundations_nodate,
  title = {Foundations and {{Applications}} of {{Higher}}-{{Dimensional Directed Type Theory}}},
  language = {en},
  author = {Harper, Robert and Licata, Daniel R},
  year = {http://www.cs.cmu.edu/afs/.cs.cmu.edu/Web/People/drl/pubs/lh102dttnsf/lh102dttnsf.pdf},
  pages = {19},
  file = {/Users/doisinkidney/Zotero/storage/QYIZ3T43/Harper and Licata - Foundations and Applications of Higher-Dimensional.pdf}
}

@incollection{hutchison_bounded_2014,
  address = {Berlin, Heidelberg},
  title = {Bounded {{Linear Types}} in a {{Resource Semiring}}},
  volume = {8410},
  isbn = {978-3-642-54832-1 978-3-642-54833-8},
  abstract = {Bounded linear types have proved to be useful for automated resource analysis and control in functional programming languages. In this paper we introduce a bounded linear typing discipline on a general notion of resource which can be modeled in a semiring. For this type system we provide both a general type-inference procedure, parameterized by the decision procedure of the semiring equational theory, and a (coherent) categorical semantics. This could be a useful type-theoretic and denotational framework for resource-sensitive compilation, and it represents a generalization of several existing type systems. As a nontrivial instance, motivated by hardware compilation, we present a complex new application to calculating and controlling timing of execution in a (recursion-free) higher-order functional programming language with local store.},
  language = {en},
  urldate = {2018-09-20},
  booktitle = {Programming {{Languages}} and {{Systems}}},
  publisher = {{Springer Berlin Heidelberg}},
  url = {http://link.springer.com/10.1007/978-3-642-54833-8_18},
  author = {Ghica, Dan R. and Smith, Alex I.},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Shao, Zhong},
  year = {2014},
  pages = {331-350},
  file = {/Users/doisinkidney/Zotero/storage/I5EDLGEL/Ghica and Smith - 2014 - Bounded Linear Types in a Resource Semiring.pdf},
  doi = {10.1007/978-3-642-54833-8_18}
}

@article{abel_foetus_nodate,
  title = {Foetus - {{Termination Checker}} for {{Simple Functional Programs}}},
  abstract = {We introduce a simple functional language foetus (lambda calculus with tuples, constructors and pattern matching) supplied with a termination checker. This checker tries to find a well-founded structural order on the parameters on the given function to prove termination. The components of the check algorithm are: function call extraction out of the program text, call graph completion and finding a lexical order for the function parameters. The HTML version of this paper contains many ready-to-run Web-based examples.},
  language = {en},
  author = {Abel, Andreas},
  pages = {24},
  file = {/Users/doisinkidney/Zotero/storage/Q7LKRL9U/Abel - foetus - Termination Checker for Simple Functional.pdf}
}

@article{ko_programming_nodate,
  title = {Programming {{Metamorphic Algorithms}} in {{Agda}} ({{Functional Pearl}})},
  volume = {0},
  language = {en},
  number = {0},
  journal = {Proceedings of the ACM on Programming Languages},
  author = {Ko, Hsiang-Shang},
  pages = {26},
  file = {/Users/doisinkidney/Zotero/storage/8K25FUEB/Ko - Programming Metamorphic Algorithms in Agda (Functi.pdf;/Users/doisinkidney/Zotero/storage/8W52A5R5/Ko - Programming Metamorphic Algorithms in Agda (Functi.pdf}
}

@misc{licata_just_2011,
  title = {Just {{Kidding}}: {{Understanding Identity Elimination}} in {{Homotopy Type Theory}}},
  shorttitle = {Just {{Kidding}}},
  abstract = {Several current proof assistants, such as Agda and Epigram, provide uniqueness of identity proofs (UIP): any two proofs of the same propositional equality are themselves propositionally equal. Homo\ldots{}},
  language = {en},
  urldate = {2018-10-10},
  journal = {Homotopy Type Theory},
  url = {https://homotopytypetheory.org/2011/04/10/just-kidding-understanding-identity-elimination-in-homotopy-type-theory/},
  author = {Licata, Dan},
  month = apr,
  year = {2011},
  file = {/Users/doisinkidney/Zotero/storage/XP9CAKLA/just-kidding-understanding-identity-elimination-in-homotopy-type-theory.html}
}

@article{wadler_propositions_2015-1,
  title = {Propositions {{As Types}}},
  volume = {58},
  issn = {0001-0782},
  abstract = {Connecting mathematical logic and computation, it ensures that some aspects of programming are absolute.},
  number = {12},
  urldate = {2018-10-10},
  journal = {Commun. ACM},
  doi = {10.1145/2699407},
  url = {http://homepages.inf.ed.ac.uk/wadler/papers/propositions-as-types/propositions-as-types.pdf},
  author = {Wadler, Philip},
  month = nov,
  year = {2015},
  pages = {75--84},
  file = {/Users/doisinkidney/Zotero/storage/6QXRH73L/propositions-as-types.pdf;/Users/doisinkidney/Zotero/storage/X6HFPXQN/propositions-as-types.pdf}
}

@article{coquand_equality_nodate,
  title = {Equality and Dependent Type Theory},
  language = {en},
  author = {Coquand, Thierry},
  pages = {59},
  file = {/Users/doisinkidney/Zotero/storage/HY4TXI2B/Coquand - Equality and dependent type theory.pdf}
}

@article{chapman_biased_nodate,
  title = {A Biased History of Equality in Type Theory},
  language = {en},
  author = {Chapman, James},
  pages = {22},
  file = {/Users/doisinkidney/Zotero/storage/LY5XPTFM/Chapman - A biased history of equality in type theory.pdf}
}

@book{whitehead_principia_1910,
  title = {Principia {{Mathematica}}. {{Vol}}. {{I}}},
  language = {English},
  urldate = {2018-10-13},
  url = {https://zbmath.org/?q=an\%3A41.0083.02},
  author = {Whitehead, A. N. and Russell, B.},
  year = {1910},
  file = {/Users/doisinkidney/Zotero/storage/CQPMGYHN/zbmath.org.html}
}

@book{whitehead_principia_1913,
  title = {Principia Mathematica. {{Vol}}. {{III}}},
  language = {English},
  urldate = {2018-10-13},
  url = {https://zbmath.org/?q=an\%3A44.0068.01},
  author = {Whitehead, A. N. and Russell, B.},
  year = {1913},
  file = {/Users/doisinkidney/Zotero/storage/8KS6FPTF/zbmath.org.html},
  note = {Published: Cambridge: University Press. X u. 491 S. \$8\^\textbackslash{}circ\$ (1913).}
}

@book{whitehead_principia_1912,
  title = {Principia {{Mathematica}}. {{Vol}}. {{II}}},
  language = {English},
  urldate = {2018-10-13},
  url = {https://zbmath.org/?q=an\%3A43.0093.03},
  author = {Whitehead, A. N. and Russell, B.},
  year = {1912},
  file = {/Users/doisinkidney/Zotero/storage/YCYKF384/zbmath.org.html},
  note = {Published: Cambridge: University Press. xxxiv, 772 S. \$8\^\textbackslash{}circ\$ (1912).
MSC2010: 
                                                03-02
                                             = 
                                                Research monographs (mathematical logic)}
}

@article{gonthier_formal_2008,
  title = {Formal {{Proof}}\textemdash{{The Four}}-{{Color Theorem}}},
  volume = {55},
  language = {en},
  number = {11},
  journal = {Notices of the AMS},
  author = {Gonthier, Georges},
  year = {2008},
  pages = {12},
  file = {/Users/doisinkidney/Zotero/storage/254L4UBG/Gonthier - 2008 - Formal Proof—The Four- Color Theorem.pdf;/Users/doisinkidney/Zotero/storage/JNKRWD79/Gonthier - 2008 - Formal Proof—The Four- Color Theorem.pdf}
}

@article{appel_solution_1977,
  title = {The {{Solution}} of the {{Four}}-{{Color}}-{{Map Problem}}},
  volume = {237},
  issn = {0036-8733},
  number = {4},
  urldate = {2018-10-14},
  journal = {Scientific American},
  url = {http://www.jstor.org/stable/24953967},
  author = {Appel, Kenneth and Haken, Wolfgang},
  year = {1977},
  pages = {108-121},
  file = {/Users/doisinkidney/Zotero/storage/ZJTJRIZC/Appel and Haken - 1977 - The Solution of the Four-Color-Map Problem.pdf}
}

@misc{abel_sized_2008,
  address = {Sendai, Japan},
  title = {Sized {{Types}} in {{Agda}}},
  language = {en},
  urldate = {2018-10-16},
  url = {http://www.cse.chalmers.se/~abela/talkAIM2008Sendai.pdf},
  author = {Abel, Andreas},
  month = nov,
  year = {2008},
  file = {/Users/doisinkidney/Zotero/storage/GQYYZM4K/Abel - Sized Types in Agda.pdf}
}

@article{danielsson_up-techniques_2017,
  title = {Up-to Techniques Using Sized Types},
  volume = {2},
  issn = {24751421},
  language = {en},
  number = {POPL},
  urldate = {2018-10-16},
  journal = {Proceedings of the ACM on Programming Languages},
  doi = {10.1145/3158131},
  url = {http://dl.acm.org/citation.cfm?doid=3177123.3158131},
  author = {Danielsson, Nils Anders},
  month = dec,
  year = {2017},
  pages = {1-28},
  file = {/Users/doisinkidney/Zotero/storage/E6LZEWWR/Danielsson - 2017 - Up-to techniques using sized types.pdf}
}

@article{danielsson_beating_2010,
  title = {Beating the {{Productivity Checker Using Embedded Languages}}},
  volume = {43},
  issn = {2075-2180},
  language = {en},
  urldate = {2018-10-16},
  journal = {Electronic Proceedings in Theoretical Computer Science},
  doi = {10.4204/EPTCS.43.3},
  url = {http://arxiv.org/abs/1012.4898v1},
  author = {Danielsson, Nils Anders},
  month = dec,
  year = {2010},
  pages = {29-48},
  file = {/Users/doisinkidney/Zotero/storage/6M8A74JC/Danielsson - 2010 - Beating the Productivity Checker Using Embedded La.pdf}
}

@article{wadler_programming_nodate,
  title = {Programming {{Language Foundations}} in {{Agda}}},
  abstract = {One of the leading textbooks for formal methods is Software Foundations (SF), written by Benjamin Pierce in collaboration with others, and based on Coq. After five years using SF in the classroom, I have come to the conclusion that Coq is not the best vehicle for this purpose, as too much of the course needs to focus on learning tactics for proof derivation, to the cost of learning programming language theory. Accordingly, I have written a new textbook, Programming Language Foundations in Agda (PLFA). PLFA covers much of the same ground as SF, although it is not a slavish imitation.},
  language = {en},
  author = {Wadler, Philip},
  pages = {18},
  file = {/Users/doisinkidney/Zotero/storage/9JWDH3DW/Wadler - Programming Language Foundations in Agda.pdf;/Users/doisinkidney/Zotero/storage/KYHSNBQ8/Wadler - Programming Language Foundations in Agda.pdf}
}

@inproceedings{hinze_turing-completeness_2015,
  address = {Cham},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Turing-{{Completeness Totally Free}}},
  volume = {9129},
  isbn = {978-3-319-19796-8 978-3-319-19797-5},
  abstract = {In this paper, I show that general recursive definitions can be represented in the free monad which supports the `effect' of making a recursive call, without saying how these calls should be executed. Diverse semantics can be given within a total framework by suitable monad morphisms. The Bove-Capretta construction of the domain of a general recursive function can be presented datatype-generically as an instance of this technique. The paper is literate Agda, but its key ideas are more broadly transferable.},
  language = {en},
  urldate = {2018-10-17},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer International Publishing}},
  url = {http://link.springer.com/10.1007/978-3-319-19797-5_13},
  author = {McBride, Conor},
  editor = {Hinze, Ralf and Voigtl\"ander, Janis},
  year = {2015},
  keywords = {False Confession,General Recursion,Recursive Call,Recursive Definition,Strong Bisimulation},
  pages = {257-275},
  file = {/Users/doisinkidney/Zotero/storage/BZZTWWIB/McBride - 2015 - Turing-Completeness Totally Free.pdf;/Users/doisinkidney/Zotero/storage/NGRE4RGY/McBride - 2015 - Turing-Completeness Totally Free.pdf},
  doi = {10.1007/978-3-319-19797-5_13}
}

@phdthesis{girard_interpretation_1972,
  type = {{PhD Thesis}},
  title = {{Interpr\'etation fonctionelle et \'elimination des coupures de l'arithm\'etique d'ordre sup\'erieur}},
  language = {fr},
  school = {PhD thesis, Universit\'e Paris VII},
  author = {Girard, Jean-Yves},
  year = {1972},
  file = {/Users/doisinkidney/Zotero/storage/QLIN2G73/Girard - Interprétation fonctionnelle et élimination des co.pdf}
}

@article{zach_hilberts_2005,
  title = {Hilbert's {{Program Then}} and {{Now}}},
  language = {en},
  urldate = {2018-11-13},
  doi = {10.1016/B978-044451541-4/50014-2},
  url = {https://arxiv.org/abs/math/0508572},
  author = {Zach, Richard},
  month = aug,
  year = {2005},
  file = {/Users/doisinkidney/Zotero/storage/UDKTVSPU/Zach - 2005 - Hilbert's Program Then and Now.pdf;/Users/doisinkidney/Zotero/storage/FGBXZSY7/0508572.html}
}

@misc{might_missing_2015,
  title = {Missing Method: {{How}} to Delete from {{Okasaki}}'s Red-Black Trees},
  urldate = {2018-11-19},
  journal = {matt.might.net},
  url = {http://matt.might.net/articles/red-black-delete/},
  author = {Might, Matthew},
  month = nov,
  year = {2015},
  file = {/Users/doisinkidney/Zotero/storage/3DCFH2UZ/red-black-delete.html}
}

@article{johann_haskell_nodate,
  title = {Haskell {{Programming}} with {{Nested Types}}: {{A Principled Approach}}},
  abstract = {Initial algebra semantics is one of the cornerstones of the theory of modern functional programming languages. For each inductive data type, it provides a Church encoding for that type, a build combinator which constructs data of that type, a fold combinator which encapsulates structured recursion over data of that type, and a fold/build rule which optimises modular programs by eliminating from them data constructed using the build combinator, and immediately consumed using the fold combinator, for that type. It has long been thought that initial algebra semantics is not expressive enough to provide a similar foundation for programming with nested types in Haskell. Specifically, the standard folds derived from initial algebra semantics have been considered too weak to capture commonly occurring patterns of recursion over data of nested types in Haskell, and no build combinators or fold/build rules have until now been defined for nested types. This paper shows that standard folds are, in fact, sufficiently expressive for programming with nested types in Haskell. It also defines build combinators and fold/build fusion rules for nested types. It thus shows how initial algebra semantics provides a principled, expressive, and elegant foundation for programming with nested types in Haskell.},
  language = {en},
  author = {Johann, Patricia and Ghani, Neil},
  pages = {48},
  file = {/Users/doisinkidney/Zotero/storage/3XNE6NQU/Johann and Ghani - Haskell Programming with Nested Types A Principle.pdf}
}

@phdthesis{bayley_generic_2001,
  type = {{{PhD Thesis}}},
  title = {Generic Operations on Nested Datatypes},
  school = {University of Oxford},
  author = {Bayley, Ian},
  year = {2001},
  file = {/Users/doisinkidney/Zotero/storage/NN39JBC3/Bayley - 2001 - Generic operations on nested datatypes.pdf}
}

@inproceedings{goos_nested_1998-1,
  address = {Berlin, Heidelberg},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Nested Datatypes},
  volume = {1422},
  isbn = {978-3-540-64591-7 978-3-540-69345-1},
  abstract = {A nested datatype, also known as a non-regular datatype, is a parametrised datatype whose declaration involves different instances of the accompanying type parameters. Nested datatypes have been mostly ignored in functional programming until recently, but they are turning out to be both theoretically important and useful in practice. The aim of this paper is to suggest a functorial semantics for such datatypes, with an associated calculational theory that mirrors and extends the standard theory for regular datatypes. Though elegant and generic, the proposed approach appears more limited than one would like, and some of the limitations are discussed.},
  language = {en},
  urldate = {2018-11-19},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  url = {https://pdfs.semanticscholar.org/7f7b/0305ca441e3509750b24cff1f2b415d1020e.pdf},
  author = {Bird, Richard and Meertens, Lambert},
  editor = {Goos, Gerhard and Hartmanis, Juris and {van Leeuwen}, Jan and Jeuring, Johan},
  year = {1998},
  keywords = {Functional Programming,Functorial Semantic,Standard Semantic,Type Constructor,Type Nest},
  pages = {52-67},
  file = {/Users/doisinkidney/Zotero/storage/A4BNWD5F/Bird and Meertens - 1998 - Nested datatypes.pdf;/Users/doisinkidney/Zotero/storage/CPVGXSKB/Bird and Meertens - 1998 - Nested datatypes.pdf},
  doi = {10.1007/BFb0054285}
}

@book{mcbride_datatypes_2015,
  title = {Datatypes of {{Datatypes}}},
  author = {McBride, Conor},
  month = jul,
  year = {2015},
  file = {/Users/doisinkidney/Zotero/storage/QKDM8YLS/conor.pdf}
}

@book{hinze_perfect_1999,
  title = {Perfect {{Trees}} and {{Bit}}-Reversal {{Permutations}}},
  abstract = {A famous algorithm is the Fast Fourier Transform, or FFT. An efficient iterative version of the FFT algorithm performs as a first step a bit-reversal permutation of the input list. The bit-reversal permutation swaps elements whose indices have binary representations that are the reverse of each other. Using an amortized approach this operation can be made to run in linear time on a random-access machine. An intriguing question is whether a linear-time implementation is also feasible on a pointer machine, that is in a purely functional setting. We show that the answer to this question is in the affirmative. In deriving a solution we employ several advanced programming language concepts such as nested datatypes, associated fold and unfold operators, rank-2 types, and polymorphic recursion. 1 Introduction A bit-reversal permutation operates on lists whose length is n = 2 k for some natural number k and swaps elements whose indices have binary representations that are the reverse of eac...},
  author = {Hinze, Ralf},
  year = {1999},
  file = {/Users/doisinkidney/Zotero/storage/4YL437LK/Hinze - 1999 - Perfect Trees and Bit-reversal Permutations.pdf;/Users/doisinkidney/Zotero/storage/36WDN5QJ/summary.html}
}

@article{breitner_ready_2018-1,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1803.06960},
  title = {Ready, {{Set}}, {{Verify}}! {{Applying Hs}}-to-Coq to {{Real}}-World {{Haskell Code}} ({{Experience Report}})},
  volume = {2},
  issn = {2475-1421},
  abstract = {Good tools can bring mechanical verification to programs written in mainstream functional languages. We use hs-to-coq to translate significant portions of Haskell's containers library into Coq, and verify it against specifications that we derive from a variety of sources including type class laws, the library's test suite, and interfaces from Coq's standard library. Our work shows that it is feasible to verify mature, widely-used, highly optimized, and unmodified Haskell code. We also learn more about the theory of weight-balanced trees, extend hs-to-coq to handle partiality, and \textendash{} since we found no bugs \textendash{} attest to the superb quality of well-tested functional code.},
  number = {ICFP},
  urldate = {2018-11-19},
  journal = {Proc. ACM Program. Lang.},
  doi = {10.1145/3236784},
  url = {http://doi.acm.org/10.1145/3236784},
  author = {Breitner, Joachim and {Spector-Zabusky}, Antal and Li, Yao and Rizkallah, Christine and Wiegley, John and Weirich, Stephanie},
  month = jul,
  year = {2018},
  keywords = {Computer Science - Programming Languages,Coq,Haskell,verification},
  pages = {89:1--89:16},
  file = {/Users/doisinkidney/Zotero/storage/47CZT66A/Breitner et al. - 2018 - Ready, Set, Verify! Applying hs-to-coq to real-wor.pdf;/Users/doisinkidney/Zotero/storage/CVI5SUYL/Breitner et al. - 2018 - Ready, Set, Verify! Applying Hs-to-coq to Real-wor.pdf;/Users/doisinkidney/Zotero/storage/JNAKLLCA/Breitner et al. - 2018 - Ready, Set, Verify! Applying Hs-to-coq to Real-wor.pdf;/Users/doisinkidney/Zotero/storage/MQGZJBF3/Breitner et al. - 2018 - Ready, Set, Verify! Applying hs-to-coq to real-wor.pdf;/Users/doisinkidney/Zotero/storage/W3P8LJJX/Breitner et al. - 2018 - Ready, Set, Verify! Applying Hs-to-coq to Real-wor.pdf;/Users/doisinkidney/Zotero/storage/3NXQ32D7/1803.html;/Users/doisinkidney/Zotero/storage/ERIANH6Y/1803.html}
}

@misc{erdi_basics_2012,
  title = {Basics for a Modular Arithmetic Type in {{Agda}}},
  urldate = {2018-11-19},
  journal = {Cactus},
  url = {https://gergo.erdi.hu/blog/2012-03-11-basics_for_a_modular_arithmetic_type_in_agda/},
  author = {\'Erdi, Gerg{\H o}},
  month = mar,
  year = {2012},
  file = {/Users/doisinkidney/Zotero/storage/HRLQEN6M/2012-03-11-basics_for_a_modular_arithmetic_type_in_agda.html}
}

@misc{erdi_mod-n_2012,
  title = {Mod-{{N}} Counters in {{Agda}}},
  urldate = {2018-11-19},
  journal = {Cactus},
  url = {https://gergo.erdi.hu/blog/2012-02-19-mod-n_counters_in_agda/},
  author = {\'Erdi, Gerg{\H o}},
  month = feb,
  year = {2012},
  file = {/Users/doisinkidney/Zotero/storage/L2NKVBUF/2012-02-19-mod-n_counters_in_agda.html}
}

@misc{komuves_nested-sequence_2016,
  title = {Nested-Sequence: {{List}}-like Data Structures with {{O}}(Log(n)) Random Access},
  shorttitle = {Nested-Sequence},
  abstract = {List-like data structures implemented using nested data types and polymorphic recursion. Also called "n-ary random access lists". They supports O(log(n)) lookup while still having amortized O(1) access to the left end of the sequence. Somewhat similar to finger trees, but much simpler, and the ternary and quaternary versions are also more memory efficient; however, modifying the right end of the sequence is still slow. See Data.Nested.Seq for general comments and Data.Nested.Seq.Binary.Lazy for an explanation of the data structure.},
  urldate = {2018-11-19},
  url = {http://hackage.haskell.org/package/nested-sequence},
  author = {Komuves, Balazs and Divianszky, Peter},
  month = jul,
  year = {2016},
  file = {/Users/doisinkidney/Zotero/storage/TZ3MQZRN/nested-sequence.html}
}

@article{ben-amram_pointers_1992,
  title = {On {{Pointers Versus Addresses}}},
  volume = {39},
  issn = {0004-5411},
  number = {3},
  urldate = {2018-11-19},
  journal = {J. ACM},
  doi = {10.1145/146637.146666},
  url = {http://doi.acm.org/10.1145/146637.146666},
  author = {{Ben-Amram}, Amir M. and Galil, Zvi},
  month = jul,
  year = {1992},
  keywords = {incompressibility,pointer structures,random access memory},
  pages = {617--648},
  file = {/Users/doisinkidney/Zotero/storage/FK6IETSX/Ben-Amram and Galil - 1992 - On Pointers Versus Addresses.pdf}
}

@book{okasaki_purely_1999,
  title = {Purely {{Functional Data Structures}}},
  isbn = {978-0-521-66350-2},
  abstract = {Most books on data structures assume an imperative language such as C or C++. However, data structures for these languages do not always translate well to functional languages such as Standard ML, Haskell, or Scheme. This book describes data structures from the point of view of functional languages, with examples, and presents design techniques that allow programmers to develop their own functional data structures. The author includes both classical data structures, such as red-black trees and binomial queues, and a host of new data structures developed exclusively for functional languages. All source code is given in Standard ML and Haskell, and most of the programs are easily adaptable to other functional languages. This handy reference for professional programmers working with functional languages can also be used as a tutorial or for self-study.},
  language = {en},
  publisher = {{Cambridge University Press}},
  author = {Okasaki, Chris},
  month = jun,
  year = {1999},
  keywords = {Computers / Databases / General,Computers / Programming Languages / General,Computers / Software Development \& Engineering / General}
}

@misc{weirich_dependent_2017,
  address = {St. Louis, MO, USA},
  title = {Dependent {{Types}} in {{Haskell}}},
  abstract = {What has dependent type theory done for Haskell? Over the past ten years, the Glasgow Haskell compiler (GHC) has adopted many type system features inspired by dependent type theory. In this talk, I will discuss the influence of dependent types on the design of GHC and on the practice of Haskell programmers. In particular, I will walk through an extended example and use it to analyze what it means to program with with dependent types in Haskell. Throughout, I will will discuss what we have learned from this experiment in language design: what works now, what doesn't work yet, and what surprised us along the way.},
  urldate = {2018-11-19},
  url = {https://www.youtube.com/watch?v=wNa3MMbhwS4},
  author = {Weirich, Stephanie},
  month = sep,
  year = {2017}
}

@inproceedings{otwani_thoralf_2018,
  address = {New York, NY, USA},
  series = {Haskell 2018},
  title = {The {{Thoralf Plugin}}: {{For Your Fancy Type Needs}}},
  isbn = {978-1-4503-5835-4},
  shorttitle = {The {{Thoralf Plugin}}},
  abstract = {Many fancy types (e.g., generalized algebraic data types, type families) require a type checker plugin. These fancy types have a type index (e.g., type level natural numbers) with an equality relation that is difficult or impossible to represent using GHC's built-in type equality. The most practical way to represent these equality relations is through a plugin that asserts equality constraints. However, such plugins are difficult to write and reason about.   In this paper, we (1) present a formal theory of reasoning about the correctness of type checker plugins for type indices, and, (2) apply this theory in creating Thoralf, a generic and extensible plugin for type indices that translates GHC constraint problems to queries to an external SMT solver. By "generic and extensible", we mean the restrictions on extending Thoralf are slight, and, if some type index could be encoded as an SMT sort, then a programmer could extend Thoralf by providing this encoding function.},
  urldate = {2018-11-21},
  booktitle = {Proceedings of the 11th {{ACM SIGPLAN International Symposium}} on {{Haskell}}},
  publisher = {{ACM}},
  doi = {10.1145/3242744.3242754},
  url = {http://doi.acm.org/10.1145/3242744.3242754},
  author = {Otwani, Divesh and Eisenberg, Richard A.},
  year = {2018},
  keywords = {SMT,GHC,constraint solver,type checker plugin},
  pages = {106--118}
}

@article{danielsson_total_nodate,
  title = {Total {{Definitional Interpreters}} for {{Time}} and {{Space Complexity}}},
  language = {en},
  author = {Danielsson, Nils Anders},
  pages = {13},
  file = {/Users/doisinkidney/Zotero/storage/EVARU4C7/Danielsson - Total Definitional Interpreters for Time and Space.pdf;/Users/doisinkidney/Zotero/storage/U7Q7J7DD/Danielsson - Total Definitional Interpreters for Time and Space.pdf}
}

@misc{wiedijk_formalizing_2018,
  title = {Formalizing 100 {{Theorems}}},
  abstract = {There used to exist a "top 100" of mathematical theorems on the web, which is a rather arbitrary list (and most of the theorems seem rather elementary), but still is nice to look at. On the current page I will keep track of which theorems from this list have been formalized. Currently the fraction that already has been formalized seems to be
93\%

The page does not keep track of all formalizations of these theorems. It just shows formalizations in systems that have formalized a significant number of theorems, or that have formalized a theorem that none of the others have done. The systems that this page refers to are (in order of the number of theorems that have been formalized, so the more interesting systems for mathematics are near the top):
HOL Light 	86
Isabelle 	80
Coq 	69
Mizar 	69
Metamath 	69
ProofPower 	43
nqthm/ACL2 	18
PVS 	16
NuPRL/MetaPRL 	8

Theorems in the list which have not been formalized yet are in italics. Formalizations of constructive proofs are in italics too. The difficult proofs in the list (according to John all the others are not a serious challenge "given a week or two") have been underlined. The formalizations under a theorem are in the order of the list of systems, and not in chronological order.},
  urldate = {2018-11-27},
  url = {http://www.cs.ru.nl/~freek/100/},
  author = {Wiedijk, Freek},
  month = oct,
  year = {2018},
  file = {/Users/doisinkidney/Zotero/storage/9H2EFAFC/100.html}
}

@book{megill_metamath_2007,
  address = {Morrisville},
  title = {Metamath: A Computer Language for Pure Mathematics},
  isbn = {978-1-4116-3724-5},
  shorttitle = {Metamath},
  language = {en},
  publisher = {{Lulu Press}},
  author = {Megill, Norman},
  year = {2007},
  file = {/Users/doisinkidney/Zotero/storage/PRRBLF3A/Megill - 2007 - Metamath a computer language for pure mathematics.pdf},
  note = {OCLC: 924789462}
}

@article{loh_tutorial_2010,
  title = {A {{Tutorial Implementation}} of a {{Dependently Typed Lambda Calculus}}},
  volume = {102},
  issn = {0169-2968},
  abstract = {We present the type rules for a dependently typed core calculus together with a straightforward implementation in Haskell. We explicitly highlight the changes necessary to shift from a simply-typed lambda calculus to the dependently typed lambda calculus. We also describe how to extend our core language with data types and write several small example programs. The article is accompanied by an executable interpreter and example code that allows immediate experimentation with the system we describe.},
  language = {en},
  number = {2},
  urldate = {2018-11-30},
  journal = {Fundamenta Informaticae},
  url = {https://www.andres-loeh.de/LambdaPi/},
  author = {L\"oh, Andres and McBride, Conor and Swierstra, Wouter},
  month = jan,
  year = {2010},
  pages = {177-207},
  file = {/Users/doisinkidney/Zotero/storage/W8UML2IR/Loh et al. - A tutorial implementation of a dependently typed l.pdf}
}

@inproceedings{boutin_using_1997,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Using Reflection to Build Efficient and Certified Decision Procedures},
  isbn = {978-3-540-69530-1},
  abstract = {In this paper we explain how computational reflection can help build efficient certified decision procedure in reduction systems. We have developed a decision procedure on abelian rings in the Coq system but the approach we describe applies to all reduction systems that allow the definition of concrete types (or datatypes). We show that computational reflection is more efficient than an LCF-like approach to implement decision procedures in a reduction system. We discuss the concept of total reflection, which we have investigated in Coq using two facts: the extraction process available in Coq and the fact that the implementation language of the Coq system can be considered as a sublanguage of Coq. Total reflection is not yet implemented in Coq but we can test its performance as the extraction process is effective. Both reflection and total reflection are conservative extensions of the reduction system in which they are used. We also discuss performance and related approaches. In the paper,we assume basic knowledges of ML and proof-checkers.},
  language = {en},
  booktitle = {Theoretical {{Aspects}} of {{Computer Software}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Boutin, Samuel},
  editor = {Abadi, Mart\'in and Ito, Takayasu},
  year = {1997},
  keywords = {Computer Algebra System,Decision Procedure,Object Language,Order Theory,Reduction System},
  pages = {515-529},
  file = {/Users/doisinkidney/Zotero/storage/F9JMVUGU/Boutin - 1997 - Using reflection to build efficient and certified .pdf}
}

@book{Coq:manual,
  title = {The {{Coq Proof Assistant Reference Manual}}, Version 7.2},
  url = {http://coq.inria.fr},
  author = {Coq Development Team, The},
  year = {2002}
}

@book{peyton_jones_haskell_2003,
  address = {Cambridge, U.K. ; New York},
  title = {Haskell 98 Language and Libraries: The Revised Report},
  isbn = {978-0-521-82614-3},
  lccn = {QA76.73.H37 H37 2003},
  shorttitle = {Haskell 98 Language and Libraries},
  publisher = {{Cambridge University Press}},
  editor = {Peyton Jones, Simon L.},
  year = {2003},
  keywords = {Haskell (Computer program language)},
  note = {OCLC: ocm51271691}
}

@article{swierstra_verifying_2011,
  title = {Verifying the {{Problem}} of the {{Dutch National Flag}} in {{Agda}}},
  language = {en},
  author = {Swierstra, Wouter},
  year = {2011},
  pages = {12},
  file = {/Users/doisinkidney/Zotero/storage/AW25ZTCW/Swierstra - 2011 - Verifying the Problem of the Dutch National Flag i.pdf}
}

@article{antoy_proving_2017,
  title = {Proving {{Non}}-{{Deterministic Computations}} in {{Agda}}},
  volume = {234},
  issn = {2075-2180},
  language = {en},
  urldate = {2018-12-17},
  journal = {Electronic Proceedings in Theoretical Computer Science},
  doi = {10.4204/EPTCS.234.13},
  url = {http://arxiv.org/abs/1701.00636},
  author = {Antoy, Sergio and Hanus, Michael and Libby, Steven},
  month = jan,
  year = {2017},
  keywords = {Computer Science - Programming Languages,Computer Science - Software Engineering},
  pages = {180-195},
  file = {/Users/doisinkidney/Zotero/storage/74HVVLN7/Antoy et al. - 2017 - Proving Non-Deterministic Computations in Agda.pdf;/Users/doisinkidney/Zotero/storage/BTPERAI7/Antoy et al. - 2017 - Proving Non-Deterministic Computations in Agda.pdf;/Users/doisinkidney/Zotero/storage/LPTLYI5Z/1701.html}
}

@inproceedings{copello_case_2014,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Case of ({{Quite}}) {{Painless Dependently Typed Programming}}: {{Fully Certified Merge Sort}} in {{Agda}}},
  isbn = {978-3-319-11863-5},
  shorttitle = {Case of ({{Quite}}) {{Painless Dependently Typed Programming}}},
  abstract = {We present a full certification of merge sort in the language Agda. It features: termination warrant without explicit proof, no proof cost to ensure that the output is sorted, and a succinct proof that the output is a permutation of the input.},
  language = {en},
  booktitle = {Programming {{Languages}}},
  publisher = {{Springer International Publishing}},
  author = {Copello, Ernesto and Tasistro, \'Alvaro and Bianchi, Bruno},
  editor = {Quint\~ao Pereira, Fernando Magno},
  year = {2014},
  keywords = {Executable Code,Proof Obligation,Recursive Call,Termination Proof,Type Check},
  pages = {62-76},
  file = {/Users/doisinkidney/Zotero/storage/USMHHAXV/Copello et al. - 2014 - Case of (Quite) Painless Dependently Typed Program.pdf}
}

@article{meshveliani_provable_nodate,
  title = {Provable Programming of Algebra: Particular Points, Examples.},
  abstract = {It is discussed an experience in provable programming of a computer algebra library with using a purely functional language with dependent types (Agda). There are given several examples illustrating particular points of implementing the approach of constructive mathematics.},
  language = {en},
  author = {Meshveliani, Sergei D},
  pages = {5},
  file = {/Users/doisinkidney/Zotero/storage/NS5Q2FTS/Meshveliani - Provable programming of algebra particular points.pdf}
}

@inproceedings{mokhov_algebraic_2017,
  address = {New York, NY, USA},
  series = {Haskell 2017},
  title = {Algebraic {{Graphs}} with {{Class}} ({{Functional Pearl}})},
  isbn = {978-1-4503-5182-9},
  abstract = {The paper presents a minimalistic and elegant approach to working with graphs in Haskell. It is built on a rigorous mathematical foundation --- an algebra of graphs --- that allows us to apply equational reasoning for proving the correctness of graph transformation algorithms. Algebraic graphs let us avoid partial functions typically caused by `malformed graphs' that contain an edge referring to a non-existent vertex. This helps to liberate APIs of existing graph libraries from partial functions.   The algebra of graphs can represent directed, undirected, reflexive and transitive graphs, as well as hypergraphs, by appropriately choosing the set of underlying axioms. The flexibility of the approach is demonstrated by developing a library for constructing and transforming polymorphic graphs.},
  urldate = {2018-12-18},
  booktitle = {Proceedings of the 10th {{ACM SIGPLAN International Symposium}} on {{Haskell}}},
  publisher = {{ACM}},
  doi = {10.1145/3122955.3122956},
  url = {http://doi.acm.org/10.1145/3122955.3122956},
  author = {Mokhov, Andrey},
  year = {2017},
  keywords = {Haskell,algebra,graph theory},
  pages = {2--13},
  file = {/Users/doisinkidney/Zotero/storage/7TDCB7J6/Mokhov - 2017 - Algebraic Graphs with Class (Functional Pearl).pdf}
}

@article{dagand_essence_2017,
  title = {The Essence of Ornaments},
  volume = {27},
  issn = {0956-7968, 1469-7653},
  abstract = {Functional programmers from all horizons strive to use, and sometimes abuse, their favorite type system in order to capture the invariants of their programs. A widely used tool in that trade consists in defining finely indexed datatypes. Operationally, these types classify the programmer's data, following the ML tradition. Logically, these types enforce the program invariants in a novel manner. This new programming pattern, by which one programs over inductive definitions to account for some invariants, lead to the development of a theory of ornaments (McBride, 2011 Ornamental Algebras, Algebraic Ornaments. Unpublished). However, ornaments originate as a dependently-typed object and may thus appear rather daunting to a functional programmer of the non-dependent kind. This article aims at presenting ornaments from first-principles and, in particular, to declutter their presentation from syntactic considerations. To do so, we shall give a sufficiently abstract model of indexed datatypes by means of many-sorted signatures. In this process, we formalize our intuition that an indexed datatype is the combination of a data-structure and a data-logic. Over this abstraction of datatypes, we shall recast the definition of ornaments, effectively giving a model of ornaments. Benefiting both from the operational and abstract nature of many-sorted signatures, ornaments should appear applicable and, one hopes, of interest beyond the type-theoretic circles, case in point being languages with generalized abstract datatypes or refinement types.},
  language = {en},
  urldate = {2019-01-11},
  journal = {Journal of Functional Programming},
  doi = {10.1017/S0956796816000356},
  url = {https://www.cambridge.org/core/journals/journal-of-functional-programming/article/essence-of-ornaments/4D2DF6F4FE23599C8C1FEA6C921A3748},
  author = {Dagand, Pierre-Evariste},
  year = {2017/ed},
  file = {/Users/doisinkidney/Zotero/storage/TLH8A8K7/4D2DF6F4FE23599C8C1FEA6C921A3748.html}
}

@misc{the_development_team_step-by-step_2009,
  title = {Step-by-{{Step Math}}},
  language = {en},
  urldate = {2019-01-12},
  journal = {Wolfram|Alpha Blog},
  url = {http://blog.wolframalpha.com/2009/12/01/step-by-step-math/},
  author = {{The Development Team}},
  month = dec,
  year = {2009},
  file = {/Users/doisinkidney/Zotero/storage/AJUGXPVM/step-by-step-math.html}
}

@misc{wolfram_research_inc._wolframalpha_2019,
  title = {Wolfram|{{Alpha}}},
  urldate = {2019-01-12},
  howpublished = {Wolfram Research, Inc.},
  url = {https://www.wolframalpha.com/},
  author = {{Wolfram Research, Inc.}},
  year = {2019}
}

@misc{kahl_hundred_2004,
  title = {The {{Hundred Greatest Theorems}}},
  abstract = {The millenium seemed to spur a lot of people to compile "Top 100" or "Best 100" lists of many things, including movies (by the American Film Institute) and books (by the Modern Library). Mathematicians were not immune, and at a mathematics conference in July, 1999, Paul and Jack Abad presented their list of "The Hundred Greatest Theorems." Their ranking is based on the following criteria: "the place the theorem holds in the literature, the quality of the proof, and the unexpectedness of the result."

The list is of course as arbitrary as the movie and book list, but the theorems here are all certainly worthy results. I hope to over time include links to the proofs of them all; for now, you'll have to content yourself with the list itself and the biographies of the principals.},
  urldate = {2019-01-13},
  url = {http://web.archive.org/web/20080105074243/http://personal.stevens.edu/~nkahl/Top100Theorems.html},
  author = {Kahl, Nathan W.},
  year = {2004},
  file = {/Users/doisinkidney/Zotero/storage/44SQ7P3J/Top100Theorems.html}
}

@inproceedings{osera_programming_2016-1,
  address = {Nara, Japan},
  series = {{{TyDe}} 2016},
  title = {Programming Assistance for Type-Directed Programming (Extended Abstract)},
  isbn = {978-1-4503-4435-7},
  abstract = {Type-directed programming is a powerful programming paradigm where rich types dictate the structure of the program, making design largely automatic. While mechanical, this paradigm still requires manual reasoning that is both tedious and error-prone. We propose using type-directed program synthesis techniques to build an interactive programming assistant for type-directed programming. This tool bridges the gaps between simple auto-completion engines and program synthesis, complementing the strengths of each.},
  language = {en},
  urldate = {2019-01-15},
  booktitle = {Proceedings of the 1st {{International Workshop}} on {{Type}}-{{Driven Development}} - {{TyDe}} 2016},
  publisher = {{ACM Press}},
  doi = {10.1145/2976022.2976027},
  url = {http://dl.acm.org/citation.cfm?doid=2976022.2976027},
  author = {Osera, Peter-Michael},
  year = {2016},
  keywords = {Program Synthesis,Type-directed Programming},
  pages = {56-57},
  file = {/Users/doisinkidney/Zotero/storage/RJ53MDBI/Osera - 2016 - Programming assistance for type-directed programmi.pdf}
}

@inproceedings{sandberg_eriksson_agda_2016,
  address = {Nara, Japan},
  title = {An Agda Formalisation of the Transitive Closure of Block Matrices (Extended Abstract)},
  isbn = {978-1-4503-4435-7},
  abstract = {We define a block based matrix representation in Agda and lift various algebraic structures (semi-near-rings, semi-rings and closed semi-rings) to matrices in order to verify algorithms that can be implemented using the closure operation in a semi-ring.},
  language = {en},
  urldate = {2019-01-15},
  booktitle = {Proceedings of the 1st {{International Workshop}} on {{Type}}-{{Driven Development}} - {{TyDe}} 2016},
  publisher = {{ACM Press}},
  doi = {10.1145/2976022.2976025},
  url = {http://dl.acm.org/citation.cfm?doid=2976022.2976025},
  author = {Sandberg Eriksson, Adam and Jansson, Patrik},
  year = {2016},
  pages = {60-61},
  file = {/Users/doisinkidney/Zotero/storage/GDBW8VYF/Sandberg Eriksson and Jansson - 2016 - An agda formalisation of the transitive closure of.pdf;/Users/doisinkidney/Zotero/storage/LCUPT57N/Sandberg Eriksson and Jansson - 2016 - An agda formalisation of the transitive closure of.pdf}
}

@inproceedings{paykin_choose_2016,
  address = {Nara, Japan},
  title = {Choose Your Own Derivative (Extended Abstract)},
  isbn = {978-1-4503-4435-7},
  language = {en},
  urldate = {2019-01-15},
  booktitle = {Proceedings of the 1st {{International Workshop}} on {{Type}}-{{Driven Development}} - {{TyDe}} 2016},
  publisher = {{ACM Press}},
  doi = {10.1145/2976022.2976024},
  url = {http://dl.acm.org/citation.cfm?doid=2976022.2976024},
  author = {Paykin, Jennifer and {Spector-Zabusky}, Antal and Foner, Kenneth},
  year = {2016},
  pages = {58-59},
  file = {/Users/doisinkidney/Zotero/storage/7P3JCCPE/Paykin et al. - 2016 - choose your own derivative (extended abstract).pdf}
}

@inproceedings{diehl_generic_2016,
  title = {Generic Lookup and Update for Infinitary Inductive-Recursive Types},
  isbn = {978-1-4503-4435-7},
  urldate = {2019-01-15},
  booktitle = {Proceedings of the 1st {{International Workshop}} on {{Type}}-{{Driven Development}}},
  publisher = {{ACM}},
  doi = {10.1145/2976022.2976031},
  url = {http://dl.acm.org/citation.cfm?id=2976022.2976031},
  author = {Diehl, Larry and Sheard, Tim},
  month = sep,
  year = {2016},
  pages = {1-12}
}

@misc{noauthor_running_nodate,
  title = {Running the Classical Pigeonhole Principle in {{Agda}}},
  urldate = {2019-01-27},
  url = {http://www.cs.bham.ac.uk/~mhe/pigeon/},
  file = {/Users/doisinkidney/Zotero/storage/7U4XW4DX/pigeon.html}
}

@article{escardo_programs_nodate,
  title = {Programs from {{Proofs III Classical}} Countable Choice via Products of Selection Functions},
  language = {en},
  author = {Escardo, Mart\i{}n},
  pages = {53},
  file = {/Users/doisinkidney/Zotero/storage/EYSSR2J2/Escardo - Programs from Proofs III Classical countable choic.pdf}
}

@unpublished{allais_deciding_2011,
  title = {Deciding {{Presburger}} Arithmetic Using Reflection},
  abstract = {The need to prove or disprove a formula of Presburger arithmetic is quite frequent in certified software development (constraints generated automatically) or when working on higher arithmetic (number theory). The fact that this theory is decidable and that Agda is now mature enough to be able to implement such a solver pushed us to try to tackle this problem.},
  language = {en},
  url = {https://gallais.github.io/pdf/presburger10.pdf},
  author = {Allais, G},
  month = may,
  year = {2011},
  file = {/Users/doisinkidney/Zotero/storage/564IKBT9/Allais - Deciding Presburger arithmetic using reﬂection.pdf;/Users/doisinkidney/Zotero/storage/7JJJTEUI/Allais - Deciding Presburger arithmetic using reﬂection.pdf}
}

@article{gilbert_definitional_2019,
  title = {Definitional {{Proof}}-{{Irrelevance}} without {{K}}},
  abstract = {Definitional equality\textemdash{}or conversion\textemdash{}for a type theory with a decidable type checking is the simplest tool to prove that two objects are the same, letting the system decide just using computation. Therefore, the more things are equal by conversion, the simpler it is to use a language based on type theory. Proof-irrelevance, stating that any two proofs of the same proposition are equal, is a possible way to extend conversion to make a type theory more powerful. However, this new power comes at a price if we integrate it naively, either by making type checking undecidable or by realizing new axioms\textemdash{}such as uniqueness of identity proofs (UIP)\textemdash{}that are incompatible with other extensions, such as univalence. In this paper, taking inspiration from homotopy type theory, we propose a general way to extend a type theory with definitional proof irrelevance, in a way that keeps type checking decidable and is compatible with univalence. We provide a new criterion to decide whether a proposition can be eliminated over a type (correcting and improving the so-called singleton elimination of Coq) by using techniques coming from recent development on dependent pattern matching without UIP. We show the generality of our approach by providing implementations for both Coq and Agda, both of which are planned to be integrated in future versions of those proof assistants.},
  language = {en},
  urldate = {2019-02-18},
  journal = {Proceedings of the ACM on Programming Languages},
  doi = {10.1145/329031610.1145/3290316},
  url = {https://hal.inria.fr/hal-01859964/document},
  author = {Gilbert, Ga\"etan and Cockx, Jesper and Sozeau, Matthieu and Tabareau, Nicolas},
  month = jan,
  year = {2019},
  pages = {1-28},
  file = {/Users/doisinkidney/Zotero/storage/M2BHRXQ2/Gilbert et al. - 2019 - Definitional Proof-Irrelevance without K.pdf;/Users/doisinkidney/Zotero/storage/W2JCHYP3/hal-01859964.html}
}

@book{jones_scipy_2001,
  title = {{{SciPy}}: {{Open}} Source Scientific Tools for {{Python}}},
  url = {http://www.scipy.org/},
  author = {Jones, Eric and Oliphant, Travis and Peterson, Pearu and others},
  year = {2001}
}

@book{r_core_team_r_2013,
  address = {Vienna, Austria},
  title = {R: {{A Language}} and {{Environment}} for {{Statistical Computing}}},
  publisher = {{R Foundation for Statistical Computing}},
  url = {http://www.R-project.org/},
  author = {{R Core Team}},
  year = {2013}
}

@article{mahboubi_machine-checked_2016,
  title = {Machine-Checked Mathematics},
  volume = {5/17},
  abstract = {In this article she gives an overview about machine-checked mathematics.},
  language = {en},
  number = {3},
  urldate = {2019-02-21},
  journal = {Nieuw Archief voor Wiskunde},
  url = {https://hal.inria.fr/hal-01363284/document},
  author = {Mahboubi, Assia},
  month = sep,
  year = {2016},
  pages = {5},
  file = {/Users/doisinkidney/Zotero/storage/K4YFJJ3Y/Mahboubi - 2016 - Machine-checked mathematics.pdf;/Users/doisinkidney/Zotero/storage/33SI4PH7/hal-01363284.html}
}

@inproceedings{mahboubi_canonical_2013,
  title = {Canonical {{Structures}} for the Working {{Coq}} User},
  volume = {7998},
  abstract = {This paper provides a gentle introduction to the art of programming type inference with the mechanism of Canonical Structures. Programmable type inference has been one of the key ingredients for the successful formalization of the Odd Order Theorem using the Coq proof assistant. The paper concludes comparing the language of Canonical Structures to the one of Type Classes and Unification Hints.},
  language = {en},
  urldate = {2019-02-21},
  booktitle = {{{ITP}} 2013, 4th {{Conference}} on {{Interactive Theorem Proving}}},
  publisher = {{Springer}},
  doi = {10.1007/978-3-642-39634-2_5},
  url = {https://hal.inria.fr/hal-00816703/document},
  author = {Mahboubi, Assia and Tassi, Enrico},
  month = jul,
  year = {2013},
  pages = {19-34},
  file = {/Users/doisinkidney/Zotero/storage/3NBZE3DT/Mahboubi and Tassi - 2013 - Canonical Structures for the working Coq user.pdf;/Users/doisinkidney/Zotero/storage/R7NZ7LRQ/hal-00816703v2.html}
}

@article{hudson_certified_2015,
  title = {Certified {{Cost Bounds}} in {{Agda}}: {{A Step Towards Automated Complexity Analysis}}},
  shorttitle = {Certified {{Cost Bounds}} in {{Agda}}},
  journal = {Honors Theses - All},
  url = {https://wesscholar.wesleyan.edu/etd_hon_theses/1484},
  author = {Hudson, Bowornmet},
  month = apr,
  year = {2015},
  file = {/Users/doisinkidney/Zotero/storage/66ZL8F5E/1484.html}
}

@inproceedings{sozeau_program-ing_2007,
  address = {New York, NY, USA},
  series = {{{ICFP}} '07},
  title = {Program-Ing {{Finger Trees}} in {{Coq}}},
  isbn = {978-1-59593-815-2},
  abstract = {Finger Trees (Hinze \& Paterson, 2006) are a general purpose persistent data structure with good performance. Their genericity permits developing a wealth of structures like ordered sequences or interval trees on top of a single implementation. However, the type systems used by current functional languages do not guarantee the coherent parameterization and specialization of Finger Trees, let alone the correctness of their implementation. We present a certified implementation of Finger Trees solving these problems using the Program extension of Coq. We not only implement the structure but also prove its invariants along the way, which permit building certified structures on top of Finger Trees in an elegant way.},
  language = {en},
  urldate = {2019-02-23},
  booktitle = {Proceedings of the 12th {{ACM SIGPLAN International Conference}} on {{Functional Programming}}},
  publisher = {{ACM}},
  doi = {10.1145/1291151.1291156},
  url = {https://www.irif.fr/~sozeau/research/publications/Program-ing_Finger_Trees_in_Coq.pdf},
  author = {Sozeau, Matthieu},
  year = {2007},
  keywords = {dependent types,C<scp>oq</scp>,certification,finger trees},
  pages = {13--24},
  file = {/Users/doisinkidney/Zotero/storage/UCNWHJF9/Sozeau - Program-ing Finger Trees in Coq.pdf}
}

@article{alvarez-picallo_change_2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1902.05465},
  primaryClass = {cs},
  title = {Change {{Actions}}: {{Models}} of {{Generalised Differentiation}}},
  shorttitle = {Change {{Actions}}},
  abstract = {Cai et al. have recently proposed change structures as a semantic framework for incremental computation. We generalise change structures to arbitrary cartesian categories and propose the notion of change action model as a categorical model for (higher-order) generalised differentiation. Change action models naturally arise from many geometric and computational settings, such as (generalised) cartesian differential categories, group models of discrete calculus, and Kleene algebra of regular expressions. We show how to build canonical change action models on arbitrary cartesian categories, reminiscent of the F\textbackslash{}`aa di Bruno construction.},
  urldate = {2019-02-25},
  journal = {arXiv:1902.05465 [cs]},
  url = {http://arxiv.org/abs/1902.05465},
  author = {{Alvarez-Picallo}, Mario and Ong, C.-H. Luke},
  month = feb,
  year = {2019},
  keywords = {Computer Science - Logic in Computer Science},
  file = {/Users/doisinkidney/Zotero/storage/STD7IWA7/Alvarez-Picallo and Ong - 2019 - Change Actions Models of Generalised Differentiat.pdf;/Users/doisinkidney/Zotero/storage/JCD8WGLB/1902.html}
}

@article{alvarez-picallo_fixing_2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1811.06069},
  primaryClass = {cs},
  title = {Fixing {{Incremental Computation}}: {{Derivatives}} of {{Fixpoints}}, and the {{Recursive Semantics}} of {{Datalog}}},
  shorttitle = {Fixing {{Incremental Computation}}},
  abstract = {Incremental computation has recently been studied using the concepts of change structures and derivatives of programs, where the derivative of a function allows updating the output of the function based on a change to its input. We generalise change structures to change actions, and study their algebraic properties. We develop change actions for common structures in computer science, including directed-complete partial orders and Boolean algebras. We then show how to compute derivatives of fixpoints. This allows us to perform incremental evaluation and maintenance of recursively defined functions with particular application to generalised Datalog programs. Moreover, unlike previous results, our techniques are modular in that they are easy to apply both to variants of Datalog and to other programming languages.},
  urldate = {2019-02-25},
  journal = {arXiv:1811.06069 [cs]},
  url = {http://arxiv.org/abs/1811.06069},
  author = {{Alvarez-Picallo}, Mario and {Eyers-Taylor}, Alex and Jones, Michael Peyton and Ong, C.-H. Luke},
  month = nov,
  year = {2018},
  keywords = {Computer Science - Programming Languages},
  file = {/Users/doisinkidney/Zotero/storage/DRLGGEHA/Alvarez-Picallo et al. - 2018 - Fixing Incremental Computation Derivatives of Fix.pdf;/Users/doisinkidney/Zotero/storage/HZVQ5KSF/1811.html}
}

@article{van_dalen_war_1990,
  title = {The {{War}} of the {{Frogs}} and the {{Mice}}, or the {{Crisis}} of the {{Mathematische Annalen}}},
  volume = {12},
  issn = {0343-6993},
  language = {en},
  number = {4},
  urldate = {2019-03-14},
  journal = {The Mathematical Intelligencer},
  doi = {10.1007/BF03024028},
  url = {https://doi.org/10.1007/BF03024028},
  author = {{van Dalen}, D.},
  month = sep,
  year = {1990},
  keywords = {Chief Editor,Editorial Board,German Mathematician,Logna,Title Page},
  pages = {17-31},
  file = {/Users/doisinkidney/Zotero/storage/SIXGY7P7/van Dalen - 1990 - The War of the frogs and the mice, or the crisis o.pdf}
}

@inproceedings{magalhaes_hierarchy_2015,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Hierarchy in {{Generic Programming Libraries}}},
  isbn = {978-3-319-19797-5},
  abstract = {Generic programming (GP) is a form of abstraction in programming languages that serves to reduce code duplication by exploiting the regular structure of algebraic datatypes. Several different approaches to GP in Haskell have surfaced, giving rise to the problem of code duplication across GP libraries. Given the original goals of GP, this is a rather unfortunate turn of events. Fortunately, we can convert between the different representations of each approach, which allows us to ``borrow'' generic functions from different approaches, avoiding the need to reimplement every generic function in every single GP library.In previous work we have shown how existing GP libraries relate to each other. In this paper we go one step further and advocate ``hierarchical GP'': through proper design of different GP approaches, each library can fit neatly in a hierarchy, greatly minimizing the amount of supporting infrastructure necessary for each approach, and allowing each library to be specific and concise, while eliminating code duplication overall. We introduce a new library for GP in Haskell intended to sit at the top of the ``GP hierarchy''. This library contains a lot of structural information, and is not intended to be used directly. Instead, it is a good starting point for generating generic representations for other libraries. This approach is also suitable for being the only library with native compiler support; all other approaches can be obtained from this one by simple conversion of representations in plain Haskell code.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer International Publishing}},
  author = {Magalh\~aes, Jos\'e Pedro and L\"oh, Andres},
  editor = {Hinze, Ralf and Voigtl\"ander, Janis},
  year = {2015},
  keywords = {Constructor Argument,Generic Programming,Structure Library,Test Data Generation,Type Family},
  pages = {93-112},
  file = {/Users/doisinkidney/Zotero/storage/QWIB8FAB/Magalhães and Löh - 2015 - Hierarchy in Generic Programming Libraries.pdf}
}

@inproceedings{fischer_clear_2015-1,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {A {{Clear Picture}} of {{Lens Laws}}},
  isbn = {978-3-319-19797-5},
  abstract = {A lens is an optical device which refracts light. Properly adjusted, it can be used to project sharp images of objects onto a screen\textemdash{}a principle underlying photography as well as human vision. Striving for clarity, we shift our focus to lenses as abstractions for bidirectional programming. By means of standard mathematical terminology as well as intuitive properties of bidirectional programs, we observe different ways to characterize lenses and show exactly how their laws interact. Like proper adjustment of optical lenses is essential for taking clear pictures, proper organization of lens laws is essential for forming a clear picture of different lens classes. Incidentally, the process of understanding bidirectional lenses clearly is quite similar to the process of taking a good picture.By showing that it is exactly the backward computation which defines lenses of a certain standard class, we provide an unusual perspective, as contemporary research tends to focus on the forward computation.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer International Publishing}},
  author = {Fischer, Sebastian and Hu, Zhenjiang and Pacheco, Hugo},
  editor = {Hinze, Ralf and Voigtl\"ander, Janis},
  year = {2015},
  keywords = {Asymmetric Type,Equational Reasoning,Forward Computation,Injectivity Property,Post Editing},
  pages = {215-223},
  file = {/Users/doisinkidney/Zotero/storage/I2NLRPNX/Fischer et al. - 2015 - A Clear Picture of Lens Laws.pdf}
}

@inproceedings{salamanca_regular_2015,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Regular {{Varieties}} of {{Automata}} and {{Coequations}}},
  isbn = {978-3-319-19797-5},
  abstract = {In this paper we use a duality result between equations and coequations for automata, proved by Ballester-Bolinches, Cosme-Ll\'opez, and Rutten to characterize nonempty classes of deterministic automata that are closed under products, subautomata, homomorphic images, and sums. One characterization is as classes of automata defined by regular equations and the second one is as classes of automata satisfying sets of coequations called varieties of languages. We show how our results are related to Birkhoff's theorem for regular varieties.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer International Publishing}},
  author = {Salamanca, J. and {Ballester-Bolinches}, A. and Bonsangue, M. M. and {Cosme-Ll\'opez}, E. and Rutten, J. J. M. M.},
  editor = {Hinze, Ralf and Voigtl\"ander, Janis},
  year = {2015},
  pages = {224-237},
  file = {/Users/doisinkidney/Zotero/storage/T6TSLEHP/Salamanca et al. - 2015 - Regular Varieties of Automata and Coequations.pdf}
}

@inproceedings{dongol_program_2015,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {A {{Program Construction}} and {{Verification Tool}} for {{Separation Logic}}},
  isbn = {978-3-319-19797-5},
  abstract = {An algebraic approach to the design of program construction and verification tools is applied to separation logic. The control-flow level is modelled by power series with convolution as separating conjunction. A generic construction lifts resource monoids to assertion and predicate transformer quantales. The data domain is captured by concrete store-heap models. These are linked to the separation algebra by soundness proofs. Verification conditions and transformation or refinement laws are derived by equational reasoning within the predicate transformer quantale. This separation of concerns makes an implementation in the Isabelle/HOL proof assistant simple and highly automatic. The resulting tool is itself correct by construction; it is explained on three simple examples.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer International Publishing}},
  author = {Dongol, Brijesh and Gomes, Victor B. F. and Struth, Georg},
  editor = {Hinze, Ralf and Voigtl\"ander, Janis},
  year = {2015},
  keywords = {Proof Assistant,Predicate Transformer,Program Construction,Separation Logic,Verification Condition},
  pages = {137-158},
  file = {/Users/doisinkidney/Zotero/storage/BT4CVJFP/Dongol et al. - 2015 - A Program Construction and Verification Tool for S.pdf}
}

@inproceedings{wu_fusion_2015,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Fusion for {{Free}}},
  isbn = {978-3-319-19797-5},
  abstract = {Algebraic effect handlers are a recently popular approach for modelling side-effects that separates the syntax and semantics of effectful operations. The shape of syntax is captured by functors, and free monads over these functors denote syntax trees. The semantics is captured by algebras, and effect handlers pass these over the syntax trees to interpret them into a semantic domain.This approach is inherently modular: different functors can be composed to make trees with richer structure. Such trees are interpreted by applying several handlers in sequence, each removing the syntactic constructs it recognizes. Unfortunately, the construction and traversal of intermediate trees is painfully inefficient and has hindered the adoption of the handler approach.This paper explains how a sequence of handlers can be fused into one, so that multiple tree traversals can be reduced to a single one and no intermediate trees need to be allocated. At the heart of this optimization is keeping the notion of a free monad abstract, thus enabling a change of representation that opens up the possibility of fusion. We demonstrate how the ensuing code can be inlined at compile time to produce efficient handlers.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer International Publishing}},
  author = {Wu, Nicolas and Schrijvers, Tom},
  editor = {Hinze, Ralf and Voigtl\"ander, Janis},
  year = {2015},
  keywords = {Abstract Syntax Tree,Effect Handler,Intermediate Tree,Syntax Tree,Term Algebra},
  pages = {302-322},
  file = {/Users/doisinkidney/Zotero/storage/JD4GT9T3/Wu and Schrijvers - 2015 - Fusion for Free.pdf}
}

@inproceedings{van_staden_rely-guarantee_2015,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {On {{Rely}}-{{Guarantee Reasoning}}},
  isbn = {978-3-319-19797-5},
  abstract = {Many semantic models of rely-guarantee have been proposed in the literature. This paper proposes a new classification of the approaches into two groups based on their treatment of guarantee conditions. To allow a meaningful comparison, it constructs an abstract model for each group in a unified setting. The first model uses a weaker judgement and supports more general rules for atomic commands and disjunction. However, the stronger judgement of the second model permits the elegant separation of the rely from the guarantee due to Hayes et al. and allows refinement-style reasoning. The generalisation to models that use binary relations for postconditions is also investigated. An operational semantics is derived and both models are shown to be sound with respect to execution. All proofs have been checked with Isabelle/HOL and are available online.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer International Publishing}},
  author = {{van Staden}, Stephan},
  editor = {Hinze, Ralf and Voigtl\"ander, Janis},
  year = {2015},
  keywords = {Semantics,Concurrency,Rely-guarantee,Soundness},
  pages = {30-49},
  file = {/Users/doisinkidney/Zotero/storage/WWT8PYP8/van Staden - 2015 - On Rely-Guarantee Reasoning.pdf}
}

@inproceedings{berghammer_relation-algebraic_2015,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {A {{Relation}}-{{Algebraic Approach}} to {{Multirelations}} and {{Predicate Transformers}}},
  isbn = {978-3-319-19797-5},
  abstract = {The correspondence between up-closed multirelations and isotone predicate transformers is well known. Less known is that multirelations have also been used for modelling topological contact, not only computations. We investigate how properties from these two lines of research translate to predicate transformers. To this end, we express the correspondence of multirelations and predicate transformers using relation algebras. It turns out to be similar to the correspondence between contact relations and closure operations. Many results generalise from up-closed to arbitrary multirelations.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer International Publishing}},
  author = {Berghammer, Rudolf and Guttmann, Walter},
  editor = {Hinze, Ralf and Voigtl\"ander, Janis},
  year = {2015},
  pages = {50-70},
  file = {/Users/doisinkidney/Zotero/storage/NX6T9DSD/Berghammer and Guttmann - 2015 - A Relation-Algebraic Approach to Multirelations an.pdf}
}

@inproceedings{roocks_preference_2015,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Preference {{Decomposition}} and the {{Expressiveness}} of {{Preference Query Languages}}},
  isbn = {978-3-319-19797-5},
  abstract = {Preferences in the scope of relational databases allow modeling user wishes by queries with soft constraints. There are different frameworks for database preferences including commercially available systems. They slightly vary in semantics and expressiveness but have in common that preferences induce strict partial orders on a given data set. In the present paper we study the expressiveness of preference operators in the available implementations. Particularly, we search for decompositions of strict partial orders into fundamental preference constructs. We study which preference operators and operands are necessary to express any strict partial order. Finally, we present two decomposition algorithms and show their correctness.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer International Publishing}},
  author = {Roocks, Patrick},
  editor = {Hinze, Ralf and Voigtl\"ander, Janis},
  year = {2015},
  keywords = {Expressiveness,Preferences,Query languages,Relational algebra},
  pages = {71-92},
  file = {/Users/doisinkidney/Zotero/storage/GK5EZ4L2/Roocks - 2015 - Preference Decomposition and the Expressiveness of.pdf}
}

@inproceedings{berghammer_column-wise_2015,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Column-{{Wise Extendible Vector Expressions}} and the {{Relational Computation}} of {{Sets}} of {{Sets}}},
  isbn = {978-3-319-19797-5},
  abstract = {We present a technique for the relational computation of sets of sets. It is based on specific vector expressions, which form the syntactical counterparts of B. Kehden's vector predicates. Compared with the technique that directly solves a posed problem by the development of a vector expression of type \textbackslash{}(\{2\^X\}\textbackslash,\textbackslash{}leftrightarrow \textbackslash,\{\textbackslash{}mathbf\{1\}\textbackslash{}!\textbackslash{}!\textbackslash{}!\textbackslash{}mathbf\{1\}\}\textbackslash{}) from a formal logical problem description, we reduce the solution to the development of inclusions between vector expressions of type \textbackslash{}(\{X\}\textbackslash,\textbackslash{}leftrightarrow \textbackslash,\{\textbackslash{}mathbf\{1\}\textbackslash{}!\textbackslash{}!\textbackslash{}!\textbackslash{}mathbf\{1\}\}\textbackslash{}). Frequently, this is a lot simpler. The transition from the inclusions to the desired vector expression of type \textbackslash{}(\{2\^X\}\textbackslash,\textbackslash{}leftrightarrow \textbackslash,\{\textbackslash{}mathbf\{1\}\textbackslash{}!\textbackslash{}!\textbackslash{}!\textbackslash{}mathbf\{1\}\}\textbackslash{}) is then immediately possible by means of a general result. We apply the technique to some examples from different areas and show how the solutions behave with regard to running time if implemented and evaluated by the Kiel RelView tool.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer International Publishing}},
  author = {Berghammer, Rudolf},
  editor = {Hinze, Ralf and Voigtl\"ander, Janis},
  year = {2015},
  pages = {238-256},
  file = {/Users/doisinkidney/Zotero/storage/YNPZZ7QA/Berghammer - 2015 - Column-Wise Extendible Vector Expressions and the .pdf}
}

@inproceedings{bahr_calculating_2015,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Calculating {{Certified Compilers}} for {{Non}}-Deterministic {{Languages}}},
  isbn = {978-3-319-19797-5},
  abstract = {Reasoning about programming languages with non-deterministic semantics entails many difficulties. For instance, to prove correctness of a compiler for such a language, one typically has to split the correctness property into a soundness and a completeness part, and then prove these two parts separately. In this paper, we present a set of proof rules to prove compiler correctness by a single proof in calculational style. The key observation that led to our proof rules is the fact that the soundness and completeness proof follow a similar pattern with only small differences. We condensed these differences into a single side condition for one of our proof rules. This side condition, however, is easily discharged automatically by a very simple form of proof search. We implemented this calculation framework in the Coq proof assistant. Apart from verifying a given compiler, our proof technique can also be used to formally derive \textendash{} from the semantics of the source language \textendash{} a compiler that is correct by construction. For such a derivation to succeed it is crucial that the underlying correctness argument proceeds as a single calculation, as opposed to separate calculations of the two directions of the correctness property. We demonstrate our technique by deriving a compiler for a simple language with interrupts.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer International Publishing}},
  author = {Bahr, Patrick},
  editor = {Hinze, Ralf and Voigtl\"ander, Janis},
  year = {2015},
  keywords = {Proof Obligation,Induction Hypothesis,Side Condition,Target Language,Virtual Machine},
  pages = {159-186},
  file = {/Users/doisinkidney/Zotero/storage/STHEZK54/Bahr - 2015 - Calculating Certified Compilers for Non-determinis.pdf}
}

@inproceedings{abou-saleh_notions_2015-1,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Notions of {{Bidirectional Computation}} and~{{Entangled~State Monads}}},
  isbn = {978-3-319-19797-5},
  abstract = {Bidirectional transformations (bx) support principled consistency maintenance between data sources. Each data source corresponds to one perspective on a composite system, manifested by operations to `get' and `set' a view of the whole from that particular perspective. Bx are important in a wide range of settings, including databases, interactive applications, and model-driven development. We show that bx are naturally modelled in terms of mutable state; in particular, the `set' operations are stateful functions. This leads naturally to considering bx that exploit other computational effects too, such as I/O, nondeterminism, and failure, all largely ignored in the bx literature to date. We present a semantic foundation for symmetric bidirectional transformations with effects. We build on the mature theory of monadic encapsulation of effects in functional programming, develop the equational theory and important combinators for effectful bx, and provide a prototype implementation in Haskell along with several illustrative examples.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer International Publishing}},
  author = {{Abou-Saleh}, Faris and Cheney, James and Gibbons, Jeremy and McKinna, James and Stevens, Perdita},
  editor = {Hinze, Ralf and Voigtl\"ander, Janis},
  year = {2015},
  keywords = {Bidirectional Transformation,Effectful Computation,Entangle State,Equational Theory,Label Transition System},
  pages = {187-214},
  file = {/Users/doisinkidney/Zotero/storage/TP44YZCC/Abou-Saleh et al. - 2015 - Notions of Bidirectional Computation and Entangled.pdf}
}

@inproceedings{moller_exploring_2015,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Exploring an {{Interface Model}} for {{CKA}}},
  isbn = {978-3-319-19797-5},
  abstract = {Concurrent Kleene Algebras (CKAs) serve to describe general concurrent systems in a unified way at an abstract algebraic level. Recently, a graph-based model for CKA has been defined in which the incoming and outgoing edges of a graph define its input/output interface. The present paper provides a simplification and a significant extension of the original model to cover notions of states, predicates and assertions in the vein of algebraic treatments using modal semirings. Moreover, it uses the extension to set up a variant of the temporal logic \textbackslash{}(\textbackslash{}mathsf \{CTL\}\^*\textbackslash{}) for the interface model.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer International Publishing}},
  author = {M\"oller, Bernhard and Hoare, Tony},
  editor = {Hinze, Ralf and Voigtl\"ander, Janis},
  year = {2015},
  keywords = {Algebra,Concurrency,Formal methods,Temporal logic},
  pages = {1-29},
  file = {/Users/doisinkidney/Zotero/storage/SFEZXTCJ/Möller and Hoare - 2015 - Exploring an Interface Model for CKA.pdf}
}

@inproceedings{ghica_geometry_2012,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {The {{Geometry}} of {{Synthesis}}},
  isbn = {978-3-642-31113-0},
  abstract = {High-level synthesis or ``hardware compilation'' is a behavioural synthesis method in which circuits are specified using conventional programming languages. Such languages are generally recognised as more accessible than hardware description languages, and it is expected that their use would significantly increase design productivity. The Geometry of Synthesis is a new hardware compilation technique which achieves this goal in a semantic-directed fashion, by noting that functional programming languages and diagrammatic descriptions of hardware share a common mathematical structure, and by using the game-semantic model of the programming language to reduce all computational effects to signal-like message passing. As a consequence, this technique has mature support for higher-order functions [1], local (assignable) state [2], concurrency [3] and (affine) recursion [4]. Moreover, the compiler can support features such as separate compilation, libraries and a foreign-function interface [5]. The programming language of GoS, Verity, is an ``Algol-like'' language [6] extended with concurrency features [7]. The interplay between the call-by-name function mechanism and local effects, an approach specific to Algol, is the key ingredient which makes it possible for a large class of programs in this language to have finitely representable semantic models which can be synthesised as stand-alone static circuits. The compiler is available as an open-source download.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Ghica, Dan R.},
  editor = {Gibbons, Jeremy and Nogueira, Pablo},
  year = {2012},
  keywords = {Conventional Programming,Hardware Description Language,Note Theor,Programming Language,Type Inference},
  pages = {23-24},
  file = {/Users/doisinkidney/Zotero/storage/2ELVRESV/Ghica - 2012 - The Geometry of Synthesis.pdf}
}

@inproceedings{sergey_calculating_2012,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Calculating {{Graph Algorithms}} for {{Dominance}} and {{Shortest Path}}},
  isbn = {978-3-642-31113-0},
  abstract = {We calculate two iterative, polynomial-time graph algorithms from the literature: a dominance algorithm and an algorithm for the single-source shortest path problem. Both algorithms are calculated directly from the definition of the properties by fixed-point fusion of (1) a least fixed point expressing all finite paths through a directed graph and (2) Galois connections that capture dominance and path length.The approach illustrates that reasoning in the style of fixed-point calculus extends gracefully to the domain of graph algorithms. We thereby bridge common practice from the school of program calculation with common practice from the school of static program analysis, and build a novel view on iterative graph algorithms as instances of abstract interpretation.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Sergey, Ilya and Midtgaard, Jan and Clarke, Dave},
  editor = {Gibbons, Jeremy and Nogueira, Pablo},
  year = {2012},
  keywords = {dominance,fixed-point calculus,fixed-point fusion,Galois connections,graph algorithms,shortest path algorithm},
  pages = {132-156},
  file = {/Users/doisinkidney/Zotero/storage/U26TRXX8/Sergey et al. - 2012 - Calculating Graph Algorithms for Dominance and Sho.pdf}
}

@inproceedings{moller_algebraic_2012,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {An {{Algebraic Calculus}} of {{Database Preferences}}},
  isbn = {978-3-642-31113-0},
  abstract = {Preference algebra, an extension of the algebra of database relations, is a well-studied field in the area of personalized databases. It allows modelling user wishes by preference terms; they represent strict partial orders telling which database objects the user prefers over other ones. There are a number of constructors that allow combining simple preferences into quite complex, nested ones. A preference term is then used as a database query, and the results are the maximal objects according to the order it denotes. Depending on the size of the database, this can be computationally expensive. For optimisation, preference queries and the corresponding terms are transformed using a number of algebraic laws. So far, the correctness proofs for such laws have been performed by hand and in a point-wise fashion. We enrich the standard theory of relational databases to an algebraic framework that allows completely point-free reasoning about complex preferences. This black-box view is amenable to a treatment in first-order logic and hence to fully automated proofs using off-the-shelf verification tools. We exemplify the use of the calculus with some non-trivial laws, notably concerning so-called preference prefilters which perform a preselection to speed up the computation of the maximal objects proper.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {M\"oller, Bernhard and Roocks, Patrick and Endres, Markus},
  editor = {Gibbons, Jeremy and Nogueira, Pablo},
  year = {2012},
  keywords = {relational algebra,preference algebra,preferences,prefilter},
  pages = {241-262},
  file = {/Users/doisinkidney/Zotero/storage/MN66Q2D8/Möller et al. - 2012 - An Algebraic Calculus of Database Preferences.pdf}
}

@inproceedings{backhouse_first-past--post_2012,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {First-{{Past}}-the-{{Post Games}}},
  isbn = {978-3-642-31113-0},
  abstract = {Informally, a first-past-the-post game is a (probabilistic) game where the winner is the person who predicts the event that occurs first among a set of events. Examples of first-past-the-post games include so-called block and hidden patterns and the Penney-Ante game invented by Walter Penney. We formalise the abstract notion of a first-past-the-post game, and the process of extending a probability distribution on symbols of an alphabet to the plays of a game.Analysis of first-past-the-post games depends on a collection of simultaneous (non-linear) equations in languages. Essentially, the equations are due to Guibas and Odlyzko but they did not formulate them as equations in languages but as equations in generating functions detailing lengths of words.Penney-Ante games are two-player games characterised by a collection of regular, prefix-free languages. For such two-player games, we show how to use the equations in languages to calculate the probability of winning. The formula generalises a formula due to John H. Conway for the original Penney-Ante game. At no point in our analysis do we use generating functions. Even so, we are able to calculate probabilities and expected values. Generating functions do appear to become necessary when higher-order cumulatives (for example, the standard deviation) are also required.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Backhouse, Roland},
  editor = {Gibbons, Jeremy and Nogueira, Pablo},
  year = {2012},
  keywords = {algorithmic problem solving,block pattern,generating function,hidden pattern,Penney-Ante,probabilistic game,regular language},
  pages = {157-176},
  file = {/Users/doisinkidney/Zotero/storage/PUSQ84MK/Backhouse - 2012 - First-Past-the-Post Games.pdf}
}

@inproceedings{paterson_constructing_2012,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Constructing {{Applicative Functors}}},
  isbn = {978-3-642-31113-0},
  abstract = {Applicative functors define an interface to computation that is more general, and correspondingly weaker, than that of monads. First used in parser libraries, they are now seeing a wide range of applications. This paper sets out to explore the space of non-monadic applicative functors useful in programming. We work with a generalization, lax monoidal functors, and consider several methods of constructing useful functors of this type, just as transformers are used to construct computational monads. For example, coends, familiar to functional programmers as existential types, yield a range of useful applicative functors, including left Kan extensions. Other constructions are final fixed points, a limited sum construction, and a generalization of the semi-direct product of monoids. Implementations in Haskell are included where possible.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Paterson, Ross},
  editor = {Gibbons, Jeremy and Nogueira, Pablo},
  year = {2012},
  keywords = {Monoidal Structure,Type Constructor,Applicative Functor,Monoidal Category,Natural Transformation},
  pages = {300-323},
  file = {/Users/doisinkidney/Zotero/storage/ZQQYIAWZ/Paterson - 2012 - Constructing Applicative Functors.pdf}
}

@inproceedings{barthe_probabilistic_2012-1,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Probabilistic {{Relational Hoare Logics}} for {{Computer}}-{{Aided Security Proofs}}},
  isbn = {978-3-642-31113-0},
  abstract = {Provable security. The goal of provable security is to verify rigorously the security of cryptographic systems. A provable security argument proceeds in three steps: 1 Define a security goal and an adversarial model; 2 Define the cryptographic system and the security assumptions upon which the security of the system hinges; 3 Show by reduction that any attack against the cryptographic system can be used to build an efficient algorithm that breaks a security assumption.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Barthe, Gilles and Gr\'egoire, Benjamin and Zanella B\'eguelin, Santiago},
  editor = {Gibbons, Jeremy and Nogueira, Pablo},
  year = {2012},
  keywords = {Adversarial Model,Cryptographic System,Initial Memory,Provable Security,Security Goal},
  pages = {1-6},
  file = {/Users/doisinkidney/Zotero/storage/CAMJI7M3/Barthe et al. - 2012 - Probabilistic Relational Hoare Logics for Computer.pdf}
}

@inproceedings{bahr_modular_2012,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Modular {{Tree Automata}}},
  isbn = {978-3-642-31113-0},
  abstract = {Tree automata are traditionally used to study properties of tree languages and tree transformations. In this paper, we consider tree automata as the basis for modular and extensible recursion schemes. We show, using well-known techniques, how to derive from standard tree automata highly modular recursion schemes. Functions that are defined in terms of these recursion schemes can be combined, reused and transformed in many ways. This flexibility facilitates the specification of complex transformations in a concise manner, which is illustrated with a number of examples.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Bahr, Patrick},
  editor = {Gibbons, Jeremy and Nogueira, Pablo},
  year = {2012},
  keywords = {Function Symbol,Recursion Scheme,Successor State,Tree Automaton,Type Term},
  pages = {263-299},
  file = {/Users/doisinkidney/Zotero/storage/Q5C5UKQ3/Bahr - 2012 - Modular Tree Automata.pdf}
}

@inproceedings{armstrong_dependently_2012,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Dependently {{Typed Programming Based}} on {{Automated Theorem Proving}}},
  isbn = {978-3-642-31113-0},
  abstract = {Mella is a minimalistic dependently typed programming language and interactive theorem prover implemented in Haskell. Its main purpose is to investigate the effective integration of automated theorem provers in this pure and simple setting. Such integrations are essential for supporting program development in dependently typed languages. We integrate the equational theorem prover Waldmeister and test it on more than 800 proof goals from the TPTP library. In contrast to previous approaches, the reconstruction of Waldmeister proofs within Mella is quite robust and does not generate a significant overhead to proof search. Mella thus yields a template for integrating more expressive theorem provers in more sophisticated languages.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Armstrong, Alasdair and Foster, Simon and Struth, Georg},
  editor = {Gibbons, Jeremy and Nogueira, Pablo},
  year = {2012},
  keywords = {Proof Search,Type Check,Automate Theorem,Automate Theorem Prove,Proof Term},
  pages = {220-240},
  file = {/Users/doisinkidney/Zotero/storage/NWS4J3BS/Armstrong et al. - 2012 - Dependently Typed Programming Based on Automated T.pdf}
}

@inproceedings{morgan_elementary_2012,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Elementary {{Probability Theory}} in the {{Eindhoven Style}}},
  isbn = {978-3-642-31113-0},
  abstract = {We extend the Eindhoven quantifier notation to elementary probability theory by adding ``distribution comprehensions'' to it.Even elementary theories can be used in complicated ways, and this occurs especially when reasoning about computer programs: an instance of this is the multi-level probabilistic structures that arise in probabilistic semantics for security.Our exemplary case study in this article is therefore the probabilistic reasoning associated with a quantitative noninterference semantics based on Hidden Markov Models of computation. But we believe the proposal here will be more generally applicable than that, and so we also revisit a number of popular puzzles, to illustrate the new notation's wider utility.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Morgan, Carroll},
  editor = {Gibbons, Jeremy and Nogueira, Pablo},
  year = {2012},
  keywords = {Conditional Distribution,Conditional Expectation,Discrete Distribution,Hide Markov Model,Sample Space},
  pages = {48-73},
  file = {/Users/doisinkidney/Zotero/storage/BCSRKVMZ/Morgan - 2012 - Elementary Probability Theory in the Eindhoven Sty.pdf}
}

@inproceedings{mandel_scheduling_2012,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Scheduling and {{Buffer Sizing}} of N-{{Synchronous Systems}}},
  isbn = {978-3-642-31113-0},
  abstract = {Lucy-n is a language for programming networks of processes communicating through bounded buffers. A dedicated type system, termed a clock calculus, automatically computes static schedules of the processes and the sizes of the buffers between them.In this article, we present a new algorithm which solves the subtyping constraints generated by the clock calculus. The advantage of this algorithm is that it finds schedules for tightly coupled systems. Moreover, it does not overestimate the buffer sizes needed and it provides a way to favor either system throughput or buffer size minimization.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Mandel, Louis and Plateau, Florence},
  editor = {Gibbons, Jeremy and Nogueira, Pablo},
  year = {2012},
  keywords = {Constraint System,Periodic Pattern,Precedence Constraint,System Throughput,Unknown Word},
  pages = {74-101},
  file = {/Users/doisinkidney/Zotero/storage/4VXDM8IF/Mandel and Plateau - 2012 - Scheduling and Buffer Sizing of n-Synchronous Syst.pdf}
}

@inproceedings{dongol_deriving_2012,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Deriving {{Real}}-{{Time Action Systems Controllers}} from {{Multiscale System Specifications}}},
  isbn = {978-3-642-31113-0},
  abstract = {This paper develops a method for deriving controllers for real-time systems in which the components of the system operate at different time granularities. To this end, we incorporate the theory of time bands into action systems, which allows one to structure a system into multiple abstractions of time. The framework includes a logic that facilitates reasoning about different types of sampling errors and transient properties (i.e., properties that only hold for a brief amount of time), and we develop theorems for simplifying proofs of hardware/software interaction. We formalise true concurrency and define refinement for the parallel composition of action systems. Our method of derivation builds on the verify-while-develop paradigm, where the action system code is developed side-by-side with its proof.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Dongol, Brijesh and Hayes, Ian J.},
  editor = {Gibbons, Jeremy and Nogueira, Pablo},
  year = {2012},
  keywords = {Parallel Composition,Action System,State Predicate,Time Band,Water Level},
  pages = {102-131},
  file = {/Users/doisinkidney/Zotero/storage/YGCIQ652/Dongol and Hayes - 2012 - Deriving Real-Time Action Systems Controllers from.pdf}
}

@inproceedings{dang_reverse_2012,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Reverse {{Exchange}} for {{Concurrency}} and {{Local Reasoning}}},
  isbn = {978-3-642-31113-0},
  abstract = {Recent research has pointed out the importance of the inequational exchange law (P*Q) ; (R*S) {$\leq$} (P ; R)*(Q ; S) for concurrent processes. In particular, it has been shown that this law is equivalent to validity of the concurrency rule for Hoare triples. Unfortunately, the law does not hold in the relationally based setting of algebraic separation logic. However, we show that under mild conditions the reverse inequation (P ; R)*(Q ; S) {$\leq$} (P*Q) ; (R*S) still holds there. Separating conjunction * in that calculus can be interpreted as true concurrency on disjointly accessed resources. From the reverse exchange law we derive slightly restricted but still reasonably useful variants of the concurrency rule. Moreover, using a corresponding definition of locality, we obtain also a variant of the frame rule. By this, the relational setting can also be applied for modular and concurrency reasoning. Finally, we present several variations of the approach to further interpret the results.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Dang, Han-Hing and M\"oller, Bernhard},
  editor = {Gibbons, Jeremy and Nogueira, Pablo},
  year = {2012},
  keywords = {Hoare logic,concurrent separation logic,frame rule,locality,relational semantics,True concurrency},
  pages = {177-197},
  file = {/Users/doisinkidney/Zotero/storage/F9EEYRTD/Dang and Möller - 2012 - Reverse Exchange for Concurrency and Local Reasoni.pdf}
}

@inproceedings{guttmann_unifying_2012,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Unifying {{Correctness Statements}}},
  isbn = {978-3-642-31113-0},
  abstract = {Partial, total and general correctness and further models of sequential computations differ in their treatment of finite, infinite and aborting executions. Algebras structure this diversity of models to avoid the repeated development of similar theories and to clarify their range of application. We introduce algebras that uniformly describe correctness statements, correctness calculi, pre-post specifications and loop refinement rules in five kinds of computation models. This extends previous work that unifies iteration, recursion and program transformations for some of these models. Our new description includes a relativised domain operation, which ignores parts of a computation, and represents bound functions for claims of termination by sequences of tests. We verify all results in Isabelle heavily using its automated theorem provers.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Guttmann, Walter},
  editor = {Gibbons, Jeremy and Nogueira, Pablo},
  year = {2012},
  keywords = {Correctness Statement,General Correctness,Partial Correctness,Relative Domain,Total Correctness},
  pages = {198-219},
  file = {/Users/doisinkidney/Zotero/storage/H7KA8QCS/Guttmann - 2012 - Unifying Correctness Statements.pdf}
}

@inproceedings{hoare_laws_2012,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {The {{Laws}} of {{Programming Unify Process Calculi}}},
  isbn = {978-3-642-31113-0},
  abstract = {We survey the well-known algebraic laws of sequential programming, and propose some less familiar laws for concurrent programming. On the basis of these laws, we derive the rules of a number of classical programming and process calculi, for example, those due to Hoare, Milner, and Kahn. The algebra is simpler than each of the calculi derived from it, and stronger than all the calculi put together. We end with a section describing the role of unification in Science and Engineering.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Hoare, Tony and {van Staden}, Stephan},
  editor = {Gibbons, Jeremy and Nogueira, Pablo},
  year = {2012},
  pages = {7-22},
  file = {/Users/doisinkidney/Zotero/storage/FFNW43AE/Hoare and van Staden - 2012 - The Laws of Programming Unify Process Calculi.pdf}
}

@inproceedings{lux_scheduler-independent_2012,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Scheduler-{{Independent Declassification}}},
  isbn = {978-3-642-31113-0},
  abstract = {The controlled declassification of secrets has received much attention in research on information-flow security, though mostly for sequential programming languages. In this article, we aim at guaranteeing the security of concurrent programs. We propose the novel security property WHAT\&WHERE that allows one to limit what information may be declassified where in a program. We show that our property provides adequate security guarantees independent of the scheduling algorithm (which is non-trivial due to the refinement paradox) and present a security type system that reliably enforces the property. In a second scheduler-independence result, we show that an earlier proposed security condition is adequate for the same range of schedulers. These are the first scheduler-independence results in the presence of declassification.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Lux, Alexander and Mantel, Heiko and Perner, Matthias},
  editor = {Gibbons, Jeremy and Nogueira, Pablo},
  year = {2012},
  keywords = {Label Transition System,Memory State,Program Point,Security Condition,Security Property},
  pages = {25-47},
  file = {/Users/doisinkidney/Zotero/storage/CXGT4LAJ/Lux et al. - 2012 - Scheduler-Independent Declassification.pdf}
}

@inproceedings{backhouse_recounting_2008,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Recounting the {{Rationals}}: {{Twice}}!},
  isbn = {978-3-540-70594-9},
  shorttitle = {Recounting the {{Rationals}}},
  abstract = {We derive an algorithm that enables the rationals to be efficiently enumerated in two different ways. One way is known and is credited to Moshe Newman; it corresponds to a deforestation of the so-called Calkin-Wilf tree of rationals. The second is new and corresponds to a deforestation of the Stern-Brocot tree of rationals. We show that both enumerations stem from the same simple algorithm. In this way, we construct a Stern-Brocot enumeration algorithm with the same time and space complexity as Newman's algorithm.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Backhouse, Roland and Ferreira, Jo\~ao F.},
  editor = {Audebaud, Philippe and {Paulin-Mohring}, Christine},
  year = {2008},
  keywords = {algorithm derivation,Calkin-Wilf tree,enumeration algorithm,rational numbers,Stern-Brocot tree},
  pages = {79-91},
  file = {/Users/doisinkidney/Zotero/storage/5VS352D7/Backhouse and Ferreira - 2008 - Recounting the Rationals Twice!.pdf}
}

@inproceedings{morrisett_programming_2008,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Programming with {{Effects}} in {{Coq}}},
  isbn = {978-3-540-70594-9},
  abstract = {Next-generation programming languages will move beyond simple type systems to include support for formal specifications and mechanically- checked proofs of adherence to those requirements. Already, in the imperative world, languages such as ESC/Java and Spec\# integrate Hoare- style pre- and post-conditions into the underlying type system. However, we argue that neither the program logics used in these systems, nor the decision procedures used to discharge verification conditions, are sufficient for establishing deep properties of modular software.In contrast, the Coq proof development environment provides a powerful program logic (CiC) coupled with an extensible, interactive environment that can combine deep insights from humans with automation to discharge deep proof obligations. Unfortunately, the language at the core of Coq is limited to purely functional programming.In the Ynot project, we are attempting to address this problem by extending Coq with a new type constructor (the Hoare-triple type), and a few carefully chosen axioms that can be used to build imperative programs in a style quite close to Haskell. I will report on our progress thus far, both in using Ynot to construct modular, extensible libraries for imperative programs, as well as our new compiler infrastructure for generating efficient code from Ynot programs.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Morrisett, Greg},
  editor = {Audebaud, Philippe and {Paulin-Mohring}, Christine},
  year = {2008},
  pages = {28-28},
  file = {/Users/doisinkidney/Zotero/storage/VW8TJFA8/Morrisett - 2008 - Programming with Effects in Coq.pdf}
}

@inproceedings{lammel_expression_2008,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {The {{Expression Lemma}}},
  isbn = {978-3-540-70594-9},
  abstract = {Algebraic data types and catamorphisms (folds) play a central role in functional programming as they allow programmers to define recursive data structures and operations on them uniformly by structural recursion. Likewise, in object-oriented (OO) programming, recursive hierarchies of object types with virtual methods play a central role for the same reason. There is a semantical correspondence between these two situations which we reveal and formalize categorically. To this end, we assume a coalgebraic model of OO programming with functional objects. The development may be helpful in deriving refactorings that turn sufficiently disciplined functional programs into OO programs of a designated shape and vice versa.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {L\"ammel, Ralf and Rypacek, Ondrej},
  editor = {Audebaud, Philippe and {Paulin-Mohring}, Christine},
  year = {2008},
  keywords = {program calculation,catamorphism,cofree comonad,distributive law,expression lemma,expression problem,fold,free monad,functional object,the composite design pattern},
  pages = {193-219},
  file = {/Users/doisinkidney/Zotero/storage/VSRCJGA2/Lämmel and Rypacek - 2008 - The Expression Lemma.pdf}
}

@inproceedings{witzel_symmetric_2008,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Symmetric and {{Synchronous Communication}} in {{Peer}}-to-{{Peer Networks}}},
  isbn = {978-3-540-70594-9},
  abstract = {Motivated by distributed implementations of game-theoretical algorithms, we study symmetric process systems and the problem of attaining common knowledge between processes. We formalize our setting by defining a notion of peer-to-peer networks and appropriate symmetry concepts in the context of Communicating Sequential Processes (CSP) [1]. We then prove that CSP with input and output guards makes common knowledge in symmetric peer-to-peer networks possible, but not the restricted version which disallows output statements in guards and is commonly implemented. Our results extend [2].An extended version is available at http://arxiv.org/abs/0710.2284 .},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Witzel, Andreas},
  editor = {Audebaud, Philippe and {Paulin-Mohring}, Christine},
  year = {2008},
  keywords = {Boolean Expression,Common Knowledge,Communication Statement,Electoral System,Original Network},
  pages = {404-421},
  file = {/Users/doisinkidney/Zotero/storage/PULDEAAL/Witzel - 2008 - Symmetric and Synchronous Communication in Peer-to.pdf}
}

@inproceedings{meinicke_probabilistic_2008,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Probabilistic {{Choice}} in {{Refinement Algebra}}},
  isbn = {978-3-540-70594-9},
  abstract = {The term refinement algebra refers to a set of abstract algebras, similar to Kleene algebra with tests, that are suitable for reasoning about programs in a total-correctness framework. Abstract algebraic reasoning also works well when probabilistic programs are concerned, and a general refinement algebra that is suitable for such programs has been defined previously. That refinement algebra does not contain features that are specific to probabilistic programs. For instance, it does not include a probabilistic choice operator, or probabilistic assertions and guards (tests), which may be used to represent correctness properties for probabilistic programs. In this paper we investigate how these features may be included in a refinement algebra. That is, we propose a new refinement algebra in which probabilistic choice, and probabilistic guards and assertions may be expressed. Two operators for modelling probabilistic enabledness and termination are also introduced.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Meinicke, Larissa and Hayes, Ian J.},
  editor = {Audebaud, Philippe and {Paulin-Mohring}, Christine},
  year = {2008},
  pages = {243-267},
  file = {/Users/doisinkidney/Zotero/storage/AT4ZM4BN/Meinicke and Hayes - 2008 - Probabilistic Choice in Refinement Algebra.pdf}
}

@inproceedings{kozen_bohmjacopini_2008,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {The {{B\"ohm}}\textendash{{Jacopini Theorem Is False}}, {{Propositionally}}},
  isbn = {978-3-540-70594-9},
  abstract = {The B\"ohm\textendash{}Jacopini theorem (B\"ohm and Jacopini, 1966) is a classical result of program schematology. It states that any deterministic flowchart program is equivalent to a while program. The theorem is usually formulated at the first-order interpreted or first-order uninterpreted (schematic) level, because the construction requires the introduction of auxiliary variables. Ashcroft and Manna (1972) and Kosaraju (1973) showed that this is unavoidable. As observed by a number of authors, a slightly more powerful structured programming construct, namely loop programs with multi-level breaks, is sufficient to represent all deterministic flowcharts without introducing auxiliary variables. Kosaraju (1973) established a strict hierarchy determined by the maximum depth of nesting allowed. In this paper we give a purely propositional account of these results. We reformulate the problems at the propositional level in terms of automata on guarded strings, the automata-theoretic counterpart to Kleene algebra with tests. Whereas the classical approaches do not distinguish between first-order and propositional levels of abstraction, we find that the purely propositional formulation allows a more streamlined mathematical treatment, using algebraic and topological concepts such as bisimulation and coinduction. Using these tools, we can give more mathematically rigorous formulations and simpler and more revealing proofs.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Kozen, Dexter and Tseng, Wei-Lung Dustin},
  editor = {Audebaud, Philippe and {Paulin-Mohring}, Christine},
  year = {2008},
  pages = {177-192},
  file = {/Users/doisinkidney/Zotero/storage/XSXPJZZP/Kozen and Tseng - 2008 - The Böhm–Jacopini Theorem Is False, Propositionall.pdf}
}

@inproceedings{gluck_circulations_2008,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Circulations, {{Fuzzy Relations}} and {{Semirings}}},
  isbn = {978-3-540-70594-9},
  abstract = {Circulations are similar to flows in capacity-constrained networks, with the difference that they also observe lower bounds and, unlike flows, are not directed from a source to a sink. We give a new description of circulations in networks using a technique introduced by Kawahara; he applied the same methods to network flows. We show the power and flexibility of his approach in a new application, refining it at the same time by introducing the concept of test relations. Furthermore we will give algebraic formulations of a generic algorithm for computing a flow in a network with lower bounds and a sufficient and necessary criterion for the existence of a circulation.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Gl\"uck, Roland and M\"oller, Bernhard},
  editor = {Audebaud, Philippe and {Paulin-Mohring}, Christine},
  year = {2008},
  keywords = {Capacity Constraint,Inverse Semigroup,Lower Bound,Network Flow,Scalar Multiplication},
  pages = {134-152},
  file = {/Users/doisinkidney/Zotero/storage/FATCHRUL/Glück and Möller - 2008 - Circulations, Fuzzy Relations and Semirings.pdf}
}

@inproceedings{jay_scrap_2008,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Scrap {{Your Type Applications}}},
  isbn = {978-3-540-70594-9},
  abstract = {System F is ubiquitous in logic, theorem proving, language meta-theory, compiler intermediate languages, and elsewhere. Along with its type abstractions come type applications, but these often appear redundant. This redundancy is both distracting and costly for type-directed compilers.We introduce System IF, for implicit System F, in which many type applications can be made implicit. It supports decidable type checking and strong normalisation. Experiments with Haskell suggest that it could be used to reduce the amount of intermediate code in compilers that employ System F.System IF constitutes a first foray into a new area in the design space of typed lambda calculi, that is interesting in its own right and may prove useful in practice.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Jay, Barry and Peyton Jones, Simon},
  editor = {Audebaud, Philippe and {Paulin-Mohring}, Christine},
  year = {2008},
  keywords = {Functional Programming,Type Inference,Critical Pair,Reduction Rule,Type Application},
  pages = {2-27},
  file = {/Users/doisinkidney/Zotero/storage/RWNYFKP4/Jay and Peyton Jones - 2008 - Scrap Your Type Applications.pdf}
}

@inproceedings{hinze_exploiting_2008,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Exploiting {{Unique Fixed Points}}},
  isbn = {978-3-540-70594-9},
  abstract = {Functional programmers happily use equational reasoning and induction to prove properties of recursive programs. To show properties of corecursive programs they employ coinduction, per perhaps less enthusiastically. Coinduction is often considered as a rather low-level proof method, especially, as it seems to depart rather radically from equational reasoning. In this talk we introduce an alternative proof technique based on unique fixed points. To make the idea concrete, consider the simplest example of a coinductive type: the type of streams, where a stream is an infinite sequence of elements. In a lazy functional language, such as Haskell, streams are easy to define and many textbooks on Haskell reproduce the folklore examples of Fibonacci or Hamming numbers defined by recursion equations over streams. One has to be a bit careful in formulating a recursion equation basically avoiding that the sequence defined swallows its own tail. However, if this care is exercised, the equation even possesses a unique solution, a fact that is not very widely appreciated. Uniqueness can be exploited to prove that two streams are equal: if they satisfy the same recursion equation, then they are! We will use this proof technique to infer some intriguing facts about particular streams and to develop the basics of finite calculus. Quite attractively, the resulting proofs have a strong equational flavour. In a nutshell, the proof method brings equational reasoning to the coworld. Of course, it is by no means restricted to streams and can be used equally well to prove properties of infinite trees or the observational equivalence of instances of an abstract datatype.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Hinze, Ralf},
  editor = {Audebaud, Philippe and {Paulin-Mohring}, Christine},
  year = {2008},
  pages = {1-1},
  file = {/Users/doisinkidney/Zotero/storage/DJ2RZ582/Hinze - 2008 - Exploiting Unique Fixed Points.pdf}
}

@inproceedings{abel_verifying_2008,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Verifying a {{Semantic}} {$B\eta$}-{{Conversion Test}} for {{Martin}}-{{L\"of Type Theory}}},
  isbn = {978-3-540-70594-9},
  abstract = {Type-checking algorithms for dependent type theories often rely on the interpretation of terms in some semantic domain of values when checking equalities. Here we analyze a version of Coquand's algorithm for checking the {$\beta\eta$}-equality of such semantic values in a theory with a predicative universe hierarchy and large elimination rules. Although this algorithm does not rely on normalization by evaluation explicitly, we show that similar ideas can be employed for its verification. In particular, our proof uses the new notions of contextual reification and strong semantic equality.The algorithm is part of a bi-directional type checking algorithm which checks whether a normal term has a certain semantic type, a technique used in the proof assistants Agda and Epigram. We work with an abstract notion of semantic domain in order to accommodate a variety of possible implementation techniques, such as normal forms, weak head normal forms, closures, and compiled code. Our aim is to get closer than previous work to verifying the type-checking algorithms which are actually used in practice.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Abel, Andreas and Coquand, Thierry and Dybjer, Peter},
  editor = {Audebaud, Philippe and {Paulin-Mohring}, Christine},
  year = {2008},
  keywords = {Type Theory,Inference Rule,Kripke Model,Neutral Type,Normal Form},
  pages = {29-56},
  file = {/Users/doisinkidney/Zotero/storage/TG8WXKZ2/Abel et al. - 2008 - Verifying a Semantic βη-Conversion Test for Martin.pdf}
}

@inproceedings{matthes_nested_2008,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Nested {{Datatypes}} with {{Generalized Mendler Iteration}}: {{Map Fusion}} and the {{Example}} of the {{Representation}} of {{Untyped Lambda Calculus}} with {{Explicit Flattening}}},
  isbn = {978-3-540-70594-9},
  shorttitle = {Nested {{Datatypes}} with {{Generalized Mendler Iteration}}},
  abstract = {Nested datatypes are families of datatypes that are indexed over all types such that the constructors may relate different family members. Moreover, the argument types of the constructors refer to indices given by expressions where the family name may occur. Especially in this case of true nesting, there is no direct support by theorem provers to guarantee termination of functions that traverse these data structures.A joint article with A. Abel and T. Uustalu (TCS 333(1\textendash{}2), pp. 3\textendash{}66, 2005) proposes iteration schemes that guarantee termination not by structural requirements but just by polymorphic typing. They are generic in the sense that no specific syntactic form of the underlying datatype ``functor'' is required. In subsequent work (accepted for the Journal of Functional Programming), the author introduced an induction principle for the verification of programs obtained from Mendler-style iteration of rank 2, which is one of those schemes, and justified it in the Calculus of Inductive Constructions through an implementation in the theorem prover Coq.The new contribution is an extension of this work to generalized Mendler iteration (introduced in Abel et al, cited above), leading to a map fusion theorem for the obtained iterative functions. The results and their implementation in Coq are used for a case study on a representation of untyped lambda calculus with explicit flattening. Substitution is proven to fulfill two of the three monad laws, the third only for ``hereditarily canonical'' terms, but this is rectified by a relativisation of the whole construction to those terms.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Matthes, Ralph},
  editor = {Audebaud, Philippe and {Paulin-Mohring}, Christine},
  year = {2008},
  pages = {220-242},
  file = {/Users/doisinkidney/Zotero/storage/JF9WR47W/Matthes - 2008 - Nested Datatypes with Generalized Mendler Iteratio.pdf}
}

@inproceedings{sintzoff_synthesis_2008,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Synthesis of {{Optimal Control Policies}} for {{Some Infinite}}-{{State Transition Systems}}},
  isbn = {978-3-540-70594-9},
  abstract = {We develop a symbolic, logic-based technique for constructing optimal control policies in some transition systems where state spaces are large or infinite. These systems are presented as iterations of finite sets of guarded assignments which have costs. The optimality objective is to minimize the total costs of system executions reaching the set characterized by a given target predicate. Guards are predicates and control policies are expressed by tuples of guards. The optimal control policy refines the control policy of the given system. It is generated from the target predicate by an iteration based on backwards induction. This iterative procedure amounts to a variant of the symbolic algorithm generating the reachability precondition; the latter characterizes the states from which some system execution reaches the target set. The main difference is the introduction of greedy and cost-dependent iteration steps.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Sintzoff, Michel},
  editor = {Audebaud, Philippe and {Paulin-Mohring}, Christine},
  year = {2008},
  keywords = {Action Program,Control Policy,Optimal Policy,Symbolic Generator,Transition System},
  pages = {336-359},
  file = {/Users/doisinkidney/Zotero/storage/WB8364MJ/Sintzoff - 2008 - Synthesis of Optimal Control Policies for Some Inf.pdf}
}

@inproceedings{harrison_asynchronous_2008,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Asynchronous {{Exceptions}} as an {{Effect}}},
  isbn = {978-3-540-70594-9},
  abstract = {Asynchronous interrupts abound in computing systems, yet they remain a thorny concept for both programming and verification practice. The ubiquity of interrupts underscores the importance of developing programming models to aid the development and verification of interrupt-driven programs. The research reported here recognizes asynchronous interrupts as a computational effect and encapsulates them as a building block in modular monadic semantics. The resulting modular semantic model can serve as both a guide for functional programming with interrupts and as a formal basis for reasoning about interrupt-driven computation as well.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Harrison, William L. and Allwein, Gerard and Gill, Andy and Procter, Adam},
  editor = {Audebaud, Philippe and {Paulin-Mohring}, Christine},
  year = {2008},
  keywords = {Functional Programming,Asynchronous Behavior,Interrupt Service Routine,Left Unit,Natural Semantic},
  pages = {153-176},
  file = {/Users/doisinkidney/Zotero/storage/PCPN73GB/Harrison et al. - 2008 - Asynchronous Exceptions as an Effect.pdf}
}

@inproceedings{backhouse_capacity-c_2008,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {The {{Capacity}}-{{C Torch Problem}}},
  isbn = {978-3-540-70594-9},
  abstract = {The torch problem (also known as the bridge problem or the flashlight problem) is about getting a number of people across a bridge as quickly as possible under certain constraints. Although a very simply stated problem, the solution is surprisingly non-trivial. The case in which there are just four people and the capacity of the bridge is two is a well-known puzzle, widely publicised on the internet. We consider the general problem where the number of people, their individual crossing times and the capacity of the bridge are all input parameters. We present an algorithm that determines the shortest total crossing time; the number of primitive computations executed by the algorithm (i.e. the worst-case time complexity of the algorithm) is proportional to the square of the number of people.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Backhouse, Roland},
  editor = {Audebaud, Philippe and {Paulin-Mohring}, Christine},
  year = {2008},
  keywords = {dynamic programming,algorithmic problem solving,algorithm derivation,shortest path},
  pages = {57-78},
  file = {/Users/doisinkidney/Zotero/storage/TVQJAL4T/Backhouse - 2008 - The Capacity-C Torch Problem.pdf}
}

@inproceedings{nishimura_safe_2008,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Safe {{Modification}} of {{Pointer Programs}} in {{Refinement Calculus}}},
  isbn = {978-3-540-70594-9},
  abstract = {This paper discusses stepwise refinement of pointer programs in the framework of refinement calculus. We augment the underlying logic with formulas of separation logic and then introduce a pair of new predicate transformers, called separating assertion and separating assumption. The new predicate transformers are derived from separating conjunction and separating implication, which are fundamental logical connectives in separation logic. They represent primitive forms of heap allocation/deallocation operators and the basic pointer statements can be specified by means of them. We derive several refinement laws that are useful for stepwise refinement and demonstrate the use of the laws in the context of correctness preserving transformations that are intended for improved memory usage.The formal development is carried out in the framework of higher-order logic and is based on Back and Preoteasa's axiomatization of state space and its extension to the heap storage [BP05, Pre06]. All the results have been implemented and verified in the theorem prover PVS.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Nishimura, Susumu},
  editor = {Audebaud, Philippe and {Paulin-Mohring}, Christine},
  year = {2008},
  keywords = {Predicate Transformer,Separation Logic,Local Scope,Pointer Program,Refinement Calculus},
  pages = {284-304},
  file = {/Users/doisinkidney/Zotero/storage/W4JPRF3A/Nishimura - 2008 - Safe Modification of Pointer Programs in Refinemen.pdf}
}

@inproceedings{regis-gianas_hoare_2008,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {A {{Hoare Logic}} for {{Call}}-by-{{Value Functional Programs}}},
  isbn = {978-3-540-70594-9},
  abstract = {We present a Hoare logic for a call-by-value programming language equipped with recursive, higher-order functions, algebraic data types, and a polymorphic type system in the style of Hindley and Milner. It is the theoretical basis for a tool that extracts proof obligations out of programs annotated with logical assertions. These proof obligations, expressed in a typed, higher-order logic, are discharged using off-the-shelf automated or interactive theorem provers. Although the technical apparatus that we exploit is by now standard, its application to call-by-value functional programming languages appears to be new, and (we claim) deserves attention. As a sample application, we check the partial correctness of a balanced binary search tree implementation.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {{R\'egis-Gianas}, Yann and Pottier, Fran{\c c}ois},
  editor = {Audebaud, Philippe and {Paulin-Mohring}, Christine},
  year = {2008},
  keywords = {Binary Search Tree,Proof Obligation,Hoare Logic,Interactive Theorem Prover,Logical Level},
  pages = {305-335},
  file = {/Users/doisinkidney/Zotero/storage/KEHJE3B3/Régis-Gianas and Pottier - 2008 - A Hoare Logic for Call-by-Value Functional Program.pdf}
}

@inproceedings{gibbons_unfolding_2008-1,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Unfolding {{Abstract Datatypes}}},
  isbn = {978-3-540-70594-9},
  abstract = {We argue that abstract datatypes \textemdash{} with public interfaces hiding private implementations \textemdash{} represent a form of codata rather than ordinary data, and hence that proof methods for corecursive programs are the appropriate techniques to use for reasoning with them. In particular, we show that the universal properties of unfold operators are perfectly suited for the task. We illustrate with solutions to two problems the solution to a problem in the recent literature.},
  language = {en},
  booktitle = {Mathematics of {{Program Construction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Gibbons, Jeremy},
  editor = {Audebaud, Philippe and {Paulin-Mohring}, Christine},
  year = {2008},
  keywords = {Pattern Match,Abstract Data Type,Proof Method,Recursive Type,Universal Property},
  pages = {110-133},
  file = {/Users/doisinkidney/Zotero/storage/B3WPZB2C/Gibbons - 2008 - Unfolding Abstract Datatypes.pdf}
}

@techreport{Hanus16Curry,
  title = {Curry: {{An Integrated Functional Logic Language}} ({{Vers}}. 0.9.0)},
  number = {0.9.0},
  url = {https://www-ps.informatik.uni-kiel.de/currywiki/},
  author = {Hanus (ed.), M.},
  month = jan,
  year = {2016},
  file = {/Users/doisinkidney/Zotero/storage/ULIG3AX7/Hanus (ed.) - 2016 - Curry An Integrated Functional Logic Language (Ve.pdf},
  howpublished = {Available at http://www.curry-language.org}
}

@misc{peebles_simple_2012,
  title = {Simple Seemingly Impossible {{Agda}}},
  abstract = {Simple seemingly impossible Agda. GitHub Gist: instantly share code, notes, and snippets.},
  urldate = {2019-03-20},
  url = {https://gist.github.com/copumpkin/1562804},
  author = {Peebles, Dan},
  month = jan,
  year = {2012},
  file = {/Users/doisinkidney/Zotero/storage/BBU9AUB2/1562804.html}
}

@misc{escardo_seemingly_2014,
  title = {Seemingly Impossible Constructive Proofs | {{Mathematics}} and {{Computation}}},
  language = {en-US},
  urldate = {2019-03-20},
  journal = {Mathematics and Computation},
  url = {http://math.andrej.com/2014/05/08/seemingly-impossible-proofs/},
  author = {Escardo, Martin},
  month = may,
  year = {2014},
  file = {/Users/doisinkidney/Zotero/storage/HL86FSMI/seemingly-impossible-proofs.html}
}

@article{escardo_infinite_2013-1,
  title = {Infinite Sets That {{Satisfy}} the {{Principle}} of {{Omniscience}} in Any {{Variety}} of {{Constructive Mathematics}}},
  volume = {78},
  issn = {0022-4812, 1943-5886},
  abstract = {We show that there are plenty of infinite sets that satisfy the omniscience principle, in a minimalistic setting for constructive mathematics that is compatible with classical mathematics. A first example of an omniscient set is the one-point compactification of the natural numbers, also known as the generic convergent sequence. We relate this to Grilliot's and Ishihara's Tricks. We generalize this example to many infinite subsets of the Cantor space. These subsets turn out to be ordinals in a constructive sense, with respect to the lexicographic order, satisfying both a well-foundedness condition with respect to decidable subsets, and transfinite induction restricted to decidable predicates. The use of simple types allows us to reach any ordinal below {$\epsilon$}Q, and richer type systems allow us to get higher.},
  language = {en},
  number = {3},
  urldate = {2019-03-20},
  journal = {The Journal of Symbolic Logic},
  doi = {10.2178/jsl.7803040},
  url = {https://www.cambridge.org/core/journals/journal-of-symbolic-logic/article/infinite-sets-that-satisfy-the-principle-of-omniscience-in-any-variety-of-constructive-mathematics/0D204ADE629B703578B848B8573FC83D},
  author = {Escard\'o, Mart\'in H.},
  month = sep,
  year = {2013},
  pages = {764-784},
  file = {/Users/doisinkidney/Zotero/storage/CKLD89PY/Escardó - 2013 - Infinite sets that Satisfy the Principle of Omnisc.pdf;/Users/doisinkidney/Zotero/storage/H6XN99YN/Escardó - 2013 - Infinite sets that Satisfy the Principle of Omnisc.pdf;/Users/doisinkidney/Zotero/storage/PTKCLWTC/0D204ADE629B703578B848B8573FC83D.html}
}

@inproceedings{escardo_what_2010,
  address = {Baltimore, Maryland, USA},
  title = {What Sequential Games, the Tychonoff Theorem and the Double-Negation Shift Have in Common},
  isbn = {978-1-4503-0255-5},
  abstract = {This is a tutorial for mathematically inclined functional programmers, based on previously published, peered reviewed theoretical work. We discuss a higher-type functional, written here in the functional programming language Haskell, which (1) optimally plays sequential games, (2) implements a computational version of the Tychonoff Theorem from topology, and (3) realizes the DoubleNegation Shift from logic and proof theory. The functional makes sense for finite and infinite (lazy) lists, and in the binary case it amounts to an operation that is available in any (strong) monad. In fact, once we define this monad in Haskell, it turns out that this amazingly versatile functional is already available in Haskell, in the standard prelude, called sequence, which iterates this binary operation. Therefore Haskell proves that this functional is even more versatile than anticipated, as the function sequence was introduced for other purposes by the language designers, in particular the iteration of a list of monadic effects (but effects are not what we discuss here).},
  language = {en},
  urldate = {2019-03-21},
  booktitle = {Proceedings of the Third {{ACM SIGPLAN}} Workshop on {{Mathematically}} Structured Functional Programming - {{MSFP}} '10},
  publisher = {{ACM Press}},
  doi = {10.1145/1863597.1863605},
  url = {http://portal.acm.org/citation.cfm?doid=1863597.1863605},
  author = {Escard\'o, Mart\'in and Oliva, Paulo},
  year = {2010},
  pages = {21},
  file = {/Users/doisinkidney/Zotero/storage/WVCQCJFF/Escardó and Oliva - 2010 - What sequential games, the tychonoff theorem and t.pdf}
}

@inproceedings{escardo_infinite_2007,
  address = {Wroclaw, Poland},
  title = {Infinite Sets That Admit Fast Exhaustive Search},
  isbn = {978-0-7695-2908-0},
  language = {en},
  urldate = {2019-03-21},
  booktitle = {22nd {{Annual IEEE Symposium}} on {{Logic}} in {{Computer Science}} ({{LICS}} 2007)},
  publisher = {{IEEE}},
  doi = {10.1109/LICS.2007.25},
  url = {http://ieeexplore.ieee.org/document/4276587/},
  author = {Escardo, Martin},
  year = {2007},
  pages = {443-452},
  file = {/Users/doisinkidney/Zotero/storage/SENA9H3F/Escardo - 2007 - Infinite sets that admit fast exhaustive search.pdf}
}

@phdthesis{golov_formalisation_2018,
  title = {Formalisation of {{Cryptographic Proofs}} in {{Agda}}},
  school = {Universiteit of Utrecht},
  author = {Golov, Anton},
  month = aug,
  year = {2018},
  file = {/Users/doisinkidney/Zotero/storage/LLX5VT8Z/agolov_thesis.pdf}
}

@unpublished{harvey_integer_2019,
  title = {Integer Multiplication in Time {{O}}(n Log n)},
  abstract = {We present an algorithm that computes the product of two n-bit integers in O(n log n) bit operations.},
  language = {en},
  urldate = {2019-03-30},
  url = {https://hal.archives-ouvertes.fr/hal-02070778/document},
  author = {Harvey, David and Hoeven, Joris Van Der},
  month = mar,
  year = {2019},
  file = {/Users/doisinkidney/Zotero/storage/3QIKIHE4/Harvey and Hoeven - Integer multiplication in time O(n log n).pdf}
}

@misc{noauthor_implementing_nodate,
  title = {Implementing {{Least}}-{{Strict Natural Numbers}} [{{CurryWiki}}]},
  urldate = {2019-03-26},
  url = {https://www-ps.informatik.uni-kiel.de/currywiki/fun/naturals},
  file = {/Users/doisinkidney/Zotero/storage/8LGWMKE9/naturals.html}
}

@article{Elliott2019-convolution-extended,
  title = {Generalized Convolution and Efficient Language Recognition (Extended Version)},
  volume = {abs/1903.10677},
  abstract = {Convolution is a broadly useful operation with applications including signal
processing, machine learning, probability, optics, polynomial multiplication,
and efficient parsing. Usually, however, this operation is understood and
implemented in more specialized forms, hiding commonalities and limiting
usefulness. This paper formulates convolution in the common algebraic framework
of semirings and semimodules and populates that framework with various
representation types. One of those types is the grand abstract template and
itself generalizes to the free semimodule monad. Other representations serve
varied uses and performance trade-offs, with implementations calculated from
simple and regular specifications.
  Of particular interest is Brzozowski's method for regular expression
matching. Uncovering the method's essence frees it from syntactic
manipulations, while generalizing from boolean to weighted membership (such as
multisets and probability distributions) and from sets to n-ary relations. The
classic trie data structure then provides an elegant and efficient alternative
to syntax.
  Pleasantly, polynomial arithmetic requires no additional implementation
effort, works correctly with a variety of representations, and handles
multivariate polynomials and power series with ease. Image convolution also
falls out as a special case.},
  language = {en},
  journal = {CoRR},
  url = {https://arxiv.org/abs/1903.10677v1},
  author = {Elliott, Conal},
  month = mar,
  year = {2019},
  keywords = {Computer Science - Programming Languages},
  file = {/Users/doisinkidney/Zotero/storage/3LB7UDNG/Elliott - 2019 - Generalized Convolution and Efficient Language Rec.pdf;/Users/doisinkidney/Zotero/storage/BFKQERZA/Elliott - 2019 - Generalized Convolution and Efficient Language Rec.pdf;/Users/doisinkidney/Zotero/storage/CEMJCIPZ/Elliott - 2019 - Generalized convolution and efficient language rec.pdf;/Users/doisinkidney/Zotero/storage/EBLWWXIK/1903.html;/Users/doisinkidney/Zotero/storage/JXJZGA8T/1903.html},
  mon = {03}
}

@unpublished{altenkirch_nable_2011,
  title = {Definable {{Quotients}} in {{Type Theory}}},
  abstract = {In Type Theory, a quotient set is a set representing a setoid. Categorically, this corresponds to the concept of an exact coequalizer. In the present paper we consider the case of a definable quotients, where the quotient set arises as the codomain of a normalization function \textemdash{}this corresponds to the notion of a split coequalizer. We give a number of examples of definable quotients and notice that it is preferable to use the setoid structure when reasoning about the quotient set. We also show that there are examples where setoids cannot be represented in ordinary Type Theory such as the real numbers or the partiality monad under the assumption that local continuity is admissible in Type Theory.},
  language = {en},
  urldate = {2019-03-31},
  url = {http://www.cs.nott.ac.uk/~psztxa/publ/defquotients.pdf},
  author = {Altenkirch, Thorsten and Anberr\'ee, Thomas and Li, Nuo},
  year = {2011},
  file = {/Users/doisinkidney/Zotero/storage/YQ3ZSEZA/Altenkirch et al. - Deﬁnable Quotients in Type Theory.pdf}
}

@inproceedings{frumin_finite_2018,
  address = {New York, NY, USA},
  series = {{{CPP}} 2018},
  title = {Finite {{Sets}} in {{Homotopy Type Theory}}},
  isbn = {978-1-4503-5586-5},
  abstract = {We study different formalizations of finite sets in homotopy type theory to obtain a general definition that exhibits both the computational facilities and the proof principles expected from finite sets. We use higher inductive types to define the type K(A) of "finite sets over type A" \`a la Kuratowski without assuming that K(A) has decidable equality. We show how to define basic functions and prove basic properties after which we give two applications of our definition.  On the foundational side, we use K to define the notions of "Kuratowski-finite type" and "Kuratowski-finite subobject", which we contrast with established notions, e.g. Bishop-finite types and enumerated types. We argue that Kuratowski-finiteness is the most general and flexible one of those and we define the usual operations on finite types and subobjects.  From the computational perspective, we show how to use K(A) for an abstract interface for well-known finite set implementations such as tree- and list-like data structures. This implies that a function defined on a concrete finite sets implementation can be obtained from a function defined on the abstract finite sets K(A) and that correctness properties are inherited. Hence, HoTT is the ideal setting for data refinement. Beside this, we define bounded quantification, which lifts a decidable property on A to one on K(A).},
  urldate = {2019-03-31},
  booktitle = {Proceedings of the 7th {{ACM SIGPLAN International Conference}} on {{Certified Programs}} and {{Proofs}}},
  publisher = {{ACM}},
  doi = {10.1145/3167085},
  url = {http://doi.acm.org/10.1145/3167085},
  author = {Frumin, Dan and Geuvers, Herman and Gondelman, L\'eon and van der Weide, Niels},
  year = {2018},
  keywords = {Coq,finite sets,finite types,higher inductive types,homotopy type theory},
  pages = {201--214},
  file = {/Users/doisinkidney/Zotero/storage/CKKYWGDG/Frumin et al. - 2018 - Finite Sets in Homotopy Type Theory.pdf}
}

@inproceedings{yorgey_monoids_2012-1,
  address = {New York, NY, USA},
  series = {Haskell '12},
  title = {Monoids: {{Theme}} and {{Variations}} ({{Functional Pearl}})},
  isbn = {978-1-4503-1574-6},
  shorttitle = {Monoids},
  abstract = {The monoid is a humble algebraic structure, at first glance even downright boring. However, there's much more to monoids than meets the eye. Using examples taken from the diagrams vector graphics framework as a case study, I demonstrate the power and beauty of monoids for library design. The paper begins with an extremely simple model of diagrams and proceeds through a series of incremental variations, all related somehow to the central theme of monoids. Along the way, I illustrate the power of compositional semantics; why you should also pay attention to the monoid's even humbler cousin, the semigroup; monoid homomorphisms; and monoid actions.},
  language = {en},
  urldate = {2019-03-31},
  booktitle = {Proceedings of the 2012 {{Haskell Symposium}}},
  publisher = {{ACM}},
  doi = {10.1145/2364506.2364520},
  url = {http://doi.acm.org/10.1145/2364506.2364520},
  author = {Yorgey, Brent A.},
  year = {2012},
  keywords = {monoid,monoid action,edsl,homomorphism},
  pages = {105--116},
  file = {/Users/doisinkidney/Zotero/storage/A2M9DFV3/Yorgey - 2012 - Monoids Theme and Variations (Functional Pearl).pdf;/Users/doisinkidney/Zotero/storage/JY68CKLZ/Yorgey - Monoids Theme and Variations (Functional Pearl).pdf;/Users/doisinkidney/Zotero/storage/RYPQWFA9/Yorgey - Monoids Theme and Variations (Functional Pearl).pdf;/Users/doisinkidney/Zotero/storage/WTS5XQK2/762.html}
}

@article{dean_mapreduce_2008-1,
  title = {{{MapReduce}}: {{Simplified Data Processing}} on {{Large Clusters}}},
  volume = {51},
  issn = {0001-0782},
  shorttitle = {{{MapReduce}}},
  abstract = {MapReduce is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. Users specify the computation in terms of a map and a reduce function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. Programmers find the system easy to use: more than ten thousand distinct MapReduce programs have been implemented internally at Google over the past four years, and an average of one hundred thousand MapReduce jobs are executed on Google's clusters every day, processing a total of more than twenty petabytes of data per day.},
  language = {en},
  number = {1},
  urldate = {2019-03-31},
  journal = {Communications of the ACM},
  doi = {10.1145/1327452.1327492},
  url = {http://doi.acm.org/10.1145/1327452.1327492},
  author = {Dean, Jeffrey and Ghemawat, Sanjay},
  month = jan,
  year = {2008},
  pages = {107--113},
  file = {/Users/doisinkidney/Zotero/storage/Q38LTDJ2/Dean and Ghemawat - 2008 - MapReduce simplified data processing on large clu.pdf}
}

@book{koopman_advanced_2009,
  address = {Berlin Heidelberg},
  series = {Theoretical {{Computer Science}} and {{General Issues}}, {{Lect}}.{{Notes Computer}}. {{Tutorial}}},
  title = {Advanced {{Functional Programming}}: 6th {{International School}}, {{AFP}} 2008, {{Heijen}}, {{The Netherlands}}, {{May}} 19-24, 2008, {{Revised Lectures}}},
  isbn = {978-3-642-04651-3},
  shorttitle = {Advanced {{Functional Programming}}},
  abstract = {This tutorial book presents seven carefully revised lectures given at the 6th International School on Functional Programming, AFP 2008, in Heijen, The Netherlands in May 2008. The book presents the following seven, carefully cross-reviewed chapters, written by leading authorities in the field: Self-adjusting: Computation with Delta ML, spider spinning for dummies, from reduction-based to reduction-free normalization, libraries for generic programming in Haskell, dependently typed programming in agda, parallel and concurrent programming in Haskell and an iTask case study: a conference management system.},
  language = {en},
  urldate = {2019-04-01},
  publisher = {{Springer-Verlag}},
  url = {https://www.springer.com/gp/book/9783642046513},
  editor = {Koopman, Pieter and Swierstra, Doaitse},
  year = {2009},
  file = {/Users/doisinkidney/Zotero/storage/8ZVWW3Q2/9783642046513.html}
}

@incollection{norell_dependently_2009,
  address = {Berlin, Heidelberg},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Dependently {{Typed Programming}} in {{Agda}}},
  isbn = {978-3-642-04652-0},
  abstract = {In Hindley-Milner style languages, such as Haskell and ML, there is a clear separation between types and values. In a dependently typed language the line is more blurry - types can contain (depend on) arbitrary values and appear as arguments and results of ordinary functions.},
  language = {en},
  urldate = {2019-04-01},
  booktitle = {Advanced {{Functional Programming}}: 6th {{International School}}, {{AFP}} 2008, {{Heijen}}, {{The Netherlands}}, {{May}} 2008, {{Revised Lectures}}},
  publisher = {{Springer Berlin Heidelberg}},
  url = {https://doi.org/10.1007/978-3-642-04652-0_5},
  author = {Norell, Ulf},
  editor = {Koopman, Pieter and Plasmeijer, Rinus and Swierstra, Doaitse},
  year = {2009},
  pages = {230-266},
  file = {/Users/doisinkidney/Zotero/storage/YBN9K3FD/Norell - 2009 - Dependently Typed Programming in Agda.pdf},
  doi = {10.1007/978-3-642-04652-0_5}
}

@misc{brent_counting_2018,
  title = {Counting Inversions with Monoidal Sparks},
  abstract = {Time for me to reveal the example I had in mind that led to the generalization in my previous post. Thanks for all the interesting comments: it seems like there are some interesting connections to \ldots{}},
  language = {en},
  urldate = {2019-04-01},
  journal = {blog :: Brent -{$>$} [String]},
  url = {https://byorgey.wordpress.com/2018/10/06/counting-inversions-with-monoidal-sparks/},
  author = {{Brent}},
  month = oct,
  year = {2018},
  file = {/Users/doisinkidney/Zotero/storage/DGEZI866/counting-inversions-with-monoidal-sparks.html}
}

@article{bazerman_flipping_2014,
  title = {Flipping {{Fold}}, {{Reformulating Reduction}}},
  language = {en},
  author = {Bazerman, Gershom},
  year = {2014},
  pages = {11},
  file = {/Users/doisinkidney/Zotero/storage/BN2WC4YI/Bazerman - 2014 - Flipping Fold, Reformulating Reduction.pdf}
}

@article{godel_uber_1931,
  title = {{\"Uber formal unentscheidbare S\"atze der Principia Mathematica und verwandter Systeme I}},
  volume = {38},
  issn = {1436-5081},
  language = {de},
  number = {1},
  urldate = {2019-04-07},
  journal = {Monatshefte f\"ur Mathematik und Physik},
  doi = {10.1007/BF01700692},
  url = {https://doi.org/10.1007/BF01700692},
  author = {G\"odel, Kurt},
  month = dec,
  year = {1931},
  pages = {173-198}
}

@article{church_unsolvable_1936,
  title = {An {{Unsolvable Problem}} of {{Elementary Number Theory}}},
  volume = {58},
  issn = {0002-9327},
  number = {2},
  urldate = {2019-04-07},
  journal = {American Journal of Mathematics},
  doi = {10.2307/2371045},
  url = {https://www.jstor.org/stable/2371045},
  author = {Church, Alonzo},
  year = {1936},
  pages = {345-363}
}

@article{church_._1937,
  title = {A. {{M}}. {{Turing}}. {{On}} Computable Numbers, with an Application to the {{Entscheidungs}} Problcm. {{Proceedings}} of the {{London Mathematical Society}}, 2 s. Vol. 42 (1936\textendash{}1937), Pp. 230\textendash{}265.},
  volume = {2},
  issn = {0022-4812, 1943-5886},
  abstract = {//static.cambridge.org/content/id/urn\%3Acambridge.org\%3Aid\%3Aarticle\%3AS002248120003958X/resource/name/firstPage-S002248120003958Xa.jpg},
  language = {en},
  number = {1},
  urldate = {2019-04-07},
  journal = {The Journal of Symbolic Logic},
  doi = {10.1017/S002248120003958X},
  url = {https://www.cambridge.org/core/journals/journal-of-symbolic-logic/article/m-turing-on-computable-numbers-with-an-application-to-the-entscheidungs-problcm-proceedings-of-the-london-mathematical-society-2-s-vol-42-19361937-pp-230265/4DFCA89035F7F7C5BF4DB5129B8BB09E},
  author = {Church, Alonzo},
  month = mar,
  year = {1937},
  pages = {42-43},
  file = {/Users/doisinkidney/Zotero/storage/BNSH2C2J/4DFCA89035F7F7C5BF4DB5129B8BB09E.html}
}

@book{hilbert_natur_1992,
  title = {{Natur und mathematisches Erkennen: Vorlesungen, gehalten 1919-1920 in G\"ottingen}},
  isbn = {978-3-7643-2668-5},
  shorttitle = {{Natur und mathematisches Erkennen}},
  language = {de},
  publisher = {{Birkh\"auser}},
  author = {Hilbert, David},
  year = {1992}
}

@article{eremondi_framework_2019,
  title = {A Framework for Improving Error Messages in Dependently-Typed Languages},
  volume = {9},
  issn = {2299-1093},
  abstract = {Dependently-typed programming languages provide a powerful tool for establishing code correctness. However, it can be hard for newcomers to learn how to employ the advanced type system of such languages effectively. For simply-typed languages, several techniques have been devised to generate helpful error messages and suggestions for the programmer. We adapt these techniques to dependently-typed languages, to facilitate their more widespread adoption. In particular, we modify a higher-order unification algorithm that is used to resolve and type-check implicit arguments. We augment this algorithm with replay graphs, allowing for a global heuristic analysis of a unification problem-set, error-tolerant typing, which allows type-checking to continue after errors are found, and counter-factual unification, which makes error messages less affected by the order in which types are checked. A formalization of our algorithm is presented with an outline of its correctness. We implement replay graphs, and compare the generated error messages to those from existing languages, highlighting the improvements we achieved.},
  number = {1},
  urldate = {2019-04-08},
  journal = {Open Computer Science},
  doi = {10.1515/comp-2019-0001},
  url = {https://www.degruyter.com/view/j/comp.2019.9.issue-1/comp-2019-0001/comp-2019-0001.xml},
  author = {Eremondi, Joseph and Swierstra, Wouter and Hage, Jurriaan},
  year = {2019},
  keywords = {counter-factual typing,higher-order unification,type error diagnosis,type-inference},
  pages = {1--32},
  file = {/Users/doisinkidney/Zotero/storage/3FUT88YQ/Eremondi et al. - 2019 - A framework for improving error messages in depend.pdf}
}

@article{dylus_one_2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1805.08059},
  title = {One {{Monad}} to {{Prove Them All}}},
  volume = {3},
  issn = {2473-7321},
  abstract = {One Monad to Prove Them All is a modern fairy tale about curiosity and perseverance, two important properties of a successful PhD student. We follow the PhD student Mona on her adventure of proving properties about Haskell programs in the proof assistant Coq. On the one hand, as a PhD student in computer science Mona observes an increasing demand for correct software products. In particular, because of the large amount of existing software, verifying existing software products becomes more important. Verifying programs in the functional programming language Haskell is no exception. On the other hand, Mona is delighted to see that communities in the area of theorem proving are becoming popular. Thus, Mona sets out to learn more about the interactive theorem prover Coq and verifying Haskell programs in Coq. To prove properties about a Haskell function in Coq, Mona has to translate the function into Coq code. As Coq programs have to be total and Haskell programs are often not, Mona has to model partiality explicitly in Coq. In her quest for a solution Mona finds an ancient manuscript that explains how properties about Haskell functions can be proven in the proof assistant Agda by translating Haskell programs into monadic Agda programs. By instantiating the monadic program with a concrete monad instance the proof can be performed in either a total or a partial setting. Mona discovers that the proposed transformation does not work in Coq due to a restriction in the termination checker. In fact the transformation does not work in Agda anymore as well, as the termination checker in Agda has been improved. We follow Mona on an educational journey through the land of functional programming where she learns about concepts like free monads and containers as well as basics and restrictions of proof assistants like Coq. These concepts are well-known individually, but their interplay gives rise to a solution for Mona's problem based on the originally proposed monadic tranformation that has not been presented before. When Mona starts to test her approach by proving a statement about simple Haskell functions, she realizes that her approach has an additional advantage over the original idea in Agda. Mona's final solution not only works for a specific monad instance but even allows her to prove monad-generic properties. Instead of proving properties over and over again for specific monad instances she is able to prove properties that hold for all monads representable by a container-based instance of the free monad. In order to strengthen her confidence in the practicability of her approach, Mona evaluates her approach in a case study that compares two implementations for queues. In order to share the results with other functional programmers the fairy tale is available as a literate Coq file. If you are a citizen of the land of functional programming or are at least familiar with its customs, had a journey that involved reasoning about functional programs of your own, or are just a curious soul looking for the next story about monads and proofs, then this tale is for you.},
  number = {3},
  urldate = {2019-04-08},
  journal = {The Art, Science, and Engineering of Programming},
  doi = {10.22152/programming-journal.org/2019/3/8},
  url = {http://arxiv.org/abs/1805.08059},
  author = {Dylus, Sandra and Christiansen, Jan and Teegen, Finn},
  month = feb,
  year = {2019},
  keywords = {Computer Science - Programming Languages},
  file = {/Users/doisinkidney/Zotero/storage/PI2VFSRP/Dylus et al. - 2019 - One Monad to Prove Them All.pdf;/Users/doisinkidney/Zotero/storage/QGWVV95E/1805.html}
}

@phdthesis{demirtas_functional_2014,
  type = {Thesis},
  title = {Functional Composition and Decomposition for Signal Processing},
  copyright = {http://dspace.mit.edu/handle/1721.1/7582},
  abstract = {Functional composition, the application of one function to the results of another function, has a long history in the mathematics community, particularly in the context of polynomials and rational functions. This thesis articulates and explores a general framework for the use of functional composition in the context of signal processing. Its many potential applications to signal processing include utilization of the composition of simpler or lower order subfunctions to exactly or approximately represent a given function or data sequence. Although functional composition currently appears implicitly in a number of established signal processing algorithms, it is shown how the more general context developed and exploited in this thesis leads to significantly improved results for several important classes of functions that are ubiquitous in signal processing such as polynomials, frequency responses and discrete multivariate functions. Specifically, the functional composition framework is exploited in analyzing, designing and extending modular filters, separating marginalization computations into more manageable subcomputations and representing discrete sequences with fewer degrees of freedom than their length and region of support with implications for sparsity and efficiency.},
  language = {eng},
  urldate = {2019-04-09},
  school = {Massachusetts Institute of Technology},
  url = {http://dspace.mit.edu/handle/1721.1/89989},
  author = {Demirtas, Sefa},
  year = {2014},
  file = {/Users/doisinkidney/Zotero/storage/MMPCF4Y7/Demirtas - 2014 - Functional composition and decomposition for signa.pdf;/Users/doisinkidney/Zotero/storage/XQX36JV5/89989.html}
}

@inproceedings{faissole_synthetic_2017,
  title = {Synthetic Topology in {{Homotopy Type Theory}} for Probabilistic Programming},
  abstract = {The ALEA Coq library formalizes discrete measure theory using a variant of the Giry monad, as a submonad of the CPS monad: (A {$\rightarrow$} [0, 1]) {$\rightarrow$} [0, 1]. This allows one to use Moggi's monadic metalanguage to give an interpretation of a language, Rml, into type theory. Rml is a functional language with a primitive for probabilistic choice. This formalization was the semantical basis for the Certicrypt system for verifying security protocols. The Easycrypt proof assistant is still based on the same semantics. We improve on the formalization by using homotopy type theory which provides e.g. quotients and functional extensionality. Moreover, homotopy type theory allows us to use synthetic topology to present a theory which also includes non-discrete (`continuous') data types, like [0, 1]. Such data types are relevant, for instance, in machine learning and differential privacy. Our axioms are justified by KleeneVesley realizability, a standard model for computation with continuous data types.},
  language = {en},
  urldate = {2019-04-09},
  booktitle = {{{PPS}} 2017 - {{Workshop}} on Probabilistic Programming Semantics},
  url = {https://hal.inria.fr/hal-01485397},
  author = {Faissole, Florian and Spitters, Bas},
  month = jan,
  year = {2017},
  pages = {3},
  file = {/Users/doisinkidney/Zotero/storage/7KV6T23I/Faissole and Spitters - Synthetic topology in Homotopy Type Theory for pro.pdf;/Users/doisinkidney/Zotero/storage/453XWDRX/hal-01485397.html}
}

@phdthesis{szymczak_programming_2018,
  title = {Programming Language Semantics as a Foundation for {{Bayesian}} Inference},
  abstract = {Bayesian modelling, in which our prior belief about the distribution on model parameters 
is updated by observed data, is a popular approach to statistical data analysis. 
However, writing specific inference algorithms for Bayesian models by hand is time-consuming 
and requires significant machine learning expertise. 
Probabilistic programming promises to make Bayesian modelling easier and more 
accessible by letting the user express a generative model as a short computer program 
(with random variables), leaving inference to the generic algorithm provided by the 
compiler of the given language. However, it is not easy to design a probabilistic programming 
language correctly and define the meaning of programs expressible in it. 
Moreover, the inference algorithms used by probabilistic programming systems usually 
lack formal correctness proofs and bugs have been found in some of them, which 
limits the confidence one can have in the results they return. 
In this work, we apply ideas from the areas of programming language theory and 
statistics to show that probabilistic programming can be a reliable tool for Bayesian 
inference. The first part of this dissertation concerns the design, semantics and type 
system of a new, substantially enhanced version of the Tabular language. Tabular is a 
schema-based probabilistic language, which means that instead of writing a full program, 
the user only has to annotate the columns of a schema with expressions generating 
corresponding values. By adopting this paradigm, Tabular aims to be user-friendly, 
but this unusual design also makes it harder to define the syntax and semantics correctly 
and reason about the language. We define the syntax of a version of Tabular extended 
with user-defined functions and pseudo-deterministic queries, design a dependent type 
system for this language and endow it with a precise semantics. We also extend Tabular 
with a concise formula notation for hierarchical linear regressions, define the type 
system of this extended language and show how to reduce it to pure Tabular. 
In the second part of this dissertation, we present the first correctness proof for a 
Metropolis-Hastings sampling algorithm for a higher-order probabilistic language. We 
define a measure-theoretic semantics of the language by means of an operationally-defined 
density function on program traces (sequences of random variables) and a map 
from traces to program outputs. We then show that the distribution of samples returned 
by our algorithm (a variant of ``Trace MCMC'' used by the Church language) matches 
the program semantics in the limit.},
  language = {en},
  urldate = {2019-04-09},
  school = {The University of Edinburgh},
  url = {https://www.era.lib.ed.ac.uk/handle/1842/28993},
  author = {Szymczak, Marcin},
  month = jul,
  year = {2018},
  file = {/Users/doisinkidney/Zotero/storage/QWNEQJNQ/Szymczak - 2018 - Programming language semantics as a foundation for.pdf;/Users/doisinkidney/Zotero/storage/3I2IV7XD/28993.html}
}

@phdthesis{huang2017programming,
  title = {On Programming Languages for Probabilistic Modeling},
  school = {Ph. D. thesis, Harvard University},
  url = {https://danehuang.github.io/papers/dissertation.pdf},
  author = {Huang, Daniel Eachern},
  year = {2017},
  file = {/Users/doisinkidney/Zotero/storage/V7L2V2Q8/dissertation.pdf}
}

@misc{gibbons_folds_2018,
  title = {Folds on Lists},
  abstract = {The previous post turned out to be rather complicated. In this one, I return to much simpler matters: foldr and foldl on lists},
  language = {en},
  urldate = {2019-04-13},
  journal = {Patterns in Functional Programming},
  url = {https://patternsinfp.wordpress.com/2018/08/14/folds-on-lists/},
  author = {Gibbons, Jeremy},
  year = {2018-08-14T},
  file = {/Users/doisinkidney/Zotero/storage/5FERRHLE/folds-on-lists.html}
}

@misc{fairbairn_re_1997,
  title = {Re: {{Heap Sort}}},
  urldate = {2019-04-14},
  url = {https://www.mail-archive.com/haskell@haskell.org/msg01788.html},
  author = {Fairbairn, Jon},
  collaborator = {The Haskell Mailing List},
  month = oct,
  year = {1997},
  file = {/Users/doisinkidney/Zotero/storage/ITES9YDB/msg01788.html}
}

@incollection{hutchison_first-order_2013,
  address = {Berlin, Heidelberg},
  title = {First-{{Order Theorem Proving}} and {{Vampire}}},
  volume = {8044},
  isbn = {978-3-642-39798-1 978-3-642-39799-8},
  abstract = {In this paper we give a short introduction in first-order theorem proving and the use of the theorem prover VAMPIRE. We discuss the superposition calculus and explain the key concepts of saturation and redundancy elimination, present saturation algorithms and preprocessing, and demonstrate how these concepts are implemented in VAMPIRE. Further, we also cover more recent topics and features of VAMPIRE designed for advanced applications, including satisfiability checking, theory reasoning, interpolation, consequence elimination, and program analysis.},
  language = {en},
  urldate = {2019-04-14},
  booktitle = {Computer {{Aided Verification}}},
  publisher = {{Springer Berlin Heidelberg}},
  url = {http://link.springer.com/10.1007/978-3-642-39799-8_1},
  author = {Kov\'acs, Laura and Voronkov, Andrei},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Sharygina, Natasha and Veith, Helmut},
  year = {2013},
  pages = {1-35},
  file = {/Users/doisinkidney/Zotero/storage/FXXISS3K/Kovács and Voronkov - 2013 - First-Order Theorem Proving and Vampire.pdf},
  doi = {10.1007/978-3-642-39799-8_1}
}

@article{gibbons_when_2001-1,
  series = {{{CMCS}} 2001, {{Coalgebraic Methods}} in {{Computer Science}} (a {{Satellite Event}} of {{ETAPS}} 2001)},
  title = {When Is a {{Function}} a {{Fold}} or an {{Unfold}}?},
  volume = {44},
  issn = {1571-0661},
  abstract = {We give a necessary and sufficient condition for when a set-theoretic function can be written using the recursion operator fold, and a dual condition for the recursion operator unfold. The conditions are simple, practically useful, and generic in the underlying datatype.},
  number = {1},
  urldate = {2019-04-15},
  journal = {Electronic Notes in Theoretical Computer Science},
  doi = {10.1016/S1571-0661(04)80906-X},
  url = {http://www.sciencedirect.com/science/article/pii/S157106610480906X},
  author = {Gibbons, Jeremy and Hutton, Graham and Altenkirch, Thorsten},
  month = may,
  year = {2001},
  pages = {146-160},
  file = {/Users/doisinkidney/Zotero/storage/H4A65BWA/Gibbons et al. - 2001 - When is a Function a Fold or an Unfold.pdf;/Users/doisinkidney/Zotero/storage/H8DWNLRG/Gibbons et al. - 2001 - When is a function a fold or an unfold.pdf;/Users/doisinkidney/Zotero/storage/5SVSBGAP/S157106610480906X.html;/Users/doisinkidney/Zotero/storage/XBXBU4X6/publication2368-abstract.html}
}

@book{bird_introduction_1988-1,
  address = {New York},
  series = {Prentice {{Hall International}} Series in Computer Science},
  title = {Introduction to {{Functional Programming}}},
  isbn = {978-0-13-484197-7},
  language = {English},
  publisher = {{Prentice Hall College Div}},
  author = {Bird, Richard},
  year = {1988}
}

@inproceedings{gill_short_1993,
  title = {A {{Short Cut}} to {{Deforestation}}},
  abstract = {Lists are often used as "glue" to connect separate parts of a program together. We propose an automatic technique for improving the efficiency of such programs, by removing many of these intermediate lists, based on a single, simple, local transformation. We have implemented the method in the Glasgow Haskell compiler.},
  publisher = {{ACM Press}},
  author = {Gill, Andrew and Launchbury, John and Jones, Simon L. Peyton},
  year = {1993},
  pages = {223--232},
  file = {/Users/doisinkidney/Zotero/storage/8SSWC95I/Gill et al. - 1993 - A Short Cut to Deforestation.pdf;/Users/doisinkidney/Zotero/storage/VVATMVQ7/summary.html}
}

@article{kuratowski_sur_1920,
  title = {{Sur la notion d'ensemble fini}},
  volume = {1},
  issn = {0016-2736},
  language = {fra},
  number = {1},
  urldate = {2019-04-22},
  journal = {Fundamenta Mathematicae},
  url = {https://eudml.org/doc/212596},
  author = {Kuratowski, Casimir},
  year = {1920},
  pages = {129-131},
  file = {/Users/doisinkidney/Zotero/storage/K77HL5NV/212596.html}
}

@article{gehrke_quantifiers_2017,
  title = {Quantifiers on Languages and Codensity Monads},
  abstract = {This paper contributes to the techniques of topo-algebraic recognition for
languages beyond the regular setting as they relate to logic on words. In
particular, we provide a general construction on recognisers corresponding to
adding one layer of various kinds of quantifiers and prove a related
Reutenauer-type theorem. Our main tools are codensity monads and duality
theory. Our construction hinges, in particular, on a measure-theoretic
characterisation of the profinite monad of the free S-semimodule monad for
finite and commutative semirings S, which generalises our earlier insight that
the Vietoris monad on Boolean spaces is the codensity monad of the finite
powerset functor.},
  language = {en},
  urldate = {2019-04-22},
  url = {https://arxiv.org/abs/1702.08841v2},
  author = {Gehrke, Mai and Petrisan, Daniela and Reggio, Luca},
  month = feb,
  year = {2017},
  file = {/Users/doisinkidney/Zotero/storage/LIDWMLRX/Gehrke et al. - 2017 - Quantifiers on languages and codensity monads.pdf;/Users/doisinkidney/Zotero/storage/Y794UAR5/1702.html}
}

@inproceedings{braibant_tactics_2011,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Tactics for {{Reasoning Modulo AC}} in {{Coq}}},
  isbn = {978-3-642-25379-9},
  abstract = {We present a set of tools for rewriting modulo associativity and commutativity (AC) in Coq, solving a long-standing practical problem. We use two building blocks: first, an extensible reflexive decision procedure for equality modulo AC; second, an OCaml plug-in for pattern matching modulo AC. We handle associative only operations, neutral elements, uninterpreted function symbols, and user-defined equivalence relations. By relying on type-classes for the reification phase, we can infer these properties automatically, so that end-users do not need to specify which operation is A or AC, or which constant is a neutral element.},
  language = {en},
  booktitle = {Certified {{Programs}} and {{Proofs}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Braibant, Thomas and Pous, Damien},
  editor = {Jouannaud, Jean-Pierre and Shao, Zhong},
  year = {2011},
  keywords = {Pattern Match,Neutral Element,Decision Procedure,Function Symbol,Binary Operation},
  pages = {167-182},
  file = {/Users/doisinkidney/Zotero/storage/AFEW9RG4/Braibant and Pous - 2011 - Tactics for Reasoning Modulo AC in Coq.pdf}
}

@inproceedings{altenkirch_monads_2010,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Monads {{Need Not Be Endofunctors}}},
  isbn = {978-3-642-12032-9},
  abstract = {We introduce a generalisation of monads, called relative monads, allowing for underlying functors between different categories. Examples include finite-dimensional vector spaces, untyped and typed {$\lambda$}-calculus syntax and indexed containers. We show that the Kleisli and Eilenberg-Moore constructions carry over to relative monads and are related to relative adjunctions. Under reasonable assumptions, relative monads are monoids in the functor category concerned and extend to monads, giving rise to a coreflection between monads and relative monads. Arrows are also an instance of relative monads.},
  language = {en},
  booktitle = {Foundations of {{Software Science}} and {{Computational Structures}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Altenkirch, Thorsten and Chapman, James and Uustalu, Tarmo},
  editor = {Ong, Luke},
  year = {2010},
  keywords = {Initial Algebra,Left Adjoint,Monoidal Category,Monoidal Structure,Substitution Rule},
  pages = {297-311},
  file = {/Users/doisinkidney/Zotero/storage/UW9UBJFF/Altenkirch et al. - 2010 - Monads Need Not Be Endofunctors.pdf}
}

@inproceedings{scott_combinator_2012,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {A {{Combinator Language}} for {{Theorem Discovery}}},
  isbn = {978-3-642-31374-5},
  abstract = {We define and implement a combinator language for intermediate lemma discovery. We start by generalising an algebraic data-structure for unbounded search and then extend it to support case-analysis. With our language defined, we expect users to be able to write discoverers which collaborate intelligently in specific problem domains. For now, the language integrates rewriting, forward-deduction, and case-analysis and discovers lemmas concurrently based on an interactive proof context. We argue that the language is most suitable for adding domain-specific automation to mechanically formalised proofs written in a forward-style, and we show how the language is used via a case-study in geometry.},
  language = {en},
  booktitle = {Intelligent {{Computer Mathematics}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Scott, Phil and Fleuriot, Jacques},
  editor = {Jeuring, Johan and Campbell, John A. and Carette, Jacques and Dos Reis, Gabriel and Sojka, Petr and Wenzel, Makarius and Sorge, Volker},
  year = {2012},
  keywords = {Combinator Language,Dependent Tactic,Interactive Proof,Interactive Theorem Prove,Modus Ponens Inference},
  pages = {371-385},
  file = {/Users/doisinkidney/Zotero/storage/G43BM9AQ/Scott and Fleuriot - 2012 - A Combinator Language for Theorem Discovery.pdf}
}

@article{rivas_unified_2018-1,
  title = {A Unified View of Monadic and Applicative Non-Determinism},
  volume = {152},
  issn = {0167-6423},
  abstract = {It is well-known that monads are monoids in the category of endofunctors, and in fact so are applicative functors. Unfortunately, monoids do not have enough structure to account for computational effects with non-determinism operators. This article recovers a unified view of computational effects with non-determinism by extending monoids to near-semirings with both additive and multiplicative structure. This enables us to generically define free constructions as well as a novel double Cayley representation that optimises both left-nested sums and left-nested products.},
  language = {en},
  urldate = {2019-04-22},
  journal = {Science of Computer Programming},
  doi = {10.1016/j.scico.2017.09.007},
  url = {http://www.sciencedirect.com/science/article/pii/S0167642317301958},
  author = {Rivas, Exequiel and Jaskelioff, Mauro and Schrijvers, Tom},
  month = jan,
  year = {2018},
  keywords = {Alternative,Free construction,Monadplus,Monoid,Near-semiring},
  pages = {70-98},
  file = {/Users/doisinkidney/Zotero/storage/2K23MT7N/Rivas et al. - 2018 - A unified view of monadic and applicative non-dete.pdf;/Users/doisinkidney/Zotero/storage/8MCP6ZRM/Rivas et al. - 2018 - A unified view of monadic and applicative non-dete.pdf;/Users/doisinkidney/Zotero/storage/HXLIK4DS/Rivas et al. - 2018 - A unified view of monadic and applicative non-dete.pdf;/Users/doisinkidney/Zotero/storage/XCQFFAW5/S0167642317301958.html}
}

@article{puhkekeskus_workshop_nodate,
  title = {Workshop ``{{Algebra}} and Its Applications'' {{May}} 5-7, 2017},
  language = {en},
  author = {Puhkekeskus, Taevaskoja},
  pages = {19},
  file = {/Users/doisinkidney/Zotero/storage/MR4XTWGL/Puhkekeskus - Workshop “Algebra and its applications” May 5-7, 2.pdf}
}

@article{uustalu_divertimento_2016,
  series = {Articles Dedicated to {{Prof}}. {{J}}. {{N}}. {{Oliveira}} on the Occasion of His 60th Birthday},
  title = {A Divertimento on {{MonadPlus}} and Nondeterminism},
  volume = {85},
  issn = {2352-2208},
  abstract = {In the Haskell community, there is a controversy about what the laws of the MonadPlus type constructor class ought to be. We suggest that there is no single universal correct answer, however there is a universal method. Important classes of notions of finitary nondeterminism are captured by what we call monads of semigroups and monads of monoids, but also by monads of different specializations of semigroups and monoids. Some of these specializations of monads are exotic and amusing too.},
  number = {5, Part 2},
  urldate = {2019-04-22},
  journal = {Journal of Logical and Algebraic Methods in Programming},
  doi = {10.1016/j.jlamp.2016.06.004},
  url = {http://www.sciencedirect.com/science/article/pii/S2352220816300530},
  author = {Uustalu, Tarmo},
  month = aug,
  year = {2016},
  keywords = {Algebraic operations,Monads,Nondeterminism,Semigroups},
  pages = {1086-1094},
  file = {/Users/doisinkidney/Zotero/storage/XN9FZJ99/S2352220816300530.html}
}

@article{pirog_eilenberg--moore_2016,
  title = {Eilenberg--{{Moore Monoids}} and {{Backtracking Monad Transformers}}},
  abstract = {We develop an algebraic underpinning of backtracking monad transformers in
the general setting of monoidal categories. As our main technical device, we
introduce Eilenberg--Moore monoids, which combine monoids with algebras for
strong monads. We show that Eilenberg--Moore monoids coincide with algebras for
the list monad transformer ('done right') known from Haskell libraries.
  From this, we obtain a number of results, including the facts that the list
monad transformer is indeed a monad, a transformer, and an instance of the
MonadPlus class. Finally, we construct an Eilenberg--Moore monoid of
endomorphisms, which, via the codensity monad construction, yields a
continuation-based implementation a la Hinze.},
  language = {en},
  urldate = {2019-04-22},
  doi = {10.4204/EPTCS.207.2},
  url = {https://arxiv.org/abs/1604.01184v1},
  author = {Pir\'og, Maciej},
  month = apr,
  year = {2016},
  file = {/Users/doisinkidney/Zotero/storage/6EKLE2GD/Piróg - 2016 - Eilenberg--Moore Monoids and Backtracking Monad Tr.pdf;/Users/doisinkidney/Zotero/storage/QTLGBW4M/Piróg - 2016 - Eilenberg--Moore Monoids and Backtracking Monad Tr.pdf;/Users/doisinkidney/Zotero/storage/CTEK3KCF/1604.html;/Users/doisinkidney/Zotero/storage/MGEBCE9R/1604.html}
}

@inproceedings{pirog_equational_2019,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Equational {{Theories}} and {{Monads}} from {{Polynomial Cayley Representations}}},
  isbn = {978-3-030-17127-8},
  abstract = {We generalise Cayley's theorem for monoids by providing an explicit formula for a (multi-sorted) equational theory represented by the type {$\mathsl{P}\mathsl{X}\rightarrow\mathsl{X}$}PX{$\rightarrow$}XPX \textbackslash{}rightarrow X, where {$\mathsl{P}$}PP is an arbitrary polynomial endofunctor with natural coefficients. From the computational perspective, examples of effects given by such theories include backtracking nondeterminism (obtained with the original Cayley representation {$\mathsl{X}\rightarrow\mathsl{X}$}X{$\rightarrow$}XX \textbackslash{}rightarrow X), finite mutable state (obtained with {$\mathsl{n}\rightarrow\mathsl{X}$}n{$\rightarrow$}Xn \textbackslash{}rightarrow X, for a constant n), and their different combinations (via {$\mathsl{n}\times\mathsl{X}\rightarrow\mathsl{X}$}n\texttimes{}X{$\rightarrow$}Xn \textbackslash{}times X \textbackslash{}rightarrow X or {$\mathsl{X}\mathsl{n}\rightarrow\mathsl{X}$}Xn{$\rightarrow$}XX\^n \textbackslash{}rightarrow X). Moreover, we show that monads induced by such theories are implementable using the type formers available in programming languages based on a polymorphic {$\mathsl{\Lambda}\lambda\backslash$}lambda -calculus, both as compositions of algebraic datatypes and as continuation-like monads. We give a set-theoretic model of the latter in terms of Barr-dinatural transformations. We also introduce CayMon, a tool that takes a polynomial as an input and generates the corresponding equational theory together with the two implementations of the induced monad in Haskell.},
  language = {en},
  booktitle = {Foundations of {{Software Science}} and {{Computation Structures}}},
  publisher = {{Springer International Publishing}},
  author = {Pir\'og, Maciej and Polesiuk, Piotr and Sieczkowski, Filip},
  editor = {Boja\'nczyk, Miko\l{}aj and Simpson, Alex},
  year = {2019},
  pages = {453-469},
  file = {/Users/doisinkidney/Zotero/storage/G55AGP6G/Piróg et al. - 2019 - Equational Theories and Monads from Polynomial Cay.pdf}
}

@article{fischer_technischen_nodate,
  title = {{der Technischen Fakult\"at der Christian-Albrechts-Universit\"at zu Kiel}},
  language = {de},
  author = {Fischer, Sebastian},
  pages = {223},
  file = {/Users/doisinkidney/Zotero/storage/PDUILD8J/Fischer - der Technischen Fakultät der Christian-Albrechts-U.pdf}
}

@techreport{pieters_handlers_2018,
  address = {Leuven},
  title = {Handlers for {{Non}}-{{Monadic Computations}} ({{Extended Version}})},
  shorttitle = {Handlers for {{Non}}-{{Monadic Computations}}},
  abstract = {Algebraic effects and handlers are a convenient method for struc- turing monadic effects with primitive effectful operations and sepa- rating the syntax from the interpretation of these operations. How- ever, the scope of conventional handlers are somewhat limited as not all side effects are monadic in nature.
This paper generalizes the notion of algebraic effects and handlers from monads to generalized monoids, which notably covers applica- tive functors and arrows. For this purpose we switch the category theoretical basis from free algebras to free monoids. In addition, we show how lax monoidal functors enable the reuse of handlers and programs across different computation classes, for example handling applicative computations with monadic handlers.},
  language = {en},
  number = {CW713},
  urldate = {2019-04-22},
  institution = {{Department of Computer Science, KU Leuven}},
  url = {http://www.cs.kuleuven.be/publicaties/rapporten/cw/CW713.pdf},
  author = {Pieters, Rubin P and Schrijvers, Tom and Exequiel, Rivas},
  month = mar,
  year = {2018},
  pages = {21},
  file = {/Users/doisinkidney/Zotero/storage/3EDGPEB4/CW713.pdf}
}

@inproceedings{pieters_handlers_2017,
  address = {Bristol, United Kingdom},
  title = {Handlers for {{Non}}-{{Monadic Computations}}},
  isbn = {978-1-4503-6343-3},
  abstract = {Algebraic effects and handlers are a convenient method for structuring monadic effects with primitive effectful operations and separating the syntax from the interpretation of these operations. However, the scope of convential handlers are somewhat limited as not all side effects are monadic in nature. This paper generalizes the notion of algebraic effects and handlers from monads to generalized monoids, which notably covers applicative functors and arrows. For this purpose we switch the category theoretical basis from free algebras to free monoids. In addition, we show how lax monoidal functors enable the reuse of handlers and programs across different computation classes, for example handling applicative computations with monadic handlers.},
  language = {en},
  urldate = {2019-04-22},
  booktitle = {Proceedings of the 29th {{Symposium}} on {{Implementation}} and {{Application}} of {{Functional Programming Languages}}  - {{IFL}} 2017},
  publisher = {{ACM Press}},
  doi = {10.1145/3205368.3205372},
  url = {http://dl.acm.org/citation.cfm?doid=3205368.3205372},
  author = {Pieters, Ruben P. and Schrijvers, Tom and Rivas, Exequiel},
  year = {2017},
  pages = {1-11},
  file = {/Users/doisinkidney/Zotero/storage/Y2836IUK/Pieters et al. - 2017 - Handlers for Non-Monadic Computations.pdf}
}

@inproceedings{schrijvers_heuristics_2014,
  address = {New York, NY, USA},
  series = {{{PPDP}} '14},
  title = {Heuristics {{Entwined}} with {{Handlers Combined}}: {{From Functional Specification}} to {{Logic Programming Implementation}}},
  isbn = {978-1-4503-2947-7},
  shorttitle = {Heuristics {{Entwined}} with {{Handlers Combined}}},
  abstract = {A long-standing problem in logic programming is how to cleanly separate logic and control. While solutions exist, they fall short in one of two ways: some are too intrusive, because they require significant changes to Prolog's underlying implementation; others are lacking a clean semantic grounding. We resolve both of these issues in this paper. We derive a solution that is both lightweight and principled. We do so by starting from a functional specification of Prolog based on monads, and extend this with the effect handlers approach to capture the dynamic search tree as syntax. Effect handlers then express heuristics in terms of tree transformations. Moreover, we can declaratively express many heuristics as trees themselves that are combined with search problems using a generic entwining handler. Our solution is not restricted to a functional model: we show how to implement this technique as a library in Prolog by means of delimited continuations.},
  urldate = {2019-04-22},
  booktitle = {Proceedings of the 16th {{International Symposium}} on {{Principles}} and {{Practice}} of {{Declarative Programming}}},
  publisher = {{ACM}},
  doi = {10.1145/2643135.2643145},
  url = {http://doi.acm.org/10.1145/2643135.2643145},
  author = {Schrijvers, Tom and Wu, Nicolas and Desouter, Benoit and Demoen, Bart},
  year = {2014},
  keywords = {monads,logic programming,delimited continuations,effect handlers,free monad transformer,heuristic tree search},
  pages = {259--270},
  file = {/Users/doisinkidney/Zotero/storage/BKUXGTYN/Schrijvers et al. - 2014 - Heuristics Entwined with Handlers Combined From F.pdf}
}

@inproceedings{karatsuba_multiplication_1962,
  title = {{Multiplication of Many-Digital Numbers by Automatic Computers}},
  volume = {145},
  language = {ru},
  booktitle = {{Doklady Akademii Nauk}},
  publisher = {{Russian Academy of Sciences}},
  author = {Karatsuba, Anatolii Alekseevich and Ofman, Yuri Petrovich},
  year = {1962},
  pages = {293--294},
  file = {/Users/doisinkidney/Zotero/storage/K4U4YKLM/Karatsuba and Ofman - Multiplication of many-digital numbers by automati.pdf;/Users/doisinkidney/Zotero/storage/XXMZMUSY/archive.html}
}

@article{hofner_dijkstra_2012,
  title = {Dijkstra, {{Floyd}} and {{Warshall}} Meet {{Kleene}}},
  volume = {24},
  issn = {0934-5043, 1433-299X},
  abstract = {Around 1960, Dijkstra, Floyd and Warshall published papers on algorithms for solving singlesource and all-sources shortest path problems, respectively. These algorithms, nowadays named after their inventors, are well known and well established. This paper sheds an algebraic light on these algorithms. We combine the shortest path problems with Kleene algebra, also known as Conway's regular algebra. This view yields a purely algebraic version of Dijkstra's shortest path algorithm and the one by Floyd/Warshall. Moreover, the algebraic abstraction yields applications of these algorithms to structures different from graphs and pinpoints the mathematical requirements on the underlying cost algebra that ensure their correctness.},
  language = {en},
  number = {4-6},
  urldate = {2019-04-23},
  journal = {Formal Aspects of Computing},
  doi = {10.1007/s00165-012-0245-4},
  url = {http://link.springer.com/10.1007/s00165-012-0245-4},
  author = {H\"ofner, Peter and M\"oller, Bernhard},
  month = jul,
  year = {2012},
  pages = {459-476},
  file = {/Users/doisinkidney/Zotero/storage/DLA3SE88/Höfner and Möller - 2012 - Dijkstra, Floyd and Warshall meet Kleene.pdf}
}

@inproceedings{piponi_commutative_2009,
  address = {New York, NY, USA},
  series = {{{ICFP}} '09},
  title = {Commutative {{Monads}}, {{Diagrams}} and {{Knots}}},
  isbn = {978-1-60558-332-7},
  abstract = {There is certain diverse class of diagram that is found in a variety of branches of mathematics and which all share this property: there is a common scheme for translating all of these diagrams into useful functional code. These diagrams include Bayesian networks, quantum computer circuits [1], trace diagrams for multilinear algebra [2], Feynman diagrams and even knot diagrams [3]. I will show how a common thread lying behind these diagrams is the presence of a commutative monad and I will show how we can use this fact to translate these diagrams directly into Haskell code making use of do-notation for monads. I will also show a number of examples of such translated code at work and use it to solve problems ranging from Bayesian inference to the topological problem of untangling tangled strings. Along the way I hope to give a little insight into the subjects mentioned above and illustrate how a functional programming language can be a valuable tool in mathematical research and experimentation.},
  language = {en},
  urldate = {2019-04-23},
  booktitle = {Proceedings of the 14th {{ACM SIGPLAN International Conference}} on {{Functional Programming}}},
  publisher = {{ACM}},
  doi = {10.1145/1596550.1596553},
  url = {http://doi.acm.org/10.1145/1596550.1596553},
  author = {Piponi, Dan P.},
  year = {2009},
  keywords = {knot theory,linear algebra,monads,tensor networks},
  pages = {231--232},
  file = {/Users/doisinkidney/Zotero/storage/3GJZY7HX/Piponi - Commutative monads, diagrams and knots.pdf}
}

@misc{piponi_diagrams_2009,
  address = {Edinburgh},
  title = {Diagrams, {{Commutative Monads}} and {{Knots}}},
  abstract = {There is certain diverse class of diagram that is found in a variety of branches of mathematics and which all share this property: there is a common scheme for translating all of these diagrams into useful functional code. These diagrams include Bayesian networks, quantum computer circuits [1], trace diagrams for multilinear algebra [2], Feynman diagrams and even knot diagrams [3]. I will show how a common thread lying behind these diagrams is the presence of a commutative monad and I will show how we can use this fact to translate these diagrams directly into Haskell code making use of do-notation for monads. I will also show a number of examples of such translated code at work and use it to solve problems ranging from Bayesian inference to the topological problem of untangling tangled strings. Along the way I hope to give a little insight into the subjects mentioned above and illustrate how a functional programming language can be a valuable tool in mathematical research and experimentation.},
  language = {en},
  urldate = {2019-04-23},
  url = {https://vimeo.com/6590617},
  author = {Piponi, Dan},
  year = {2009},
  file = {/Users/doisinkidney/Zotero/storage/LUFSQZ39/Piponi - Diagrams, Commutative Monads and Knots.pdf}
}

@article{spivey_combinators_2000,
  title = {Combinators for Breadth-First Search},
  volume = {10},
  issn = {1469-7653, 0956-7968},
  abstract = {Every functional programmer knows the technique of ``replacing failure by a list of
successes'' (Wadler, 1985), but wise programmers are aware also of the possibility
that the list will be empty or (worse) divergent. In fact, the ``lists of successes''
technique is equivalent to the incomplete depth-first search strategy used in Prolog.At heart, the idea is quite simple: whenever we might want to use a `multi-function' such as
`f' [ratio ][ratio ] {$\alpha$} [Rarr ] {$\beta$} that can return many results or none, we replace it by a
genuine function f [ratio ][ratio ] {$\alpha$} {$\rightarrow$} {$\beta$} stream that returns a lazy stream of results, and
rely on lazy evaluation to compute the answers one at a time, and only as they are needed. For
the sake of clarity, I will distinguish between the types of finite lists ({$\alpha$} list) and of
potentially infinite, lazy streams ({$\alpha$} stream), though both may be implemented in the
same way. Following the conventions used in ML, type constructors follow their argument types.},
  language = {en},
  number = {4},
  urldate = {2019-04-23},
  journal = {Journal of Functional Programming},
  url = {https://www.cambridge.org/core/journals/journal-of-functional-programming/article/combinators-for-breadthfirst-search/60383337C85657F3F6549C18F4E345BA},
  author = {Spivey, Michael},
  month = jul,
  year = {2000},
  pages = {397-408},
  file = {/Users/doisinkidney/Zotero/storage/79QNQM45/download\;jsessionid=A267805D8847F9EFA93C73A9811088C3.pdf;/Users/doisinkidney/Zotero/storage/VH9ZW98N/Spivey - Combinators for Breadth-First Search.pdf;/Users/doisinkidney/Zotero/storage/LLWQT9I7/60383337C85657F3F6549C18F4E345BA.html;/Users/doisinkidney/Zotero/storage/QX7BPARU/summary.html}
}

@inproceedings{jaskelioff_functional_2015,
  address = {New York, NY, USA},
  series = {{{ICFP}} 2015},
  title = {Functional {{Pearl}}: {{A Smart View}} on {{Datatypes}}},
  isbn = {978-1-4503-3669-7},
  shorttitle = {Functional {{Pearl}}},
  abstract = {Left-nested list concatenations, left-nested binds on the free monad, and left-nested choices in many non-determinism monads have an algorithmically bad performance. Can we solve this problem without losing the ability to pattern-match on the computation? Surprisingly, there is a deceptively simple solution: use a smart view to pattern-match on the datatype. We introduce the notion of smart view and show how it solves the problem of slow left-nested operations. In particular, we use the technique to obtain fast and simple implementations of lists, of free monads, and of two non-determinism monads.},
  urldate = {2019-04-23},
  booktitle = {Proceedings of the 20th {{ACM SIGPLAN International Conference}} on {{Functional Programming}}},
  publisher = {{ACM}},
  doi = {10.1145/2784731.2784743},
  url = {http://doi.acm.org/10.1145/2784731.2784743},
  author = {Jaskelioff, Mauro and Rivas, Exequiel},
  year = {2015},
  keywords = {Data Structure,List,Monad,MonadPlus},
  pages = {355--361}
}

@inproceedings{seres_algebra_1999-1,
  title = {The Algebra of Logic Programming},
  abstract = {A declarative programming language has two kinds of semantics The more abstract helps in reasoning about speci cations and correctness while an operational semantics determines the manner of program exe cution A correct program should reconcile its abstract meaning with its concrete interpretation To help in this we present a kind of algebraic semantics for logic pro gramming It lists only those laws that are equally valid for predicate calculus and for the standard depth rst strategy of Prolog An alterna tive strategy is breadth rst search which shares many of the same laws Both strategies are shown to be special cases of the most general strat egy that for tree searching The three strategies are de ned in the lazy functional language Haskell so that each law can be proved by standard algebraic reasoning The laws are an enrichment of the familiar categorical concept of a monad and the links between such monads are explored},
  booktitle = {{{ICLP}}},
  author = {Seres, Silvija},
  year = {1999},
  keywords = {Algebraic semantics (computer science),Boolean algebra,Correctness (computer science),Declarative programming,First-order logic,Functional programming,Gene Ontology Term Enrichment,Haskell,Lazy evaluation,Linear algebra,Logic programming,Monad (functional programming),Operational semantics,Programming language,Prolog},
  file = {/Users/doisinkidney/Zotero/storage/THCK9WRT/Seres - 1999 - The algebra of logic programming.pdf}
}

@article{spivey_algebra_2000,
  title = {The {{Algebra}} of {{Searching}}},
  abstract = {this paper, we seek to develop a logic for logic programs that takes into account this procedural aspect of their behaviour under dierent search strategies, emphasizing algebraic properties that are common to all search strategies.},
  author = {Spivey, Mike and Seres, Silvija},
  month = jan,
  year = {2000},
  file = {/Users/doisinkidney/Zotero/storage/2HLJXNZ7/seres_carh99.pdf;/Users/doisinkidney/Zotero/storage/3P98FZXW/Spivey and Seres - 2000 - The Algebra of Searching.pdf}
}

@article{ahman_update_2014,
  title = {Update {{Monads}}: {{Cointerpreting Directed Containers}}},
  shorttitle = {Update {{Monads}}},
  abstract = {We introduce update monads as a generalization of state monads. Update monads are the compatible compositions of reader and writer monads given by a set and a monoid. Distributive laws between such monads are given by actions of the monoid on the set.},
  language = {en},
  urldate = {2019-04-23},
  doi = {10.4230/lipics.types.2013.1},
  url = {http://drops.dagstuhl.de/opus/volltexte/2014/4623/},
  author = {Ahman, Danel and Uustalu, Tarmo},
  collaborator = {Herbstritt, Marc},
  year = {2014},
  keywords = {000 Computer science; knowledge; general works,Computer Science},
  pages = {23 pages},
  file = {/Users/doisinkidney/Zotero/storage/AGEKW4XZ/Ahman and Uustalu - 2014 - Update Monads Cointerpreting Directed Containers.pdf}
}

@misc{kmett_how_2015,
  title = {How to {{Replace Failure}} by a {{Heap}} of {{Successes}} - {{School}} of {{Haskell}} | {{School}} of {{Haskell}}},
  language = {en},
  urldate = {2019-04-23},
  journal = {School of Haskell},
  url = {https://www.schoolofhaskell.com/user/edwardk/heap-of-successes},
  author = {Kmett, Edward},
  month = may,
  year = {2015},
  file = {/Users/doisinkidney/Zotero/storage/BUEPUGRY/heap-of-successes.html}
}

@article{schrijvers_search_2012,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1203.1095},
  primaryClass = {cs},
  title = {Search {{Combinators}}},
  abstract = {The ability to model search in a constraint solver can be an essential asset for solving combinatorial problems. However, existing infrastructure for defining search heuristics is often inadequate. Either modeling capabilities are extremely limited or users are faced with a general-purpose programming language whose features are not tailored towards writing search heuristics. As a result, major improvements in performance may remain unexplored. This article introduces search combinators, a lightweight and solver-independent method that bridges the gap between a conceptually simple modeling language for search (high-level, functional and naturally compositional) and an efficient implementation (low-level, imperative and highly non-modular). By allowing the user to define application-tailored search strategies from a small set of primitives, search combinators effectively provide a rich domain-specific language (DSL) for modeling search to the user. Remarkably, this DSL comes at a low implementation cost to the developer of a constraint solver. The article discusses two modular implementation approaches and shows, by empirical evaluation, that search combinators can be implemented without overhead compared to a native, direct implementation in a constraint solver.},
  urldate = {2019-04-24},
  journal = {arXiv:1203.1095 [cs]},
  url = {http://arxiv.org/abs/1203.1095},
  author = {Schrijvers, Tom and Tack, Guido and Wuille, Pieter and Samulowitz, Horst and Stuckey, Peter J.},
  month = mar,
  year = {2012},
  keywords = {Computer Science - Artificial Intelligence},
  file = {/Users/doisinkidney/Zotero/storage/J7AY24S9/Schrijvers et al. - 2012 - Search Combinators.pdf;/Users/doisinkidney/Zotero/storage/M53VXZ6K/1203.html}
}

@article{chapman_quotienting_nodate,
  title = {Quotienting the {{Delay Monad}} by {{Weak Bisimilarity}}},
  abstract = {The delay datatype was introduced by Capretta [3] as a means to deal with partial functions (as in computability theory) in Martin-Lo\textasciidieresis{}f type theory. It is a monad and it constitutes a constructive alternative to the maybe monad. It is often desirable to consider two delayed computations equal, if they terminate with equal values, whenever one of them terminates. The equivalence relation underlying this identification is called weak bisimilarity. In type theory, one commonly replaces quotients with setoids. In this approach, the delay monad quotiented by weak bisimilarity is still a monad. In this paper, we consider Hofmann's alternative approach [6] of extending type theory with inductive-like quotient types. In this setting, it is difficult to define the intended monad multiplication for the quotiented datatype. We give a solution where we postulate some principles, crucially proposition extensionality and the (semi-classical) axiom of countable choice. We have fully formalized our results in the Agda dependently typed programming language.},
  language = {en},
  author = {Chapman, James and Uustalu, Tarmo and Veltri, Niccolo},
  pages = {16},
  file = {/Users/doisinkidney/Zotero/storage/G988UC46/Chapman et al. - Quotienting the Delay Monad by Weak Bisimilarity.pdf}
}

@article{mcmahan_generalizing_2005,
  title = {Generalizing {{Dijkstra}}'s {{Algorithm}} and {{Gaussian Elimination}} for {{Solving MDPs}}},
  abstract = {We study the problem of computing the optimal value function for a Markov decision process with positive costs. Computing this function quickly and accurately is a basic step in many schemes for deciding how to act in stochastic environments. There are efficient algorithms which compute value functions for special types of MDPs: for deterministic MDPs with S states and A actions, Dijkstra's algorithm runs in time O(AS log S). And, in single-action MDPs (Markov chains), standard linear-algebraic algorithms find the value function in time O(S3), or faster by taking advantage of sparsity or good conditioning. Algorithms for solving general MDPs can take much longer: we are not aware of any speed guarantees better than those for comparably-sized linear programs. We present a family of algorithms which reduce to Dijkstra's algorithm when applied to deterministic MDPs, and to standard techniques for solving linear equations when applied to Markov chains. More importantly, we demonstrate experimentally that these algorithms perform well when applied to MDPs which ``almost'' have the required special structure.},
  language = {en},
  author = {McMahan, H Brendan and Gordon, Geoffrey J},
  month = may,
  year = {2005},
  pages = {24},
  file = {/Users/doisinkidney/Zotero/storage/YIR7D4JV/McMahan and Gordon - Generalizing Dijkstra’s Algorithm and Gaussian Eli.pdf}
}

@article{edelkamp_cost-algebraic_2005,
  title = {Cost-{{Algebraic Heuristic Search}}},
  abstract = {Heuristic search is used to efficiently solve the single-node shortest path problem in weighted graphs. In practice, however, one is not only interested in finding a short path, but an optimal path, according to a certain cost notion. We propose an algebraic formalism that captures many cost notions, like typical Quality of Service attributes. We thus generalize A*, the popular heuristic search algorithm, for solving optimal-path problem. The paper provides an answer to a fundamental question for AI search, namely to which general notion of cost, heuristic search algorithms can be applied. We proof correctness of the algorithms and provide experimental results that validate the feasibility of the approach.},
  language = {en},
  author = {Edelkamp, Stefan},
  year = {2005},
  pages = {6},
  file = {/Users/doisinkidney/Zotero/storage/54NQKH39/Edelkamp - Cost-Algebraic Heuristic Search.pdf;/Users/doisinkidney/Zotero/storage/YBVSB6EL/Edelkamp - Cost-Algebraic Heuristic Search.pdf}
}

@inproceedings{guttmann_relation-algebraic_2016,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Relation-{{Algebraic Verification}} of {{Prim}}'s {{Minimum Spanning Tree Algorithm}}},
  isbn = {978-3-319-46750-4},
  abstract = {We formally prove the correctness of Prim's algorithm for computing minimum spanning trees. We introduce new generalisations of relation algebras and Kleene algebras, in which most of the proof can be carried out. Only a small part needs additional operations, for which we introduce a new algebraic structure. We instantiate these algebras by matrices over extended reals, which model the weighted graphs used in the algorithm. Many existing results from relation algebras and Kleene algebras generalise from the relation model to the weighted-graph model with no or small changes. The overall structure of the proof uses Hoare logic. All results are formally verified in Isabelle/HOL heavily using its integrated automated theorem provers.},
  language = {en},
  booktitle = {Theoretical {{Aspects}} of {{Computing}} \textendash{} {{ICTAC}} 2016},
  publisher = {{Springer International Publishing}},
  author = {Guttmann, Walter},
  editor = {Sampaio, Augusto and Wang, Farn},
  year = {2016},
  pages = {51-68}
}

@article{mohri_semiring_nodate-2,
  title = {Semiring {{Frameworks}} and {{Algorithms}} for {{Shortest}}-{{Distance Problems}}},
  abstract = {We define general algebraic frameworks for shortest-distance problems based on the structure of semirings. We give a generic algorithm for finding single-source shortest distances in a weighted directed graph when the weights satisfy the conditions of our general semiring framework. The same algorithm can be used to solve efficiently classical shortest paths problems or to find the k-shortest distances in a directed graph. It can be used to solve single-source shortest-distance problems in weighted directed acyclic graphs over any semiring. We examine several semirings and describe some specific instances of our generic algorithms to illustrate their use and compare them with existing methods and algorithms. The proof of the soundness of all algorithms is given in detail, including their pseudocode and a full analysis of their running time complexity.},
  language = {en},
  author = {Mohri, Mehryar},
  pages = {30},
  file = {/Users/doisinkidney/Zotero/storage/PHS7HCML/Mohri - Semiring Frameworks and Algorithms for Shortest-Di.pdf;/Users/doisinkidney/Zotero/storage/X2QAWB8Y/Mohri - Semiring Frameworks and Algorithms for Shortest-Di.pdf;/Users/doisinkidney/Zotero/storage/ZE652TTT/Mohri - Semiring Frameworks and Algorithms for Shortest-Di.pdf;/Users/doisinkidney/Zotero/storage/JB9RZRCP/summary.html}
}

@inproceedings{green_provenance_2007-1,
  address = {Beijing, China},
  title = {Provenance Semirings},
  isbn = {978-1-59593-685-1},
  abstract = {We show that relational algebra calculations for incomplete databases, probabilistic databases, bag semantics and whyprovenance are particular cases of the same general algorithms involving semirings. This further suggests a comprehensive provenance representation that uses semirings of polynomials. We extend these considerations to datalog and semirings of formal power series. We give algorithms for datalog provenance calculation as well as datalog evaluation for incomplete and probabilistic databases. Finally, we show that for some semirings containment of conjunctive queries is the same as for standard set semantics.},
  language = {en},
  urldate = {2019-04-29},
  booktitle = {Proceedings of the Twenty-Sixth {{ACM SIGMOD}}-{{SIGACT}}-{{SIGART}} Symposium on {{Principles}} of Database Systems  - {{PODS}} '07},
  publisher = {{ACM Press}},
  doi = {10.1145/1265530.1265535},
  url = {http://portal.acm.org/citation.cfm?doid=1265530.1265535},
  author = {Green, Todd J. and Karvounarakis, Grigoris and Tannen, Val},
  year = {2007},
  pages = {31},
  file = {/Users/doisinkidney/Zotero/storage/N7CPZPTZ/Green et al. - 2007 - Provenance Semirings.pdf;/Users/doisinkidney/Zotero/storage/UNHHYMFZ/Green et al. - 2007 - Provenance semirings.pdf}
}

@article{bernardy_certified_2016-1,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1601.07724},
  title = {Certified {{Context}}-{{Free Parsing}}: {{A}} Formalisation of {{Valiant}}'s {{Algorithm}} in {{Agda}}},
  volume = {12},
  issn = {18605974},
  shorttitle = {Certified {{Context}}-{{Free Parsing}}},
  abstract = {Valiant (1975) has developed an algorithm for recognition of context free languages. As of today, it remains the algorithm with the best asymptotic complexity for this purpose. In this paper, we present an algebraic specification, implementation, and proof of correctness of a generalisation of Valiant's algorithm. The generalisation can be used for recognition, parsing or generic calculation of the transitive closure of upper triangular matrices. The proof is certified by the Agda proof assistant. The certification is representative of state-of-the-art methods for specification and proofs in proof assistants based on type-theory. As such, this paper can be read as a tutorial for the Agda system.},
  number = {2},
  urldate = {2019-04-29},
  journal = {Logical Methods in Computer Science},
  doi = {10.2168/LMCS-12(2:6)2016},
  url = {http://arxiv.org/abs/1601.07724},
  author = {Bernardy, Jean-Philippe and Jansson, Patrik},
  month = jun,
  year = {2016},
  keywords = {Computer Science - Logic in Computer Science,F.4.1,F.4.2},
  pages = {6},
  file = {/Users/doisinkidney/Zotero/storage/53P9TW38/Bernardy and Jansson - 2016 - Certified Context-Free Parsing A formalisation of.pdf;/Users/doisinkidney/Zotero/storage/GJQ7ZX3J/Bernardy and Jansson - 2016 - Certified Context-Free Parsing A formalisation of.pdf;/Users/doisinkidney/Zotero/storage/SJE2AMQ7/Bernardy and Jansson - 2016 - Certified Context-Free Parsing A formalisation of.pdf;/Users/doisinkidney/Zotero/storage/3MG2VFP7/1601.html;/Users/doisinkidney/Zotero/storage/8D9MHWLY/1601.html;/Users/doisinkidney/Zotero/storage/G6P4CLVI/1601.html}
}

@article{saenz-carrasco_functional_2016,
  title = {Functional {{Programming}} and {{Non}}-{{Distributivity}} in {{Pathfinding}} Problems},
  language = {en},
  author = {{Saenz-Carrasco}, Juan Carlos},
  month = dec,
  year = {2016},
  pages = {98},
  file = {/Users/doisinkidney/Zotero/storage/DHXAEY65/Saenz-Carrasco - Functional Programming and Non-Distributivity in P.pdf}
}

@incollection{atallah_theory_2009,
  title = {Theory of {{Privacy}} and {{Anonymity}}},
  volume = {4},
  isbn = {978-1-58488-820-8 978-1-58488-821-5},
  language = {en},
  urldate = {2019-04-29},
  booktitle = {Algorithms and {{Theory}} of {{Computation Handbook}}, {{Second Edition}}, {{Volume}} 2},
  publisher = {{Chapman and Hall/CRC}},
  url = {http://www.crcnetbase.com/doi/abs/10.1201/9781584888215-c18},
  author = {Ciriani, Valentina and Vimercati, Sabrina and Foresti, Sara and Samarati, Pierangela},
  editor = {Atallah, Mikhail and Blanton, Marina},
  month = nov,
  year = {2009},
  pages = {1-35},
  file = {/Users/doisinkidney/Zotero/storage/JGHXE46W/Ciriani et al. - 2009 - Theory of Privacy and Anonymity.pdf},
  doi = {10.1201/9781584888215-c18}
}

@article{hinze_concrete_2010-1,
  title = {Concrete Stream Calculus: {{An}} Extended Study},
  volume = {20},
  issn = {0956-7968, 1469-7653},
  shorttitle = {Concrete Stream Calculus},
  abstract = {This paper shows how to reason about streams concisely and precisely. Streams, infinite sequences of elements, live in a coworld: they are given by a coinductive datatype, operations on streams are implemented by corecursive programs, and proofs are typically concocted using coinduction. This paper offers an alternative to coinduction. Suitably restricted, stream equations possess unique solutions. This property gives rise to a simple and attractive proof technique, essentially bringing equational reasoning to the coworld. We redevelop the theory of recurrences, finite calculus and generating functions using streams and stream operators, building on the cornerstone of unique solutions. The paper contains a sm\"org\aa{}sbord of examples: we study recursion elimination, investigate the binary carry sequence, explore Sprague-Grundy numbers and present two proofs of Moessner's Theorem. The calculations benefit from the rich structure of streams. As the type of streams is an applicative functor we can effortlessly lift operations and their properties to streams. In combination with Haskell's facilities for overloading, this greatly contributes to conciseness of notation. The development is indeed constructive: streams and stream operators are implemented in Haskell, usually by one-liners. The resulting calculus or library, if you wish, is elegant and fun to use.},
  language = {en},
  number = {5-6},
  urldate = {2019-04-29},
  journal = {Journal of Functional Programming},
  doi = {10.1017/S0956796810000213},
  url = {https://www.cambridge.org/core/product/identifier/S0956796810000213/type/journal_article},
  author = {Hinze, Ralf},
  month = nov,
  year = {2010},
  pages = {463-535},
  file = {/Users/doisinkidney/Zotero/storage/AXHV4QKA/Hinze - 2010 - Concrete stream calculus An extended study.pdf;/Users/doisinkidney/Zotero/storage/LE7UCKFI/Hinze - 2010 - Concrete stream calculus An extended study.pdf;/Users/doisinkidney/Zotero/storage/SISIB8JN/F5DADE7E7819BB96D9091F3404AFB323.html}
}

@article{hinze_efcient_1999,
  title = {Efficient {{Monadic}}-Style {{Backtracking}}},
  abstract = {Lists are ubiquitous in functional programming. The list constructor forms an instance of a monad capturing non-deterministic computations. Despite its popularity the list monad suffers from serious drawbacks: It relies in an essential way on lazy evaluation, it is inefficient, and it is not modular. We develop an alternative based on continuations, which remedies these shortcomings. Essential use is made of constructor classes and second-order types, which sets the work apart from other approaches. Continuation-based backtracking monads behave amazingly well in practice: If an optimizing compiler is used, their performance is commensurate to that of logic languages. The class mechanism greatly eases the task of adding features to the basic machinery. We study three extensions in detail: control operations, all solutions functions, and exception handling.},
  language = {en},
  author = {Hinze, Ralf},
  month = sep,
  year = {1999},
  pages = {51},
  file = {/Users/doisinkidney/Zotero/storage/MBKEMS4W/Hinze - Efﬁcient Monadic-style Backtracking.pdf}
}

@article{schrijvers_monadic_2009-2,
  title = {Monadic Constraint Programming},
  volume = {19},
  issn = {1469-7653, 0956-7968},
  abstract = {A constraint programming system combines two essential components: a constraint solver and a search engine. The constraint solver reasons about satisfiability of conjunctions of constraints, and the search engine controls the search for solutions by iteratively exploring a disjunctive search tree defined by the constraint program. In this paper we give a monadic definition of constraint programming in which the solver is defined as a monad threaded through the monadic search tree. We are then able to define search and search strategies as first-class objects that can themselves be built or extended by composable search transformers. Search transformers give a powerful and unifying approach to viewing search in constraint programming, and the resulting constraint programming system is first class and extremely flexible.},
  language = {en},
  number = {6},
  urldate = {2019-04-29},
  journal = {Journal of Functional Programming},
  doi = {10.1017/S0956796809990086},
  url = {https://www.cambridge.org/core/journals/journal-of-functional-programming/article/monadic-constraint-programming/213541C635A4EEC9ADA73B345B731E9D},
  author = {Schrijvers, Tom and Stuckey, Peter and Wadler, Philip},
  month = nov,
  year = {2009},
  pages = {663-697},
  file = {/Users/doisinkidney/Zotero/storage/JWHRLTMP/Schrijvers et al. - 2009 - Monadic constraint programming.pdf;/Users/doisinkidney/Zotero/storage/EJARFNLK/213541C635A4EEC9ADA73B345B731E9D.html;/Users/doisinkidney/Zotero/storage/K6SP22RV/213541C635A4EEC9ADA73B345B731E9D.html},
  note = {https://people.cs.kuleuven.be/\textasciitilde{}tom.schrijvers/MCP/}
}

@inproceedings{fischer_purely_2009,
  address = {New York, NY, USA},
  series = {{{ICFP}} '09},
  title = {Purely {{Functional Lazy Non}}-Deterministic {{Programming}}},
  isbn = {978-1-60558-332-7},
  abstract = {Functional logic programming and probabilistic programming have demonstrated the broad benefits of combining laziness (non-strict evaluation with sharing of the results) with non-determinism. Yet these benefits are seldom enjoyed in functional programming, because the existing features for non-strictness, sharing, and non-determinism in functional languages are tricky to combine. We present a practical way to write purely functional lazy non-deterministic programs that are efficient and perspicuous. We achieve this goal by embedding the programs into existing languages (such as Haskell, SML, and OCaml) with high-quality implementations, by making choices lazily and representing data with non-deterministic components, by working with custom monadic data types and search strategies, and by providing equational laws for the programmer to reason about their code.},
  urldate = {2019-04-29},
  booktitle = {Proceedings of the 14th {{ACM SIGPLAN International Conference}} on {{Functional Programming}}},
  publisher = {{ACM}},
  doi = {10.1145/1596550.1596556},
  url = {http://doi.acm.org/10.1145/1596550.1596556},
  author = {Fischer, Sebastian and Kiselyov, Oleg and Shan, Chung-chieh},
  year = {2009},
  keywords = {call-time choice,continuations,monads,side effects},
  pages = {11--22},
  file = {/Users/doisinkidney/Zotero/storage/85SBXKF9/Fischer et al. - 2009 - Purely Functional Lazy Non-deterministic Programmi.pdf;/Users/doisinkidney/Zotero/storage/ZEY84LVL/Fischer et al. - 2009 - Purely Functional Lazy Non-deterministic Programmi.pdf}
}

@article{hyland_combining_2007,
  series = {Festschrift for {{John C}}. {{Reynolds}}'s 70th Birthday},
  title = {Combining Algebraic Effects with Continuations},
  volume = {375},
  issn = {0304-3975},
  abstract = {We consider the natural combinations of algebraic computational effects such as side-effects, exceptions, interactive input/output, and nondeterminism with continuations. Continuations are not an algebraic effect, but previously developed combinations of algebraic effects given by sum and tensor extend, with effort, to include commonly used combinations of the various algebraic effects with continuations. Continuations also give rise to a third sort of combination, that given by applying the continuations monad transformer to an algebraic effect. We investigate the extent to which sum and tensor extend from algebraic effects to arbitrary monads, and the extent to which Felleisen et~al.'s C operator extends from continuations to its combination with algebraic effects. To do all this, we use Dubuc's characterisation of strong monads in terms of enriched large Lawvere theories.},
  number = {1},
  urldate = {2019-04-29},
  journal = {Theoretical Computer Science},
  doi = {10.1016/j.tcs.2006.12.026},
  url = {http://www.sciencedirect.com/science/article/pii/S0304397506009157},
  author = {Hyland, Martin and Levy, Paul Blain and Plotkin, Gordon and Power, John},
  month = may,
  year = {2007},
  keywords = {Computational effect,Lawvere theory,Modularity,Monad},
  pages = {20-40},
  file = {/Users/doisinkidney/Zotero/storage/9JFVV7TA/Hyland et al. - 2007 - Combining algebraic effects with continuations.pdf;/Users/doisinkidney/Zotero/storage/FD9DARPQ/S0304397506009157.html}
}

@inproceedings{milius_complete_2009,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Complete {{Iterativity}} for {{Algebras}} with {{Effects}}},
  isbn = {978-3-642-03741-2},
  abstract = {Completely iterative algebras (cias) are those algebras in which recursive equations have unique solutions. In this paper we study complete iterativity for algebras with computational effects (described by a monad). First, we prove that for every analytic endofunctor on Set there exists a canonical distributive law over any commutative monad M, hence a lifting of that endofunctor to the Kleisli category of M. Then, for an arbitrary distributive law {$\lambda$} of an endofunctor H on Set over a monad M we introduce {$\lambda$}-cias. The cias for the corresponding lifting of H (called Kleisli-cias) form a full subcategory of the category of {$\lambda$}-cias. For various monads of interest we prove that free Kleisli-cias coincide with free {$\lambda$}-cias, and these free algebras are given by free algebras for H. Finally, for three concrete examples of monads we prove that Kleisli-cias and {$\lambda$}-cias coincide and give a characterisation of those algebras.},
  language = {en},
  booktitle = {Algebra and {{Coalgebra}} in {{Computer Science}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Milius, Stefan and Palm, Thorsten and Schwencke, Daniel},
  editor = {Kurz, Alexander and Lenisa, Marina and Tarlecki, Andrzej},
  year = {2009},
  keywords = {distributive law,initial algebra,iterative algebra,monad,terminal coalgebra},
  pages = {34-48}
}

@inproceedings{vandenbroucke_fixing_2015,
  address = {Koblenz, Germany},
  title = {Fixing Non-Determinism},
  isbn = {978-1-4503-4273-5},
  abstract = {Non-deterministic computations are conventionally modelled by lists of their outcomes. This approach provides a concise declarative description of certain problems, as well as a way of generically solving such problems.},
  language = {en},
  urldate = {2019-04-29},
  booktitle = {Proceedings of the 27th {{Symposium}} on the {{Implementation}} and {{Application}} of {{Functional Programming Languages}} - {{IFL}} '15},
  publisher = {{ACM Press}},
  doi = {10.1145/2897336.2897342},
  url = {http://dl.acm.org/citation.cfm?doid=2897336.2897342},
  author = {Vandenbroucke, Alexander and Schrijvers, Tom and Piessens, Frank},
  year = {2015},
  pages = {1-12},
  file = {/Users/doisinkidney/Zotero/storage/CDD9XNVG/Vandenbroucke et al. - 2015 - Fixing non-determinism.pdf;/Users/doisinkidney/Zotero/storage/K2Q3SXL7/Vandenbroucke et al. - 2015 - Fixing non-determinism.pdf}
}

@inproceedings{ford_packrat_2002-2,
  address = {New York, NY, USA},
  series = {{{ICFP}} '02},
  title = {Packrat {{Parsing}}:: {{Simple}}, {{Powerful}}, {{Lazy}}, {{Linear Time}}, {{Functional Pearl}}},
  isbn = {978-1-58113-487-2},
  shorttitle = {Packrat {{Parsing}}},
  abstract = {Packrat parsing is a novel technique for implementing parsers in a lazy functional programming language. A packrat parser provides the power and flexibility of top-down parsing with backtracking and unlimited lookahead, but nevertheless guarantees linear parse time. Any language defined by an LL(k) or LR(k) grammar can be recognized by a packrat parser, in addition to many languages that conventional linear-time algorithms do not support. This additional power simplifies the handling of common syntactic idioms such as the widespread but troublesome longest-match rule, enables the use of sophisticated disambiguation strategies such as syntactic and semantic predicates, provides better grammar composition properties, and allows lexical analysis to be integrated seamlessly into parsing. Yet despite its power, packrat parsing shares the same simplicity and elegance as recursive descent parsing; in fact converting a backtracking recursive descent parser into a linear-time packrat parser often involves only a fairly straightforward structural change. This paper describes packrat parsing informally with emphasis on its use in practical applications, and explores its advantages and disadvantages with respect to the more conventional alternatives.},
  language = {en},
  urldate = {2019-04-29},
  booktitle = {Proceedings of the {{Seventh ACM SIGPLAN International Conference}} on {{Functional Programming}}},
  publisher = {{ACM}},
  doi = {10.1145/581478.581483},
  url = {http://doi.acm.org/10.1145/581478.581483},
  author = {Ford, Bryan},
  year = {2002},
  keywords = {backtracking,Haskell,lexical analysis,memoization,parser combinators,scannerless parsing,top-down parsing},
  pages = {112},
  file = {/Users/doisinkidney/Zotero/storage/94SZVRXD/Ford - Packrat Parsing a Practical Linear-Time Algorithm.pdf;/Users/doisinkidney/Zotero/storage/R2CSLLCS/Ford - Packrat Parsing a Practical Linear-Time Algorithm.pdf;/Users/doisinkidney/Zotero/storage/WQQD9SBF/Ford - Packrat Parsing a Practical Linear-Time Algorithm.pdf}
}

@inproceedings{devriese_fixing_2013-1,
  address = {Rome, Italy},
  title = {Fixing Idioms: A Recursion Primitive for Applicative {{DSLs}}},
  isbn = {978-1-4503-1842-6},
  shorttitle = {Fixing Idioms},
  abstract = {In a lazy functional language, the standard encoding of recursion in DSLs uses the host language's recursion, so that DSL algorithms automatically use the host language's least fixpoints, even though many domains require algorithms to produce different fixpoints. In particular, this is the case for DSLs implemented as Applicative functors (structures with a notion of pure computations and function application). We propose a recursion primitive afix that models a recursive binder in a finally tagless HOAS encoding, but with a novel rank-2 type that allows us to specify and exploit the effectsvalues separation that characterises Applicative DSLs. Unlike related approaches for Monad s and Arrow s, we model effectful recursion, not value recursion.},
  language = {en},
  urldate = {2019-05-03},
  booktitle = {Proceedings of the {{ACM SIGPLAN}} 2013 Workshop on {{Partial}} Evaluation and Program Manipulation - {{PEPM}} '13},
  publisher = {{ACM Press}},
  doi = {10.1145/2426890.2426910},
  url = {http://dl.acm.org/citation.cfm?doid=2426890.2426910},
  author = {Devriese, Dominique and Sergey, Ilya and Clarke, Dave and Piessens, Frank},
  year = {2013},
  keywords = {applicative functors,hoas,observable recursion},
  pages = {97},
  file = {/Users/doisinkidney/Zotero/storage/JWSMGJI2/Devriese et al. - 2013 - Fixing idioms a recursion primitive for applicati.pdf}
}

@inproceedings{firsov_certified_2013-1,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Certified {{Parsing}} of {{Regular Languages}}},
  isbn = {978-3-319-03545-1},
  abstract = {We report on a certified parser generator for regular languages using the Agda programming language. Specifically, we programmed a transformation of regular expressions into a Boolean-matrix based representation of nondeterministic finite automata (NFAs). And we proved (in Agda) that a string matches a regular expression if and only if the NFA accepts it. The proof of the if-part is effectively a function turning acceptance of a string into a parse tree while the only-if part gives a function turning rejection into a proof of impossibility of a parse tree.},
  language = {en},
  booktitle = {Certified {{Programs}} and {{Proofs}}},
  publisher = {{Springer International Publishing}},
  author = {Firsov, Denis and Uustalu, Tarmo},
  editor = {Gonthier, Georges and Norrish, Michael},
  year = {2013},
  keywords = {Incidence Matrix,Parse Tree,Pattern Match,Regular Expression,Regular Language},
  pages = {98-113},
  file = {/Users/doisinkidney/Zotero/storage/42TMAGWF/Firsov and Uustalu - 2013 - Certified Parsing of Regular Languages.pdf}
}

@inproceedings{lopes_certified_2016,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Certified {{Derivative}}-{{Based Parsing}} of {{Regular Expressions}}},
  isbn = {978-3-319-45279-1},
  abstract = {We describe the formalization of a certified algorithm for regular expression parsing based on Brzozowski derivatives, in the dependently typed language Idris. The formalized algorithm produces a proof that an input string matches a given regular expression or a proof that no matching exists. A tool for regular expression based search in the style of the well known GNU grep has been developed with the certified algorithm, and practical experiments were conducted with this tool.},
  language = {en},
  booktitle = {Programming {{Languages}}},
  publisher = {{Springer International Publishing}},
  author = {Lopes, Raul and Ribeiro, Rodrigo and Camar\~ao, Carlos},
  editor = {Castor, Fernando and Liu, Yu David},
  year = {2016},
  keywords = {Parse Tree,Regular Expression,Deterministic Finite Automaton,Empty String,Input String},
  pages = {95-109},
  file = {/Users/doisinkidney/Zotero/storage/LJKRA3T2/Lopes et al. - 2016 - Certified Derivative-Based Parsing of Regular Expr.pdf}
}

@article{mokhov_build_2018-1,
  title = {Build {{Systems}} \`a {{La Carte}}},
  volume = {2},
  issn = {2475-1421},
  abstract = {Build systems are awesome, terrifying -- and unloved. They are used by every developer around the world, but are rarely the object of study. In this paper we offer a systematic, and executable, framework for developing and comparing build systems, viewing them as related points in landscape rather than as isolated phenomena. By teasing apart existing build systems, we can recombine their components, allowing us to prototype new build systems with desired properties.},
  language = {en-US},
  number = {ICFP},
  urldate = {2019-05-03},
  journal = {Proc. ACM Program. Lang.},
  doi = {10.1145/3236774},
  url = {http://doi.acm.org/10.1145/3236774},
  author = {Mokhov, Andrey and Mitchell, Neil and Peyton Jones, Simon},
  month = jul,
  year = {2018},
  keywords = {algorithms,functional programming,build systems},
  pages = {79:1--79:29},
  file = {/Users/doisinkidney/Zotero/storage/KHUVSGHL/Mokhov et al. - 2018 - Build Systems à La Carte.pdf;/Users/doisinkidney/Zotero/storage/44IL5PYC/build-systems-la-carte.html}
}

@article{bloom_partial_2007,
  title = {Partial {{Conway}} and Iteration Semirings},
  abstract = {A Conway semiring is a semiring \$S\$ equipped with a unary operation \$\^*:S \textbackslash{}to
S\$, always called 'star', satisfying the sum star and product star identities.
It is known that these identities imply a Kleene type theorem. Some
computationally important semirings, such as \$N\$ or \$N\^\{\textbackslash{}rat\}\textbackslash{}llangle {$\Sigma\sphat$}*
\textbackslash{}rrangle\$ of rational power series of words on \${$\Sigma\$$} with coefficients in
\$N\$, cannot have a total star operation satisfying the Conway identities. We
introduce here partial Conway semirings, which are semirings \$S\$ which have a
star operation defined only on an ideal of \$S\$; when the arguments are
appropriate, the operation satisfies the above identities. We develop the
general theory of partial Conway semirings and prove a Kleene theorem for this
generalization.},
  language = {en},
  urldate = {2019-05-04},
  url = {https://arxiv.org/abs/0712.2952v1},
  author = {Bloom, S. L. and Esik, Z. and Kuich, W.},
  month = dec,
  year = {2007},
  file = {/Users/doisinkidney/Zotero/storage/CV3E8QEG/Bloom et al. - 2007 - Partial Conway and iteration semirings.pdf;/Users/doisinkidney/Zotero/storage/N34I2HNI/0712.html}
}

@article{esik_inductive_2004,
  title = {Inductive {${_\ast}$}-Semirings},
  volume = {324},
  issn = {03043975},
  abstract = {One of the most well-known induction principles in computer science is the \"yxed point induction rule, or least pre-\"yxed point rule. Inductive {${_\ast}$}-semirings are partially ordered semirings equipped with a star operation satisfying the \"yxed point equation and the \"yxed point induction rule for linear terms. Inductive {${_\ast}$}-semirings are extensions of continuous semirings and the Kleene algebras of Conway and Kozen.},
  language = {en},
  number = {1},
  urldate = {2019-05-04},
  journal = {Theoretical Computer Science},
  doi = {10.1016/j.tcs.2004.03.050},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0304397504002051},
  author = {\'Esik, Zolt\'an and Kuich, Werner},
  month = sep,
  year = {2004},
  pages = {3-33},
  file = {/Users/doisinkidney/Zotero/storage/QK6Z4QBW/Ésik and Kuich - 2004 - Inductive ∗-semirings.pdf}
}

@incollection{droste_semirings_2009-1,
  address = {Berlin, Heidelberg},
  title = {Semirings and {{Formal Power Series}}},
  isbn = {978-3-642-01491-8 978-3-642-01492-5},
  language = {en},
  urldate = {2019-05-04},
  booktitle = {Handbook of {{Weighted Automata}}},
  publisher = {{Springer Berlin Heidelberg}},
  url = {http://link.springer.com/10.1007/978-3-642-01492-5_1},
  author = {Droste, Manfred and Kuich, Werner},
  editor = {Droste, Manfred and Kuich, Werner and Vogler, Heiko},
  year = {2009},
  pages = {3-28},
  file = {/Users/doisinkidney/Zotero/storage/A6IBK22U/Droste and Kuich - 2009 - Semirings and Formal Power Series.pdf},
  doi = {10.1007/978-3-642-01492-5_1}
}

@article{bloom_conway_2008,
  title = {Conway and {{Iteration Semirings}}},
  language = {en},
  author = {Bloom, Stephen L},
  year = {2008},
  pages = {66},
  file = {/Users/doisinkidney/Zotero/storage/FUA5T6TG/Bloom - Conway and Iteration Semirings.pdf}
}

@article{saenz-carrasco_towards_2013,
  title = {Towards a General Algorithm for Path-Finding Problems},
  language = {en},
  author = {{Saenz-Carrasco}, Juan Carlos},
  month = jun,
  year = {2013},
  pages = {31},
  file = {/Users/doisinkidney/Zotero/storage/47W3T5II/Saenz-Carrasco - Towards a general algorithm for path-finding probl.pdf}
}

@inproceedings{esik_iteration_2008,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Iteration {{Semirings}}},
  isbn = {978-3-540-85780-8},
  abstract = {A Conway semiring is a semiring S equipped with a unary operation *:S {$\rightarrow$}S, called star, satisfying the sum star and product star equations. An iteration semiring is a Conway semiring satisfying Conway's group equations. In this extended abstract, we review the role of iteration semirings in the axiomatization of regular languages and rational power series, and in the axiomatization of the equational theory of continuous and complete semirings.},
  language = {en},
  booktitle = {Developments in {{Language Theory}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {\'Esik, Zolt\'an},
  editor = {Ito, Masami and Toyama, Masafumi},
  year = {2008},
  keywords = {Equational Theory,Functional Matrice,Ideal Term,Regular Language,Star Equation},
  pages = {1-20},
  file = {/Users/doisinkidney/Zotero/storage/I8SIVJDM/Ésik - 2008 - Iteration Semirings.pdf}
}

@article{ahrens_non-wellfounded_2015,
  title = {Non-Wellfounded Trees in {{Homotopy Type Theory}}},
  abstract = {We prove a conjecture about the constructibility of coinductive types - in
the principled form of indexed M-types - in Homotopy Type Theory. The
conjecture says that in the presence of inductive types, coinductive types are
derivable. Indeed, in this work, we construct coinductive types in a subsystem
of Homotopy Type Theory; this subsystem is given by Intensional Martin-L\"of
type theory with natural numbers and Voevodsky's Univalence Axiom. Our results
are mechanized in the computer proof assistant Agda.},
  language = {en},
  urldate = {2019-05-04},
  url = {https://arxiv.org/abs/1504.02949v1},
  author = {Ahrens, Benedikt and Capriotti, Paolo and Spadotti, R\'egis},
  month = apr,
  year = {2015},
  file = {/Users/doisinkidney/Zotero/storage/6KL2WEGP/Ahrens et al. - 2015 - Non-wellfounded trees in Homotopy Type Theory.pdf;/Users/doisinkidney/Zotero/storage/IQBZG32S/1504.html}
}

@article{uustalu_finiteness_2017,
  title = {Finiteness and Rational Sequences, Constructively*},
  volume = {27},
  issn = {0956-7968, 1469-7653},
  abstract = {Rational sequences are possibly infinite sequences with a finite number of distinct suffixes. In this paper, we present different implementations of rational sequences in Martin\textendash{}L\"of type theory. First, we literally translate the above definition of rational sequence into the language of type theory, i.e., we construct predicates on possibly infinite sequences expressing the finiteness of the set of suffixes. In type theory, there exist several inequivalent notions of finiteness. We consider two of them, listability and Noetherianness, and show that in the implementation of rational sequences the two notions are interchangeable. Then we introduce the type of lists with backpointers, which is an inductive implementation of rational sequences. Lists with backpointers can be unwound into rational sequences, and rational sequences can be truncated into lists with backpointers. As an example, we see how to convert the fractional representation of a rational number into its decimal representation and vice versa.},
  language = {en},
  urldate = {2019-05-04},
  journal = {Journal of Functional Programming},
  doi = {10.1017/S0956796817000041},
  url = {https://www.cambridge.org/core/journals/journal-of-functional-programming/article/finiteness-and-rational-sequences-constructively/FCC024B602F850DDCEB2E9092E72369B},
  author = {Uustalu, Tarmo and Veltri, Niccol\`o},
  year = {2017/ed},
  file = {/Users/doisinkidney/Zotero/storage/VI9F4EKI/FCC024B602F850DDCEB2E9092E72369B.html}
}

@misc{kmett_free_2011-1,
  type = {Blog},
  title = {Free {{Modules}} and {{Functional Linear Functionals}}},
  abstract = {Today I hope to start a new series of posts exploring constructive abstract algebra in Haskell.

In particular, I want to talk about a novel encoding of linear functionals, polynomials and linear maps in Haskell, but first we're going to have to build up some common terminology.

Having obtained the blessing of Wolfgang Jeltsch, I replaced the algebra package on hackage with something... bigger, although still very much a work in progress.},
  urldate = {2019-05-05},
  journal = {The Comonad.Reader},
  url = {http://comonad.com/reader/2011/free-modules-and-functional-linear-functionals/},
  author = {Kmett, Edward},
  month = jul,
  year = {2011},
  file = {/Users/doisinkidney/Zotero/storage/HQJATPFS/free-modules-and-functional-linear-functionals.html;/Users/doisinkidney/Zotero/storage/RCN6GHG3/free-modules-and-functional-linear-functionals.html}
}

@misc{kmett_state_2018,
  type = {Blog},
  title = {The {{State Comonad}}},
  abstract = {Is State a Comonad?

Not Costate or rather, Store as we tend to call it today, but actually State s itself?

Let's see!},
  urldate = {2019-05-05},
  journal = {The Comonad.Reader},
  url = {http://comonad.com/reader/2018/the-state-comonad/},
  author = {Kmett, Edward},
  month = jan,
  year = {2018},
  file = {/Users/doisinkidney/Zotero/storage/UB47Z7UV/the-state-comonad.html}
}

@misc{kingofthehomless_i_2018,
  title = {I Made a Monad That {{I}} Haven't Seen before, and {{I}} Have a Few Questions about It.},
  abstract = {This came from me wanting to create an applicative that would append two monoids together, but worked differently than the regular writer monad...},
  language = {en-gb},
  urldate = {2019-05-05},
  journal = {reddit},
  url = {https://www.reddit.com/r/haskell/comments/7oav51/i_made_a_monad_that_i_havent_seen_before_and_i/},
  author = {{KingOfTheHomless}},
  month = jan,
  year = {2018},
  file = {/Users/doisinkidney/Zotero/storage/J7WVZGEU/i_made_a_monad_that_i_havent_seen_before_and_i.html}
}

@inproceedings{pieters_faster_2019,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Faster {{Coroutine Pipelines}}: {{A Reconstruction}}},
  isbn = {978-3-030-05998-9},
  shorttitle = {Faster {{Coroutine Pipelines}}},
  abstract = {Spivey has recently presented a novel functional representation that supports the efficient composition, or merging, of coroutine pipelines for processing streams of data. This representation was inspired by Shivers and Might's three-continuation approach and is shown to be equivalent to a simple yet inefficient executable specification. Unfortunately, neither Shivers and Might's original work nor the equivalence proof sheds much light on the underlying principles allowing the derivation of this efficient representation from its specification.This paper gives the missing insight by reconstructing a systematic derivation in terms of known transformation steps from the simple specification to the efficient representation. This derivation sheds light on the limitations of the representation and on its applicability to other settings. In particular, it has enabled us to obtain a similar representation for pipes featuring two-way communication, similar to the Haskell pipes library. Our benchmarks confirm that this two-way representation retains the same improved performance characteristics.},
  language = {en},
  booktitle = {Practical {{Aspects}} of {{Declarative Languages}}},
  publisher = {{Springer International Publishing}},
  author = {Pieters, Ruben P. and Schrijvers, Tom},
  editor = {Alferes, Jos\'e J\'ulio and Johansson, Moa},
  year = {2019},
  keywords = {Algebra,Stream processing,Structured recursion},
  pages = {133-149}
}

@article{pirog_backtracking_2017,
  title = {Backtracking with Cut via a Distributive Law and Left-Zero Monoids*},
  volume = {27},
  issn = {0956-7968, 1469-7653},
  abstract = {We employ the framework of algebraic effects to augment the list monad with the pruning cut operator known from Prolog. We give two descriptions of the resulting monad: as the monad of free left-zero monoids, and as a composition via a distributive law of the list monad and the `unary idempotent operation' monad. The scope delimiter of cut arises as a handler.},
  language = {en},
  urldate = {2019-05-06},
  journal = {Journal of Functional Programming},
  doi = {10.1017/S0956796817000077},
  url = {https://www.cambridge.org/core/journals/journal-of-functional-programming/article/backtracking-with-cut-via-a-distributive-law-and-leftzero-monoids/9B7B1620EEFD293888B7B1E0F805156B},
  author = {Pir\'og, Maciej and Staton, Sam},
  year = {2017/ed},
  file = {/Users/doisinkidney/Zotero/storage/55R2TTII/9B7B1620EEFD293888B7B1E0F805156B.html}
}

@article{wehrung_metric_1993,
  title = {Metric Properties of Positively Ordered Monoids},
  volume = {5},
  issn = {0933-7741, 1435-5337},
  abstract = {We introduce here an intrinsic (quasi-) metric on each positively ordered monoid (P.O.M.), which is defined in terms of the evaluation map from the given P.O.M. to its bidual and for which P.O.M. homomorphisms are continuous. Moreover, we find a class of refinement P.O.M.'s which, equipped with the canonical metric, are complete metric spaces; this class includes the class of weak cardinal algebras, but also most cases of completions of a certain kind (we will call it `strongly reduced products') of P.O.M.'s, and of which a prototype has been used in a previous paper for the description of the evaluation map of a given refinement P.O.M.. This result can also be viewed as a wide generalization to the non-linearly ordered case (for example weak cardinal algebras) of the (Cauchy-) completeness of the real line.},
  language = {en},
  number = {5},
  urldate = {2019-05-07},
  journal = {Forum Mathematicum},
  doi = {10.1515/form.1993.5.183},
  url = {https://www.degruyter.com/view/j/form.1993.issue-5/form.1993.5.183/form.1993.5.183.xml},
  author = {Wehrung, Friedrich},
  year = {1993},
  file = {/Users/doisinkidney/Zotero/storage/H4IU3JDE/Wehrung - 1993 - Metric properties of positively ordered monoids.pdf}
}

@article{pirog_backtracking_2017-1,
  title = {Backtracking with Cut via a Distributive Law and Left-Zero Monoids},
  volume = {27},
  issn = {0956-7968, 1469-7653},
  abstract = {We employ the framework of algebraic effects to augment the list monad with the pruning cut operator known from Prolog. We give two descriptions of the resulting monad: as the monad of free left-zero monoids, and as a composition via a distributive law of the list monad and the `unary idempotent operation' monad. The scope delimiter of cut arises as a handler.},
  language = {en},
  urldate = {2019-05-08},
  journal = {Journal of Functional Programming},
  doi = {10.1017/S0956796817000077},
  url = {https://www.cambridge.org/core/product/identifier/S0956796817000077/type/journal_article},
  author = {Pir\'og, Maciej and Staton, Sam},
  year = {2017},
  pages = {e17},
  file = {/Users/doisinkidney/Zotero/storage/SJK3WUIN/Piróg and Staton - 2017 - Backtracking with cut via a distributive law and l.pdf}
}


